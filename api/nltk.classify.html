

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>classify Package &mdash; NLTK 2.0 documentation</title>
    
    <link rel="stylesheet" href="../_static/agogo.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '2.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="top" title="NLTK 2.0 documentation" href="../index.html" />
    <link rel="up" title="nltk Package" href="nltk.html" />
    <link rel="next" title="cluster Package" href="nltk.cluster.html" />
    <link rel="prev" title="chunk Package" href="nltk.chunk.html" /> 
  </head>
  <body>
    <div class="header-wrapper">
      <div class="header">
        <div class="headertitle"><a
          href="../index.html">NLTK 2.0 documentation</a></div>
        <div class="rel">
          <a href="nltk.chunk.html" title="chunk Package"
             accesskey="P">previous</a> |
          <a href="nltk.cluster.html" title="cluster Package"
             accesskey="N">next</a> |
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a>
        </div>
       </div>
    </div>

    <div class="content-wrapper">
      <div class="content">
        <div class="document">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="classify-package">
<h1>classify Package<a class="headerlink" href="#classify-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id1">
<h2><tt class="xref py py-mod docutils literal"><span class="pre">classify</span></tt> Package<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-nltk.classify"></span><p>Classes and interfaces for labeling tokens with category labels (or
&#8220;class labels&#8221;).  Typically, labels are represented with strings
(such as <tt class="docutils literal"><span class="pre">'health'</span></tt> or <tt class="docutils literal"><span class="pre">'sports'</span></tt>).  Classifiers can be used to
perform a wide range of classification tasks.  For example,
classifiers can be used...</p>
<ul class="simple">
<li>to classify documents by topic</li>
<li>to classify ambiguous words by which word sense is intended</li>
<li>to classify acoustic signals by which phoneme they represent</li>
<li>to classify sentences by their author</li>
</ul>
<div class="section" id="features">
<h3>Features<a class="headerlink" href="#features" title="Permalink to this headline">¶</a></h3>
<p>In order to decide which category label is appropriate for a given
token, classifiers examine one or more &#8216;features&#8217; of the token.  These
&#8220;features&#8221; are typically chosen by hand, and indicate which aspects
of the token are relevant to the classification decision.  For
example, a document classifier might use a separate feature for each
word, recording how often that word occurred in the document.</p>
</div>
<div class="section" id="featuresets">
<h3>Featuresets<a class="headerlink" href="#featuresets" title="Permalink to this headline">¶</a></h3>
<p>The features describing a token are encoded using a &#8220;featureset&#8221;,
which is a dictionary that maps from &#8220;feature names&#8221; to &#8220;feature
values&#8221;.  Feature names are unique strings that indicate what aspect
of the token is encoded by the feature.  Examples include
<tt class="docutils literal"><span class="pre">'prevword'</span></tt>, for a feature whose value is the previous word; and
<tt class="docutils literal"><span class="pre">'contains-word(library)'</span></tt> for a feature that is true when a document
contains the word <tt class="docutils literal"><span class="pre">'library'</span></tt>.  Feature values are typically
booleans, numbers, or strings, depending on which feature they
describe.</p>
<p>Featuresets are typically constructed using a &#8220;feature detector&#8221;
(also known as a &#8220;feature extractor&#8221;).  A feature detector is a
function that takes a token (and sometimes information about its
context) as its input, and returns a featureset describing that token.
For example, the following feature detector converts a document
(stored as a list of words) to a featureset describing the set of
words included in the document:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="c"># Define a feature detector function.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">document_features</span><span class="p">(</span><span class="n">document</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="nb">dict</span><span class="p">([(</span><span class="s">&#39;contains-word(</span><span class="si">%s</span><span class="s">)&#39;</span> <span class="o">%</span> <span class="n">w</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">document</span><span class="p">])</span>
</pre></div>
</div>
<p>Feature detectors are typically applied to each token before it is fed
to the classifier:</p>
<p>The parameters that a feature detector expects will vary, depending on
the task and the needs of the feature detector.  For example, a
feature detector for word sense disambiguation (WSD) might take as its
input a sentence, and the index of a word that should be classified,
and return a featureset for that word.  The following feature detector
for WSD includes features describing the left and right contexts of
the target word:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">wsd_features</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">featureset</span> <span class="o">=</span> <span class="p">{}</span>
<span class="gp">... </span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">index</span><span class="o">-</span><span class="mi">3</span><span class="p">),</span> <span class="n">index</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">featureset</span><span class="p">[</span><span class="s">&#39;left-context(</span><span class="si">%s</span><span class="s">)&#39;</span> <span class="o">%</span> <span class="n">sentence</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="bp">True</span>
<span class="gp">... </span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">index</span><span class="o">+</span><span class="mi">3</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">))):</span>
<span class="gp">... </span>        <span class="n">featureset</span><span class="p">[</span><span class="s">&#39;right-context(</span><span class="si">%s</span><span class="s">)&#39;</span> <span class="o">%</span> <span class="n">sentence</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="bp">True</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">featureset</span>
</pre></div>
</div>
</div>
<div class="section" id="training-classifiers">
<h3>Training Classifiers<a class="headerlink" href="#training-classifiers" title="Permalink to this headline">¶</a></h3>
<p>Most classifiers are built by training them on a list of hand-labeled
examples, known as the &#8220;training set&#8221;.  Training sets are represented
as lists of <tt class="docutils literal"><span class="pre">(featuredict,</span> <span class="pre">label)</span></tt> tuples.</p>
</div>
</div>
<div class="section" id="module-nltk.classify.api">
<span id="api-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">api</span></tt> Module<a class="headerlink" href="#module-nltk.classify.api" title="Permalink to this headline">¶</a></h2>
<p>Interfaces for labeling tokens with category labels (or &#8220;class labels&#8221;).</p>
<p><tt class="docutils literal"><span class="pre">ClassifierI</span></tt> is a standard interface for &#8220;single-category
classification&#8221;, in which the set of categories is known, the number
of categories is finite, and each text belongs to exactly one
category.</p>
<p><tt class="docutils literal"><span class="pre">MultiClassifierI</span></tt> is a standard interface for &#8220;multi-category
classification&#8221;, which is like single-category classification except
that each text belongs to zero or more categories.</p>
<dl class="class">
<dt id="nltk.classify.api.ClassifierI">
<em class="property">class </em><tt class="descclassname">nltk.classify.api.</tt><tt class="descname">ClassifierI</tt><a class="reference internal" href="../_modules/nltk/classify/api.html#ClassifierI"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.api.ClassifierI" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>A processing interface for labeling tokens with a single category
label (or &#8220;class&#8221;).  Labels are typically strs or
ints, but can be any immutable type.  The set of labels
that the classifier chooses from must be fixed and finite.</p>
<dl class="docutils">
<dt>Subclasses must define:</dt>
<dd><ul class="first last simple">
<li><tt class="docutils literal"><span class="pre">labels()</span></tt></li>
<li>either <tt class="docutils literal"><span class="pre">classify()</span></tt> or <tt class="docutils literal"><span class="pre">batch_classify()</span></tt> (or both)</li>
</ul>
</dd>
<dt>Subclasses may define:</dt>
<dd><ul class="first last simple">
<li>either <tt class="docutils literal"><span class="pre">prob_classify()</span></tt> or <tt class="docutils literal"><span class="pre">batch_prob_classify()</span></tt> (or both)</li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="nltk.classify.api.ClassifierI.batch_classify">
<tt class="descname">batch_classify</tt><big>(</big><em>featuresets</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/api.html#ClassifierI.batch_classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.api.ClassifierI.batch_classify" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply <tt class="docutils literal"><span class="pre">self.classify()</span></tt> to each element of <tt class="docutils literal"><span class="pre">featuresets</span></tt>.  I.e.:</p>
<blockquote>
<div>return [self.classify(fs) for fs in featuresets]</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">list(label)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.api.ClassifierI.batch_prob_classify">
<tt class="descname">batch_prob_classify</tt><big>(</big><em>featuresets</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/api.html#ClassifierI.batch_prob_classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.api.ClassifierI.batch_prob_classify" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply <tt class="docutils literal"><span class="pre">self.prob_classify()</span></tt> to each element of <tt class="docutils literal"><span class="pre">featuresets</span></tt>.  I.e.:</p>
<blockquote>
<div>return [self.prob_classify(fs) for fs in featuresets]</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">list(ProbDistI)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.api.ClassifierI.classify">
<tt class="descname">classify</tt><big>(</big><em>featureset</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/api.html#ClassifierI.classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.api.ClassifierI.classify" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">the most appropriate label for the given featureset.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">label</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.api.ClassifierI.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/api.html#ClassifierI.labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.api.ClassifierI.labels" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">the list of category labels used by this classifier.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">list of (immutable)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.api.ClassifierI.prob_classify">
<tt class="descname">prob_classify</tt><big>(</big><em>featureset</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/api.html#ClassifierI.prob_classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.api.ClassifierI.prob_classify" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">a probability distribution over labels for the given
featureset.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">ProbDistI</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.classify.api.MultiClassifierI">
<em class="property">class </em><tt class="descclassname">nltk.classify.api.</tt><tt class="descname">MultiClassifierI</tt><a class="reference internal" href="../_modules/nltk/classify/api.html#MultiClassifierI"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.api.MultiClassifierI" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>A processing interface for labeling tokens with zero or more
category labels (or &#8220;labels&#8221;).  Labels are typically strs
or ints, but can be any immutable type.  The set of labels
that the multi-classifier chooses from must be fixed and finite.</p>
<dl class="docutils">
<dt>Subclasses must define:</dt>
<dd><ul class="first last simple">
<li><tt class="docutils literal"><span class="pre">labels()</span></tt></li>
<li>either <tt class="docutils literal"><span class="pre">classify()</span></tt> or <tt class="docutils literal"><span class="pre">batch_classify()</span></tt> (or both)</li>
</ul>
</dd>
<dt>Subclasses may define:</dt>
<dd><ul class="first last simple">
<li>either <tt class="docutils literal"><span class="pre">prob_classify()</span></tt> or <tt class="docutils literal"><span class="pre">batch_prob_classify()</span></tt> (or both)</li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="nltk.classify.api.MultiClassifierI.batch_classify">
<tt class="descname">batch_classify</tt><big>(</big><em>featuresets</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/api.html#MultiClassifierI.batch_classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.api.MultiClassifierI.batch_classify" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply <tt class="docutils literal"><span class="pre">self.classify()</span></tt> to each element of <tt class="docutils literal"><span class="pre">featuresets</span></tt>.  I.e.:</p>
<blockquote>
<div>return [self.classify(fs) for fs in featuresets]</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">list(set(label))</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.api.MultiClassifierI.batch_prob_classify">
<tt class="descname">batch_prob_classify</tt><big>(</big><em>featuresets</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/api.html#MultiClassifierI.batch_prob_classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.api.MultiClassifierI.batch_prob_classify" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply <tt class="docutils literal"><span class="pre">self.prob_classify()</span></tt> to each element of <tt class="docutils literal"><span class="pre">featuresets</span></tt>.  I.e.:</p>
<blockquote>
<div>return [self.prob_classify(fs) for fs in featuresets]</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">list(ProbDistI)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.api.MultiClassifierI.classify">
<tt class="descname">classify</tt><big>(</big><em>featureset</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/api.html#MultiClassifierI.classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.api.MultiClassifierI.classify" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">the most appropriate set of labels for the given featureset.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">set(label)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.api.MultiClassifierI.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/api.html#MultiClassifierI.labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.api.MultiClassifierI.labels" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">the list of category labels used by this classifier.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">list of (immutable)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.api.MultiClassifierI.prob_classify">
<tt class="descname">prob_classify</tt><big>(</big><em>featureset</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/api.html#MultiClassifierI.prob_classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.api.MultiClassifierI.prob_classify" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">a probability distribution over sets of labels for the
given featureset.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">ProbDistI</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nltk.classify.decisiontree">
<span id="decisiontree-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">decisiontree</span></tt> Module<a class="headerlink" href="#module-nltk.classify.decisiontree" title="Permalink to this headline">¶</a></h2>
<p>A classifier model that decides which label to assign to a token on
the basis of a tree structure, where branches correspond to conditions
on feature values, and leaves correspond to label assignments.</p>
<dl class="class">
<dt id="nltk.classify.decisiontree.DecisionTreeClassifier">
<em class="property">class </em><tt class="descclassname">nltk.classify.decisiontree.</tt><tt class="descname">DecisionTreeClassifier</tt><big>(</big><em>label</em>, <em>feature_name=None</em>, <em>decisions=None</em>, <em>default=None</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#DecisionTreeClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.DecisionTreeClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.api.ClassifierI" title="nltk.classify.api.ClassifierI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.api.ClassifierI</span></tt></a></p>
<dl class="staticmethod">
<dt id="nltk.classify.decisiontree.DecisionTreeClassifier.best_binary_stump">
<em class="property">static </em><tt class="descname">best_binary_stump</tt><big>(</big><em>feature_names</em>, <em>labeled_featuresets</em>, <em>feature_values</em>, <em>verbose=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#DecisionTreeClassifier.best_binary_stump"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.DecisionTreeClassifier.best_binary_stump" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="nltk.classify.decisiontree.DecisionTreeClassifier.best_stump">
<em class="property">static </em><tt class="descname">best_stump</tt><big>(</big><em>feature_names</em>, <em>labeled_featuresets</em>, <em>verbose=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#DecisionTreeClassifier.best_stump"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.DecisionTreeClassifier.best_stump" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="nltk.classify.decisiontree.DecisionTreeClassifier.binary_stump">
<em class="property">static </em><tt class="descname">binary_stump</tt><big>(</big><em>feature_name</em>, <em>feature_value</em>, <em>labeled_featuresets</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#DecisionTreeClassifier.binary_stump"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.DecisionTreeClassifier.binary_stump" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.decisiontree.DecisionTreeClassifier.classify">
<tt class="descname">classify</tt><big>(</big><em>featureset</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#DecisionTreeClassifier.classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.DecisionTreeClassifier.classify" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.decisiontree.DecisionTreeClassifier.error">
<tt class="descname">error</tt><big>(</big><em>labeled_featuresets</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#DecisionTreeClassifier.error"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.DecisionTreeClassifier.error" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.decisiontree.DecisionTreeClassifier.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#DecisionTreeClassifier.labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.DecisionTreeClassifier.labels" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="nltk.classify.decisiontree.DecisionTreeClassifier.leaf">
<em class="property">static </em><tt class="descname">leaf</tt><big>(</big><em>labeled_featuresets</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#DecisionTreeClassifier.leaf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.DecisionTreeClassifier.leaf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.decisiontree.DecisionTreeClassifier.pp">
<tt class="descname">pp</tt><big>(</big><em>width=70</em>, <em>prefix=''</em>, <em>depth=4</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#DecisionTreeClassifier.pp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.DecisionTreeClassifier.pp" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a string containing a pretty-printed version of this
decision tree.  Each line in this string corresponds to a
single decision tree node or leaf, and indentation is used to
display the structure of the decision tree.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.decisiontree.DecisionTreeClassifier.pseudocode">
<tt class="descname">pseudocode</tt><big>(</big><em>prefix=''</em>, <em>depth=4</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#DecisionTreeClassifier.pseudocode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.DecisionTreeClassifier.pseudocode" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a string representation of this decision tree that
expresses the decisions it makes as a nested set of pseudocode
if statements.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.decisiontree.DecisionTreeClassifier.refine">
<tt class="descname">refine</tt><big>(</big><em>labeled_featuresets</em>, <em>entropy_cutoff</em>, <em>depth_cutoff</em>, <em>support_cutoff</em>, <em>binary=False</em>, <em>feature_values=None</em>, <em>verbose=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#DecisionTreeClassifier.refine"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.DecisionTreeClassifier.refine" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="nltk.classify.decisiontree.DecisionTreeClassifier.stump">
<em class="property">static </em><tt class="descname">stump</tt><big>(</big><em>feature_name</em>, <em>labeled_featuresets</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#DecisionTreeClassifier.stump"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.DecisionTreeClassifier.stump" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="nltk.classify.decisiontree.DecisionTreeClassifier.train">
<em class="property">static </em><tt class="descname">train</tt><big>(</big><em>labeled_featuresets</em>, <em>entropy_cutoff=0.050000000000000003</em>, <em>depth_cutoff=100</em>, <em>support_cutoff=10</em>, <em>binary=False</em>, <em>feature_values=None</em>, <em>verbose=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#DecisionTreeClassifier.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.DecisionTreeClassifier.train" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>binary</strong> &#8211; If true, then treat all feature/value pairs a</td>
</tr>
</tbody>
</table>
<p>individual binary features, rather than using a single n-way
branch for each feature.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="nltk.classify.decisiontree.demo">
<tt class="descclassname">nltk.classify.decisiontree.</tt><tt class="descname">demo</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.demo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.decisiontree.f">
<tt class="descclassname">nltk.classify.decisiontree.</tt><tt class="descname">f</tt><big>(</big><em>x</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#f"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.f" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-nltk.classify.mallet">
<span id="mallet-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">mallet</span></tt> Module<a class="headerlink" href="#module-nltk.classify.mallet" title="Permalink to this headline">¶</a></h2>
<p>A set of functions used to interface with the external <a class="reference external" href="http://mallet.cs.umass.edu/">Mallet</a> machine learning
package. Before mallet can be used, you should tell NLTK where it can find
the mallet package, using the <tt class="docutils literal"><span class="pre">config_mallet()</span></tt> function. Typical usage:</p>
<dl class="function">
<dt id="nltk.classify.mallet.call_mallet">
<tt class="descclassname">nltk.classify.mallet.</tt><tt class="descname">call_mallet</tt><big>(</big><em>cmd</em>, <em>classpath=None</em>, <em>stdin=None</em>, <em>stdout=None</em>, <em>stderr=None</em>, <em>blocking=True</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/mallet.html#call_mallet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.mallet.call_mallet" title="Permalink to this definition">¶</a></dt>
<dd><p>Call <cite>nltk.internals.java</cite> with the given command, and with the classpath
modified to include both <tt class="docutils literal"><span class="pre">nltk.jar</span></tt> and all the <tt class="docutils literal"><span class="pre">.jar</span></tt> files defined by
Mallet.</p>
<p>See <cite>nltk.internals.java</cite> for parameter and return value descriptions.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.mallet.config_mallet">
<tt class="descclassname">nltk.classify.mallet.</tt><tt class="descname">config_mallet</tt><big>(</big><em>mallet_home=None</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/mallet.html#config_mallet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.mallet.config_mallet" title="Permalink to this definition">¶</a></dt>
<dd><p>Configure NLTK&#8217;s interface to the Mallet machine learning package.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>mallet_home</strong> (<em>str</em>) &#8211; The full path to the mallet directory. If not
specified, then NLTK will search the system for a mallet directory;
and if one is not found, it will raise a <tt class="docutils literal"><span class="pre">LookupError</span></tt> exception.</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-nltk.classify.maxent">
<span id="maxent-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">maxent</span></tt> Module<a class="headerlink" href="#module-nltk.classify.maxent" title="Permalink to this headline">¶</a></h2>
<p>A classifier model based on maximum entropy modeling framework.  This
framework considers all of the probability distributions that are
empirically consistent with the training data; and chooses the
distribution with the highest entropy.  A probability distribution is
&#8220;empirically consistent&#8221; with a set of training data if its estimated
frequency with which a class and a feature vector value co-occur is
equal to the actual frequency in the data.</p>
<div class="section" id="terminology-feature">
<h3>Terminology: &#8216;feature&#8217;<a class="headerlink" href="#terminology-feature" title="Permalink to this headline">¶</a></h3>
<p>The term <em>feature</em> is usually used to refer to some property of an
unlabeled token.  For example, when performing word sense
disambiguation, we might define a <tt class="docutils literal"><span class="pre">'prevword'</span></tt> feature whose value is
the word preceding the target word.  However, in the context of
maxent modeling, the term <em>feature</em> is typically used to refer to a
property of a &#8220;labeled&#8221; token.  In order to prevent confusion, we
will introduce two distinct terms to disambiguate these two different
concepts:</p>
<blockquote>
<div><ul class="simple">
<li>An &#8220;input-feature&#8221; is a property of an unlabeled token.</li>
<li>A &#8220;joint-feature&#8221; is a property of a labeled token.</li>
</ul>
</div></blockquote>
<p>In the rest of the <tt class="docutils literal"><span class="pre">nltk.classify</span></tt> module, the term &#8220;features&#8221; is
used to refer to what we will call &#8220;input-features&#8221; in this module.</p>
<p>In literature that describes and discusses maximum entropy models,
input-features are typically called &#8220;contexts&#8221;, and joint-features
are simply referred to as &#8220;features&#8221;.</p>
<div class="section" id="converting-input-features-to-joint-features">
<h4>Converting Input-Features to Joint-Features<a class="headerlink" href="#converting-input-features-to-joint-features" title="Permalink to this headline">¶</a></h4>
<p>In maximum entropy models, joint-features are required to have numeric
values.  Typically, each input-feature <tt class="docutils literal"><span class="pre">input_feat</span></tt> is mapped to a
set of joint-features of the form:</p>
<div class="line-block">
<div class="line">joint_feat(token, label) = { 1 if input_feat(token) == feat_val</div>
<div class="line-block">
<div class="line">{      and label == some_label</div>
<div class="line">{</div>
<div class="line">{ 0 otherwise</div>
</div>
</div>
<p>For all values of <tt class="docutils literal"><span class="pre">feat_val</span></tt> and <tt class="docutils literal"><span class="pre">some_label</span></tt>.  This mapping is
performed by classes that implement the <tt class="docutils literal"><span class="pre">MaxentFeatureEncodingI</span></tt>
interface.</p>
<dl class="class">
<dt id="nltk.classify.maxent.BinaryMaxentFeatureEncoding">
<em class="property">class </em><tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">BinaryMaxentFeatureEncoding</tt><big>(</big><em>labels</em>, <em>mapping</em>, <em>unseen_features=False</em>, <em>alwayson_features=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#BinaryMaxentFeatureEncoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.BinaryMaxentFeatureEncoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.maxent.MaxentFeatureEncodingI" title="nltk.classify.maxent.MaxentFeatureEncodingI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.maxent.MaxentFeatureEncodingI</span></tt></a></p>
<p>A feature encoding that generates vectors containing a binary
joint-features of the form:</p>
<div class="line-block">
<div class="line">joint_feat(fs, l) = { 1 if (fs[fname] == fval) and (l == label)</div>
<div class="line-block">
<div class="line">{</div>
<div class="line">{ 0 otherwise</div>
</div>
</div>
<p>Where <tt class="docutils literal"><span class="pre">fname</span></tt> is the name of an input-feature, <tt class="docutils literal"><span class="pre">fval</span></tt> is a value
for that input-feature, and <tt class="docutils literal"><span class="pre">label</span></tt> is a label.</p>
<p>Typically, these features are constructed based on a training
corpus, using the <tt class="docutils literal"><span class="pre">train()</span></tt> method.  This method will create one
feature for each combination of <tt class="docutils literal"><span class="pre">fname</span></tt>, <tt class="docutils literal"><span class="pre">fval</span></tt>, and <tt class="docutils literal"><span class="pre">label</span></tt>
that occurs at least once in the training corpus.</p>
<p>The <tt class="docutils literal"><span class="pre">unseen_features</span></tt> parameter can be used to add &#8220;unseen-value
features&#8221;, which are used whenever an input feature has a value
that was not encountered in the training corpus.  These features
have the form:</p>
<div class="line-block">
<div class="line">joint_feat(fs, l) = { 1 if is_unseen(fname, fs[fname])</div>
<div class="line-block">
<div class="line">{      and l == label</div>
<div class="line">{</div>
<div class="line">{ 0 otherwise</div>
</div>
</div>
<p>Where <tt class="docutils literal"><span class="pre">is_unseen(fname,</span> <span class="pre">fval)</span></tt> is true if the encoding does not
contain any joint features that are true when <tt class="docutils literal"><span class="pre">fs[fname]==fval</span></tt>.</p>
<p>The <tt class="docutils literal"><span class="pre">alwayson_features</span></tt> parameter can be used to add &#8220;always-on
features&#8221;, which have the form:</p>
<div class="highlight-python"><pre>|  joint_feat(fs, l) = { 1 if (l == label)
|                      {
|                      { 0 otherwise</pre>
</div>
<p>These always-on features allow the maxent model to directly model
the prior probabilities of each label.</p>
<dl class="method">
<dt id="nltk.classify.maxent.BinaryMaxentFeatureEncoding.describe">
<tt class="descname">describe</tt><big>(</big><em>f_id</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#BinaryMaxentFeatureEncoding.describe"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.BinaryMaxentFeatureEncoding.describe" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.BinaryMaxentFeatureEncoding.encode">
<tt class="descname">encode</tt><big>(</big><em>featureset</em>, <em>label</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#BinaryMaxentFeatureEncoding.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.BinaryMaxentFeatureEncoding.encode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.BinaryMaxentFeatureEncoding.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#BinaryMaxentFeatureEncoding.labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.BinaryMaxentFeatureEncoding.labels" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.BinaryMaxentFeatureEncoding.length">
<tt class="descname">length</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#BinaryMaxentFeatureEncoding.length"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.BinaryMaxentFeatureEncoding.length" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="classmethod">
<dt id="nltk.classify.maxent.BinaryMaxentFeatureEncoding.train">
<em class="property">classmethod </em><tt class="descname">train</tt><big>(</big><em>train_toks</em>, <em>count_cutoff=0</em>, <em>labels=None</em>, <em>**options</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#BinaryMaxentFeatureEncoding.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.BinaryMaxentFeatureEncoding.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct and return new feature encoding, based on a given
training corpus <tt class="docutils literal"><span class="pre">train_toks</span></tt>.  See the class description
<tt class="docutils literal"><span class="pre">BinaryMaxentFeatureEncoding</span></tt> for a description of the
joint-features that will be included in this encoding.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>train_toks</strong> (<em>list(tuple(dict, str))</em>) &#8211; Training data, represented as a list of
pairs, the first member of which is a feature dictionary,
and the second of which is a classification label.</li>
<li><strong>count_cutoff</strong> (<em>int</em>) &#8211; A cutoff value that is used to discard
rare joint-features.  If a joint-feature&#8217;s value is 1
fewer than <tt class="docutils literal"><span class="pre">count_cutoff</span></tt> times in the training corpus,
then that joint-feature is not included in the generated
encoding.</li>
<li><strong>labels</strong> (<em>list</em>) &#8211; A list of labels that should be used by the
classifier.  If not specified, then the set of labels
attested in <tt class="docutils literal"><span class="pre">train_toks</span></tt> will be used.</li>
<li><strong>options</strong> &#8211; Extra parameters for the constructor, such as
<tt class="docutils literal"><span class="pre">unseen_features</span></tt> and <tt class="docutils literal"><span class="pre">alwayson_features</span></tt>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="attribute">
<dt id="nltk.classify.maxent.ConditionalExponentialClassifier">
<tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">ConditionalExponentialClassifier</tt><a class="headerlink" href="#nltk.classify.maxent.ConditionalExponentialClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for MaxentClassifier.</p>
<p>alias of <a class="reference internal" href="#nltk.classify.maxent.MaxentClassifier" title="nltk.classify.maxent.MaxentClassifier"><tt class="xref py py-class docutils literal"><span class="pre">MaxentClassifier</span></tt></a></p>
</dd></dl>

<dl class="class">
<dt id="nltk.classify.maxent.FunctionBackedMaxentFeatureEncoding">
<em class="property">class </em><tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">FunctionBackedMaxentFeatureEncoding</tt><big>(</big><em>func</em>, <em>length</em>, <em>labels</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#FunctionBackedMaxentFeatureEncoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.FunctionBackedMaxentFeatureEncoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.maxent.MaxentFeatureEncodingI" title="nltk.classify.maxent.MaxentFeatureEncodingI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.maxent.MaxentFeatureEncodingI</span></tt></a></p>
<p>A feature encoding that calls a user-supplied function to map a
given featureset/label pair to a sparse joint-feature vector.</p>
<dl class="method">
<dt id="nltk.classify.maxent.FunctionBackedMaxentFeatureEncoding.describe">
<tt class="descname">describe</tt><big>(</big><em>fid</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#FunctionBackedMaxentFeatureEncoding.describe"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.FunctionBackedMaxentFeatureEncoding.describe" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.FunctionBackedMaxentFeatureEncoding.encode">
<tt class="descname">encode</tt><big>(</big><em>featureset</em>, <em>label</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#FunctionBackedMaxentFeatureEncoding.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.FunctionBackedMaxentFeatureEncoding.encode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.FunctionBackedMaxentFeatureEncoding.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#FunctionBackedMaxentFeatureEncoding.labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.FunctionBackedMaxentFeatureEncoding.labels" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.FunctionBackedMaxentFeatureEncoding.length">
<tt class="descname">length</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#FunctionBackedMaxentFeatureEncoding.length"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.FunctionBackedMaxentFeatureEncoding.length" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.classify.maxent.GISEncoding">
<em class="property">class </em><tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">GISEncoding</tt><big>(</big><em>labels</em>, <em>mapping</em>, <em>unseen_features=False</em>, <em>alwayson_features=False</em>, <em>C=None</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#GISEncoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.GISEncoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.maxent.BinaryMaxentFeatureEncoding" title="nltk.classify.maxent.BinaryMaxentFeatureEncoding"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.maxent.BinaryMaxentFeatureEncoding</span></tt></a></p>
<p>A binary feature encoding which adds one new joint-feature to the
joint-features defined by <tt class="docutils literal"><span class="pre">BinaryMaxentFeatureEncoding</span></tt>: a
correction feature, whose value is chosen to ensure that the
sparse vector always sums to a constant non-negative number.  This
new feature is used to ensure two preconditions for the GIS
training algorithm:</p>
<blockquote>
<div><ul class="simple">
<li>At least one feature vector index must be nonzero for every
token.</li>
<li>The feature vector must sum to a constant non-negative number
for every token.</li>
</ul>
</div></blockquote>
<dl class="attribute">
<dt id="nltk.classify.maxent.GISEncoding.C">
<tt class="descname">C</tt><a class="reference internal" href="../_modules/nltk/classify/maxent.html#GISEncoding.C"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.GISEncoding.C" title="Permalink to this definition">¶</a></dt>
<dd><p>The non-negative constant that all encoded feature vectors
will sum to.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.GISEncoding.describe">
<tt class="descname">describe</tt><big>(</big><em>f_id</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#GISEncoding.describe"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.GISEncoding.describe" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.GISEncoding.encode">
<tt class="descname">encode</tt><big>(</big><em>featureset</em>, <em>label</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#GISEncoding.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.GISEncoding.encode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.GISEncoding.length">
<tt class="descname">length</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#GISEncoding.length"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.GISEncoding.length" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.classify.maxent.MaxentClassifier">
<em class="property">class </em><tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">MaxentClassifier</tt><big>(</big><em>encoding</em>, <em>weights</em>, <em>logarithmic=True</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.api.ClassifierI" title="nltk.classify.api.ClassifierI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.api.ClassifierI</span></tt></a></p>
<p>A maximum entropy classifier (also known as a &#8220;conditional
exponential classifier&#8221;).  This classifier is parameterized by a
set of &#8220;weights&#8221;, which are used to combine the joint-features
that are generated from a featureset by an &#8220;encoding&#8221;.  In
particular, the encoding maps each <tt class="docutils literal"><span class="pre">(featureset,</span> <span class="pre">label)</span></tt> pair to
a vector.  The probability of each label is then computed using
the following equation:</p>
<div class="highlight-python"><pre>                          dotprod(weights, encode(fs,label))
prob(fs|label) = ---------------------------------------------------
                 sum(dotprod(weights, encode(fs,l)) for l in labels)</pre>
</div>
<p>Where <tt class="docutils literal"><span class="pre">dotprod</span></tt> is the dot product:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">dotprod</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">)</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="o">*</span><span class="n">y</span> <span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">))</span>
</pre></div>
</div>
<dl class="attribute">
<dt id="nltk.classify.maxent.MaxentClassifier.ALGORITHMS">
<tt class="descname">ALGORITHMS</tt><em class="property"> = ['GIS', 'IIS', 'CG', 'BFGS', 'Powell', 'LBFGSB', 'Nelder-Mead', 'MEGAM', 'TADM']</em><a class="headerlink" href="#nltk.classify.maxent.MaxentClassifier.ALGORITHMS" title="Permalink to this definition">¶</a></dt>
<dd><p>A list of the algorithm names that are accepted for the
<tt class="docutils literal"><span class="pre">train()</span></tt> method&#8217;s <tt class="docutils literal"><span class="pre">algorithm</span></tt> parameter.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.MaxentClassifier.classify">
<tt class="descname">classify</tt><big>(</big><em>featureset</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentClassifier.classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentClassifier.classify" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.MaxentClassifier.explain">
<tt class="descname">explain</tt><big>(</big><em>featureset</em>, <em>columns=4</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentClassifier.explain"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentClassifier.explain" title="Permalink to this definition">¶</a></dt>
<dd><p>Print a table showing the effect of each of the features in
the given feature set, and how they combine to determine the
probabilities of each label for that featureset.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.MaxentClassifier.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentClassifier.labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentClassifier.labels" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.MaxentClassifier.prob_classify">
<tt class="descname">prob_classify</tt><big>(</big><em>featureset</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentClassifier.prob_classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentClassifier.prob_classify" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.MaxentClassifier.set_weights">
<tt class="descname">set_weights</tt><big>(</big><em>new_weights</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentClassifier.set_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentClassifier.set_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the feature weight vector for this classifier.
:param new_weights: The new feature weight vector.
:type new_weights: list of float</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.MaxentClassifier.show_most_informative_features">
<tt class="descname">show_most_informative_features</tt><big>(</big><em>n=10</em>, <em>show='all'</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentClassifier.show_most_informative_features"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentClassifier.show_most_informative_features" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>show</strong> &#8211; all, neg, or pos (for negative-only or positive-only)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="classmethod">
<dt id="nltk.classify.maxent.MaxentClassifier.train">
<em class="property">classmethod </em><tt class="descname">train</tt><big>(</big><em>train_toks</em>, <em>algorithm=None</em>, <em>trace=3</em>, <em>encoding=None</em>, <em>labels=None</em>, <em>sparse=True</em>, <em>gaussian_prior_sigma=0</em>, <em>**cutoffs</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentClassifier.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentClassifier.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a new maxent classifier based on the given corpus of
training samples.  This classifier will have its weights
chosen to maximize entropy while remaining empirically
consistent with the training corpus.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first">MaxentClassifier</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">The new maxent classifier</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>train_toks</strong> (<em>list</em>) &#8211; Training data, represented as a list of
pairs, the first member of which is a featureset,
and the second of which is a classification label.</li>
<li><strong>algorithm</strong> (<em>str</em>) &#8211; <p>A case-insensitive string, specifying which
algorithm should be used to train the classifier.  The
following algorithms are currently available.</p>
<ul>
<li>Iterative Scaling Methods: Generalized Iterative Scaling (<tt class="docutils literal"><span class="pre">'GIS'</span></tt>),
Improved Iterative Scaling (<tt class="docutils literal"><span class="pre">'IIS'</span></tt>)</li>
<li>Optimization Methods (requiring scipy): Conjugate gradient (<tt class="docutils literal"><span class="pre">'CG'</span></tt>)
Broyden-Fletcher-Goldfarb-Shanno algorithm (<tt class="docutils literal"><span class="pre">'BFGS'</span></tt>),
Powell algorithm (<tt class="docutils literal"><span class="pre">'Powell'</span></tt>),
A limited-memory variant of the BFGS algorithm (<tt class="docutils literal"><span class="pre">'LBFGSB'</span></tt>),
The Nelder-Mead algorithm (<tt class="docutils literal"><span class="pre">'Nelder-Mead'</span></tt>).</li>
<li>External Libraries (requiring megam):
LM-BFGS algorithm, with training performed by Megam (<tt class="docutils literal"><span class="pre">'megam'</span></tt>)</li>
</ul>
<p>The default algorithm is <tt class="docutils literal"><span class="pre">'CG'</span></tt> if scipy is
installed; and <tt class="docutils literal"><span class="pre">'IIS'</span></tt> otherwise.</p>
</li>
<li><strong>trace</strong> (<em>int</em>) &#8211; The level of diagnostic tracing output to produce.
Higher values produce more verbose output.</li>
<li><strong>encoding</strong> (<em>MaxentFeatureEncodingI</em>) &#8211; A feature encoding, used to convert featuresets
into feature vectors.  If none is specified, then a
<tt class="docutils literal"><span class="pre">BinaryMaxentFeatureEncoding</span></tt> will be built based on the
features that are attested in the training corpus.</li>
<li><strong>labels</strong> (<em>list(str)</em>) &#8211; The set of possible labels.  If none is given, then
the set of all labels attested in the training data will be
used instead.</li>
<li><strong>sparse</strong> &#8211; If True, then use sparse matrices instead of
dense matrices.  Currently, this is only supported by
the scipy (optimization method) algorithms.  For other
algorithms, its value is ignored.</li>
<li><strong>gaussian_prior_sigma</strong> &#8211; The sigma value for a gaussian
prior on model weights.  Currently, this is supported by
the scipy (optimization method) algorithms and <tt class="docutils literal"><span class="pre">megam</span></tt>.
For other algorithms, its value is ignored.</li>
<li><strong>cutoffs</strong> &#8211; <p>Arguments specifying various conditions under
which the training should be halted.  (Some of the cutoff
conditions are not supported by some algorithms.)</p>
<ul>
<li><tt class="docutils literal"><span class="pre">max_iter=v</span></tt>: Terminate after <tt class="docutils literal"><span class="pre">v</span></tt> iterations.</li>
<li><tt class="docutils literal"><span class="pre">min_ll=v</span></tt>: Terminate after the negative average
log-likelihood drops under <tt class="docutils literal"><span class="pre">v</span></tt>.</li>
<li><tt class="docutils literal"><span class="pre">min_lldelta=v</span></tt>: Terminate if a single iteration improves
log likelihood by less than <tt class="docutils literal"><span class="pre">v</span></tt>.</li>
<li><tt class="docutils literal"><span class="pre">tolerance=v</span></tt>: Terminate a scipy optimization method when
improvement drops below a tolerance level <tt class="docutils literal"><span class="pre">v</span></tt>.  The
exact meaning of this tolerance depends on the scipy
algorithm used.  See <tt class="docutils literal"><span class="pre">scipy</span></tt> documentation for more
info.  Default values: 1e-3 for CG, 1e-5 for LBFGSB,
and 1e-4 for other algorithms.  (<tt class="docutils literal"><span class="pre">scipy</span></tt> only)</li>
</ul>
</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.MaxentClassifier.weights">
<tt class="descname">weights</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentClassifier.weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentClassifier.weights" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">The feature weight vector for this classifier.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">list of float</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.classify.maxent.MaxentFeatureEncodingI">
<em class="property">class </em><tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">MaxentFeatureEncodingI</tt><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentFeatureEncodingI"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentFeatureEncodingI" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>A mapping that converts a set of input-feature values to a vector
of joint-feature values, given a label.  This conversion is
necessary to translate featuresets into a format that can be used
by maximum entropy models.</p>
<p>The set of joint-features used by a given encoding is fixed, and
each index in the generated joint-feature vectors corresponds to a
single joint-feature.  The length of the generated joint-feature
vectors is therefore constant (for a given encoding).</p>
<p>Because the joint-feature vectors generated by
<tt class="docutils literal"><span class="pre">MaxentFeatureEncodingI</span></tt> are typically very sparse, they are
represented as a list of <tt class="docutils literal"><span class="pre">(index,</span> <span class="pre">value)</span></tt> tuples, specifying the
value of each non-zero joint-feature.</p>
<p>Feature encodings are generally created using the <tt class="docutils literal"><span class="pre">train()</span></tt>
method, which generates an appropriate encoding based on the
input-feature values and labels that are present in a given
corpus.</p>
<dl class="method">
<dt id="nltk.classify.maxent.MaxentFeatureEncodingI.describe">
<tt class="descname">describe</tt><big>(</big><em>fid</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentFeatureEncodingI.describe"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentFeatureEncodingI.describe" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">A string describing the value of the joint-feature
whose index in the generated feature vectors is <tt class="docutils literal"><span class="pre">fid</span></tt>.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">str</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.MaxentFeatureEncodingI.encode">
<tt class="descname">encode</tt><big>(</big><em>featureset</em>, <em>label</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentFeatureEncodingI.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentFeatureEncodingI.encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a (featureset, label) pair, return the corresponding
vector of joint-feature values.  This vector is represented as
a list of <tt class="docutils literal"><span class="pre">(index,</span> <span class="pre">value)</span></tt> tuples, specifying the value of
each non-zero joint-feature.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">list(tuple(int, int))</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.MaxentFeatureEncodingI.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentFeatureEncodingI.labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentFeatureEncodingI.labels" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">A list of the &#8220;known labels&#8221; &#8211; i.e., all labels
<tt class="docutils literal"><span class="pre">l</span></tt> such that <tt class="docutils literal"><span class="pre">self.encode(fs,l)</span></tt> can be a nonzero
joint-feature vector for some value of <tt class="docutils literal"><span class="pre">fs</span></tt>.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">list</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.MaxentFeatureEncodingI.length">
<tt class="descname">length</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentFeatureEncodingI.length"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentFeatureEncodingI.length" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">The size of the fixed-length joint-feature vectors
that are generated by this encoding.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">int</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.MaxentFeatureEncodingI.train">
<tt class="descname">train</tt><big>(</big><em>train_toks</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentFeatureEncodingI.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentFeatureEncodingI.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct and return new feature encoding, based on a given
training corpus <tt class="docutils literal"><span class="pre">train_toks</span></tt>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>train_toks</strong> (<em>list(tuple(dict, str))</em>) &#8211; Training data, represented as a list of
pairs, the first member of which is a feature dictionary,
and the second of which is a classification label.</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.classify.maxent.TadmEventMaxentFeatureEncoding">
<em class="property">class </em><tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">TadmEventMaxentFeatureEncoding</tt><big>(</big><em>labels</em>, <em>mapping</em>, <em>unseen_features=False</em>, <em>alwayson_features=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TadmEventMaxentFeatureEncoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TadmEventMaxentFeatureEncoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.maxent.BinaryMaxentFeatureEncoding" title="nltk.classify.maxent.BinaryMaxentFeatureEncoding"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.maxent.BinaryMaxentFeatureEncoding</span></tt></a></p>
<dl class="method">
<dt id="nltk.classify.maxent.TadmEventMaxentFeatureEncoding.describe">
<tt class="descname">describe</tt><big>(</big><em>fid</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TadmEventMaxentFeatureEncoding.describe"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TadmEventMaxentFeatureEncoding.describe" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.TadmEventMaxentFeatureEncoding.encode">
<tt class="descname">encode</tt><big>(</big><em>featureset</em>, <em>label</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TadmEventMaxentFeatureEncoding.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TadmEventMaxentFeatureEncoding.encode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.TadmEventMaxentFeatureEncoding.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TadmEventMaxentFeatureEncoding.labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TadmEventMaxentFeatureEncoding.labels" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.TadmEventMaxentFeatureEncoding.length">
<tt class="descname">length</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TadmEventMaxentFeatureEncoding.length"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TadmEventMaxentFeatureEncoding.length" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="classmethod">
<dt id="nltk.classify.maxent.TadmEventMaxentFeatureEncoding.train">
<em class="property">classmethod </em><tt class="descname">train</tt><big>(</big><em>train_toks</em>, <em>count_cutoff=0</em>, <em>labels=None</em>, <em>**options</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TadmEventMaxentFeatureEncoding.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TadmEventMaxentFeatureEncoding.train" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.classify.maxent.TadmMaxentClassifier">
<em class="property">class </em><tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">TadmMaxentClassifier</tt><big>(</big><em>encoding</em>, <em>weights</em>, <em>logarithmic=True</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TadmMaxentClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TadmMaxentClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.maxent.MaxentClassifier" title="nltk.classify.maxent.MaxentClassifier"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.maxent.MaxentClassifier</span></tt></a></p>
<dl class="classmethod">
<dt id="nltk.classify.maxent.TadmMaxentClassifier.train">
<em class="property">classmethod </em><tt class="descname">train</tt><big>(</big><em>train_toks</em>, <em>**kwargs</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TadmMaxentClassifier.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TadmMaxentClassifier.train" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.classify.maxent.TypedMaxentFeatureEncoding">
<em class="property">class </em><tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">TypedMaxentFeatureEncoding</tt><big>(</big><em>labels</em>, <em>mapping</em>, <em>unseen_features=False</em>, <em>alwayson_features=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TypedMaxentFeatureEncoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TypedMaxentFeatureEncoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.maxent.MaxentFeatureEncodingI" title="nltk.classify.maxent.MaxentFeatureEncodingI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.maxent.MaxentFeatureEncodingI</span></tt></a></p>
<p>A feature encoding that generates vectors containing integer,
float and binary joint-features of the form:</p>
<p>Binary (for string and boolean features):</p>
<div class="line-block">
<div class="line">joint_feat(fs, l) = { 1 if (fs[fname] == fval) and (l == label)</div>
<div class="line-block">
<div class="line">{</div>
<div class="line">{ 0 otherwise</div>
</div>
</div>
<p>Value (for integer and float features):</p>
<div class="line-block">
<div class="line">joint_feat(fs, l) = { fval if     (fs[fname] == type(fval))</div>
<div class="line-block">
<div class="line">{         and (l == label)</div>
<div class="line">{</div>
<div class="line">{ not encoded otherwise</div>
</div>
</div>
<p>Where <tt class="docutils literal"><span class="pre">fname</span></tt> is the name of an input-feature, <tt class="docutils literal"><span class="pre">fval</span></tt> is a value
for that input-feature, and <tt class="docutils literal"><span class="pre">label</span></tt> is a label.</p>
<p>Typically, these features are constructed based on a training
corpus, using the <tt class="docutils literal"><span class="pre">train()</span></tt> method.</p>
<p>For string and boolean features [type(fval) not in (int, float)]
this method will create one feature for each combination of
<tt class="docutils literal"><span class="pre">fname</span></tt>, <tt class="docutils literal"><span class="pre">fval</span></tt>, and <tt class="docutils literal"><span class="pre">label</span></tt> that occurs at least once in the
training corpus.</p>
<p>For integer and float features [type(fval) in (int, float)] this
method will create one feature for each combination of <tt class="docutils literal"><span class="pre">fname</span></tt>
and <tt class="docutils literal"><span class="pre">label</span></tt> that occurs at least once in the training corpus.</p>
<p>For binary features the <tt class="docutils literal"><span class="pre">unseen_features</span></tt> parameter can be used
to add &#8220;unseen-value features&#8221;, which are used whenever an input
feature has a value that was not encountered in the training
corpus.  These features have the form:</p>
<div class="line-block">
<div class="line">joint_feat(fs, l) = { 1 if is_unseen(fname, fs[fname])</div>
<div class="line-block">
<div class="line">{      and l == label</div>
<div class="line">{</div>
<div class="line">{ 0 otherwise</div>
</div>
</div>
<p>Where <tt class="docutils literal"><span class="pre">is_unseen(fname,</span> <span class="pre">fval)</span></tt> is true if the encoding does not
contain any joint features that are true when <tt class="docutils literal"><span class="pre">fs[fname]==fval</span></tt>.</p>
<p>The <tt class="docutils literal"><span class="pre">alwayson_features</span></tt> parameter can be used to add &#8220;always-on
features&#8221;, which have the form:</p>
<div class="line-block">
<div class="line">joint_feat(fs, l) = { 1 if (l == label)</div>
<div class="line-block">
<div class="line">{</div>
<div class="line">{ 0 otherwise</div>
</div>
</div>
<p>These always-on features allow the maxent model to directly model
the prior probabilities of each label.</p>
<dl class="method">
<dt id="nltk.classify.maxent.TypedMaxentFeatureEncoding.describe">
<tt class="descname">describe</tt><big>(</big><em>f_id</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TypedMaxentFeatureEncoding.describe"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TypedMaxentFeatureEncoding.describe" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.TypedMaxentFeatureEncoding.encode">
<tt class="descname">encode</tt><big>(</big><em>featureset</em>, <em>label</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TypedMaxentFeatureEncoding.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TypedMaxentFeatureEncoding.encode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.TypedMaxentFeatureEncoding.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TypedMaxentFeatureEncoding.labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TypedMaxentFeatureEncoding.labels" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.TypedMaxentFeatureEncoding.length">
<tt class="descname">length</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TypedMaxentFeatureEncoding.length"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TypedMaxentFeatureEncoding.length" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="classmethod">
<dt id="nltk.classify.maxent.TypedMaxentFeatureEncoding.train">
<em class="property">classmethod </em><tt class="descname">train</tt><big>(</big><em>train_toks</em>, <em>count_cutoff=0</em>, <em>labels=None</em>, <em>**options</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TypedMaxentFeatureEncoding.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TypedMaxentFeatureEncoding.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct and return new feature encoding, based on a given
training corpus <tt class="docutils literal"><span class="pre">train_toks</span></tt>.  See the class description
<tt class="docutils literal"><span class="pre">TypedMaxentFeatureEncoding</span></tt> for a description of the
joint-features that will be included in this encoding.</p>
<p>Note: recognized feature values types are (int, float), over
types are interpreted as regular binary features.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>train_toks</strong> (<em>list(tuple(dict, str))</em>) &#8211; Training data, represented as a list of
pairs, the first member of which is a feature dictionary,
and the second of which is a classification label.</li>
<li><strong>count_cutoff</strong> (<em>int</em>) &#8211; A cutoff value that is used to discard
rare joint-features.  If a joint-feature&#8217;s value is 1
fewer than <tt class="docutils literal"><span class="pre">count_cutoff</span></tt> times in the training corpus,
then that joint-feature is not included in the generated
encoding.</li>
<li><strong>labels</strong> (<em>list</em>) &#8211; A list of labels that should be used by the
classifier.  If not specified, then the set of labels
attested in <tt class="docutils literal"><span class="pre">train_toks</span></tt> will be used.</li>
<li><strong>options</strong> &#8211; Extra parameters for the constructor, such as
<tt class="docutils literal"><span class="pre">unseen_features</span></tt> and <tt class="docutils literal"><span class="pre">alwayson_features</span></tt>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="nltk.classify.maxent.calculate_deltas">
<tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">calculate_deltas</tt><big>(</big><em>train_toks</em>, <em>classifier</em>, <em>unattested</em>, <em>ffreq_empirical</em>, <em>nfmap</em>, <em>nfarray</em>, <em>nftranspose</em>, <em>encoding</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#calculate_deltas"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.calculate_deltas" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the update values for the classifier weights for
this iteration of IIS.  These update weights are the value of
<tt class="docutils literal"><span class="pre">delta</span></tt> that solves the equation:</p>
<div class="highlight-python"><pre>ffreq_empirical[i]
       =
SUM[fs,l] (classifier.prob_classify(fs).prob(l) *
           feature_vector(fs,l)[i] *
           exp(delta[i] * nf(feature_vector(fs,l))))</pre>
</div>
<dl class="docutils">
<dt>Where:</dt>
<dd><ul class="first last simple">
<li><em>(fs,l)</em> is a (featureset, label) tuple from <tt class="docutils literal"><span class="pre">train_toks</span></tt></li>
<li><em>feature_vector(fs,l)</em> = <tt class="docutils literal"><span class="pre">encoding.encode(fs,l)</span></tt></li>
<li><em>nf(vector)</em> = <tt class="docutils literal"><span class="pre">sum([val</span> <span class="pre">for</span> <span class="pre">(id,val)</span> <span class="pre">in</span> <span class="pre">vector])</span></tt></li>
</ul>
</dd>
</dl>
<p>This method uses Newton&#8217;s method to solve this equation for
<em>delta[i]</em>.  In particular, it starts with a guess of
<tt class="docutils literal"><span class="pre">delta[i]</span></tt> = 1; and iteratively updates <tt class="docutils literal"><span class="pre">delta</span></tt> with:</p>
<div class="line-block">
<div class="line">delta[i] -= (ffreq_empirical[i] - sum1[i])/(-sum2[i])</div>
</div>
<p>until convergence, where <em>sum1</em> and <em>sum2</em> are defined as:</p>
<div class="line-block">
<div class="line">sum1[i](delta) = SUM[fs,l] f[i](fs,l,delta)</div>
<div class="line">sum2[i](delta) = SUM[fs,l] (f[i](fs,l,delta).nf(feature_vector(fs,l)))</div>
<div class="line">f[i](fs,l,delta) = (classifier.prob_classify(fs).prob(l) .</div>
<div class="line-block">
<div class="line">feature_vector(fs,l)[i] .</div>
<div class="line">exp(delta[i] . nf(feature_vector(fs,l))))</div>
</div>
</div>
<p>Note that <em>sum1</em> and <em>sum2</em> depend on <tt class="docutils literal"><span class="pre">delta</span></tt>; so they need
to be re-computed each iteration.</p>
<p>The variables <tt class="docutils literal"><span class="pre">nfmap</span></tt>, <tt class="docutils literal"><span class="pre">nfarray</span></tt>, and <tt class="docutils literal"><span class="pre">nftranspose</span></tt> are
used to generate a dense encoding for <em>nf(ltext)</em>.  This
allows <tt class="docutils literal"><span class="pre">_deltas</span></tt> to calculate <em>sum1</em> and <em>sum2</em> using
matrices, which yields a significant performance improvement.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>train_toks</strong> (<em>list(tuple(dict, str))</em>) &#8211; The set of training tokens.</li>
<li><strong>classifier</strong> (<em>ClassifierI</em>) &#8211; The current classifier.</li>
<li><strong>ffreq_empirical</strong> (<em>sequence of float</em>) &#8211; An array containing the empirical
frequency for each feature.  The <em>i</em>th element of this
array is the empirical frequency for feature <em>i</em>.</li>
<li><strong>unattested</strong> (<em>sequence of int</em>) &#8211; An array that is 1 for features that are
not attested in the training data; and 0 for features that
are attested.  In other words, <tt class="docutils literal"><span class="pre">unattested[i]==0</span></tt> iff
<tt class="docutils literal"><span class="pre">ffreq_empirical[i]==0</span></tt>.</li>
<li><strong>nfmap</strong> (<em>dict(int -&gt; int)</em>) &#8211; A map that can be used to compress <tt class="docutils literal"><span class="pre">nf</span></tt> to a dense
vector.</li>
<li><strong>nfarray</strong> (<em>array(float)</em>) &#8211; An array that can be used to uncompress <tt class="docutils literal"><span class="pre">nf</span></tt>
from a dense vector.</li>
<li><strong>nftranspose</strong> (<em>array(float)</em>) &#8211; The transpose of <tt class="docutils literal"><span class="pre">nfarray</span></tt></li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.maxent.calculate_empirical_fcount">
<tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">calculate_empirical_fcount</tt><big>(</big><em>train_toks</em>, <em>encoding</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#calculate_empirical_fcount"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.calculate_empirical_fcount" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.maxent.calculate_estimated_fcount">
<tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">calculate_estimated_fcount</tt><big>(</big><em>classifier</em>, <em>train_toks</em>, <em>encoding</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#calculate_estimated_fcount"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.calculate_estimated_fcount" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.maxent.calculate_nfmap">
<tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">calculate_nfmap</tt><big>(</big><em>train_toks</em>, <em>encoding</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#calculate_nfmap"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.calculate_nfmap" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct a map that can be used to compress <tt class="docutils literal"><span class="pre">nf</span></tt> (which is
typically sparse).</p>
<p><em>nf(feature_vector)</em> is the sum of the feature values for
<em>feature_vector</em>.</p>
<p>This represents the number of features that are active for a
given labeled text.  This method finds all values of <em>nf(t)</em>
that are attested for at least one token in the given list of
training tokens; and constructs a dictionary mapping these
attested values to a continuous range <em>0...N</em>.  For example,
if the only values of <em>nf()</em> that were attested were 3, 5, and
7, then <tt class="docutils literal"><span class="pre">_nfmap</span></tt> might return the dictionary <tt class="docutils literal"><span class="pre">{3:0,</span> <span class="pre">5:1,</span> <span class="pre">7:2}</span></tt>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">A map that can be used to compress <tt class="docutils literal"><span class="pre">nf</span></tt> to a dense
vector.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict(int -&gt; int)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.maxent.demo">
<tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">demo</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.demo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.maxent.train_maxent_classifier_with_gis">
<tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">train_maxent_classifier_with_gis</tt><big>(</big><em>train_toks</em>, <em>trace=3</em>, <em>encoding=None</em>, <em>labels=None</em>, <em>**cutoffs</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#train_maxent_classifier_with_gis"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.train_maxent_classifier_with_gis" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a new <tt class="docutils literal"><span class="pre">ConditionalExponentialClassifier</span></tt>, using the given
training samples, using the Generalized Iterative Scaling
algorithm.  This <tt class="docutils literal"><span class="pre">ConditionalExponentialClassifier</span></tt> will encode
the model that maximizes entropy from all the models that are
empirically consistent with <tt class="docutils literal"><span class="pre">train_toks</span></tt>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">See :</th><td class="field-body"><tt class="docutils literal"><span class="pre">train_maxent_classifier()</span></tt> for parameter descriptions.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.maxent.train_maxent_classifier_with_iis">
<tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">train_maxent_classifier_with_iis</tt><big>(</big><em>train_toks</em>, <em>trace=3</em>, <em>encoding=None</em>, <em>labels=None</em>, <em>**cutoffs</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#train_maxent_classifier_with_iis"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.train_maxent_classifier_with_iis" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a new <tt class="docutils literal"><span class="pre">ConditionalExponentialClassifier</span></tt>, using the given
training samples, using the Improved Iterative Scaling algorithm.
This <tt class="docutils literal"><span class="pre">ConditionalExponentialClassifier</span></tt> will encode the model
that maximizes entropy from all the models that are empirically
consistent with <tt class="docutils literal"><span class="pre">train_toks</span></tt>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">See :</th><td class="field-body"><tt class="docutils literal"><span class="pre">train_maxent_classifier()</span></tt> for parameter descriptions.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.maxent.train_maxent_classifier_with_megam">
<tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">train_maxent_classifier_with_megam</tt><big>(</big><em>train_toks</em>, <em>trace=3</em>, <em>encoding=None</em>, <em>labels=None</em>, <em>gaussian_prior_sigma=0</em>, <em>**kwargs</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#train_maxent_classifier_with_megam"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.train_maxent_classifier_with_megam" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a new <tt class="docutils literal"><span class="pre">ConditionalExponentialClassifier</span></tt>, using the given
training samples, using the external <tt class="docutils literal"><span class="pre">megam</span></tt> library.  This
<tt class="docutils literal"><span class="pre">ConditionalExponentialClassifier</span></tt> will encode the model that
maximizes entropy from all the models that are empirically
consistent with <tt class="docutils literal"><span class="pre">train_toks</span></tt>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">See :</th><td class="field-body"><tt class="docutils literal"><span class="pre">train_maxent_classifier()</span></tt> for parameter descriptions.</td>
</tr>
<tr class="field-even field"><th class="field-name">See :</th><td class="field-body"><tt class="docutils literal"><span class="pre">nltk.classify.megam</span></tt></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.maxent.train_maxent_classifier_with_scipy">
<tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">train_maxent_classifier_with_scipy</tt><big>(</big><em>train_toks</em>, <em>trace=3</em>, <em>encoding=None</em>, <em>labels=None</em>, <em>algorithm='CG'</em>, <em>sparse=True</em>, <em>gaussian_prior_sigma=0</em>, <em>**cutoffs</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#train_maxent_classifier_with_scipy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.train_maxent_classifier_with_scipy" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a new <tt class="docutils literal"><span class="pre">ConditionalExponentialClassifier</span></tt>, using the given
training samples, using the specified <tt class="docutils literal"><span class="pre">scipy</span></tt> optimization
algorithm.  This <tt class="docutils literal"><span class="pre">ConditionalExponentialClassifier</span></tt> will encode
the model that maximizes entropy from all the models that are
empirically consistent with <tt class="docutils literal"><span class="pre">train_toks</span></tt>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">See :</th><td class="field-body"><tt class="docutils literal"><span class="pre">train_maxent_classifier()</span></tt> for parameter descriptions.</td>
</tr>
<tr class="field-even field"><th class="field-name">Require :</th><td class="field-body">The <tt class="docutils literal"><span class="pre">scipy</span></tt> package must be installed.</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
</div>
</div>
<div class="section" id="module-nltk.classify.megam">
<span id="megam-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">megam</span></tt> Module<a class="headerlink" href="#module-nltk.classify.megam" title="Permalink to this headline">¶</a></h2>
<p>A set of functions used to interface with the external <a class="reference external" href="http://www.cs.utah.edu/~hal/megam/">megam</a> maxent
optimization package. Before megam can be used, you should tell NLTK where it
can find the megam binary, using the <tt class="docutils literal"><span class="pre">config_megam()</span></tt> function. Typical
usage:</p>
<p>Use with MaxentClassifier. Example below, see MaxentClassifier documentation
for details.</p>
<blockquote>
<div>nltk.classify.MaxentClassifier.train(corpus, &#8216;megam&#8217;)</div></blockquote>
<dl class="function">
<dt id="nltk.classify.megam.call_megam">
<tt class="descclassname">nltk.classify.megam.</tt><tt class="descname">call_megam</tt><big>(</big><em>args</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/megam.html#call_megam"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.megam.call_megam" title="Permalink to this definition">¶</a></dt>
<dd><p>Call the <tt class="docutils literal"><span class="pre">megam</span></tt> binary with the given arguments.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.megam.config_megam">
<tt class="descclassname">nltk.classify.megam.</tt><tt class="descname">config_megam</tt><big>(</big><em>bin=None</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/megam.html#config_megam"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.megam.config_megam" title="Permalink to this definition">¶</a></dt>
<dd><p>Configure NLTK&#8217;s interface to the <tt class="docutils literal"><span class="pre">megam</span></tt> maxent optimization
package.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>bin</strong> (<em>str</em>) &#8211; The full path to the <tt class="docutils literal"><span class="pre">megam</span></tt> binary.  If not specified,
then nltk will search the system for a <tt class="docutils literal"><span class="pre">megam</span></tt> binary; and if
one is not found, it will raise a <tt class="docutils literal"><span class="pre">LookupError</span></tt> exception.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.megam.parse_megam_weights">
<tt class="descclassname">nltk.classify.megam.</tt><tt class="descname">parse_megam_weights</tt><big>(</big><em>s</em>, <em>features_count</em>, <em>explicit=True</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/megam.html#parse_megam_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.megam.parse_megam_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Given the stdout output generated by <tt class="docutils literal"><span class="pre">megam</span></tt> when training a
model, return a <tt class="docutils literal"><span class="pre">numpy</span></tt> array containing the corresponding weight
vector.  This function does not currently handle bias features.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.megam.write_megam_file">
<tt class="descclassname">nltk.classify.megam.</tt><tt class="descname">write_megam_file</tt><big>(</big><em>train_toks</em>, <em>encoding</em>, <em>stream</em>, <em>bernoulli=True</em>, <em>explicit=True</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/megam.html#write_megam_file"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.megam.write_megam_file" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate an input file for <tt class="docutils literal"><span class="pre">megam</span></tt> based on the given corpus of
classified tokens.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>train_toks</strong> (<em>list(tuple(dict, str))</em>) &#8211; Training data, represented as a list of
pairs, the first member of which is a feature dictionary,
and the second of which is a classification label.</li>
<li><strong>encoding</strong> (<em>MaxentFeatureEncodingI</em>) &#8211; A feature encoding, used to convert featuresets
into feature vectors. May optionally implement a cost() method
in order to assign different costs to different class predictions.</li>
<li><strong>stream</strong> (<em>stream</em>) &#8211; The stream to which the megam input file should be
written.</li>
<li><strong>bernoulli</strong> &#8211; If true, then use the &#8216;bernoulli&#8217; format.  I.e.,
all joint features have binary values, and are listed iff they
are true.  Otherwise, list feature values explicitly.  If
<tt class="docutils literal"><span class="pre">bernoulli=False</span></tt>, then you must call <tt class="docutils literal"><span class="pre">megam</span></tt> with the
<tt class="docutils literal"><span class="pre">-fvals</span></tt> option.</li>
<li><strong>explicit</strong> &#8211; If true, then use the &#8216;explicit&#8217; format.  I.e.,
list the features that would fire for any of the possible
labels, for each token.  If <tt class="docutils literal"><span class="pre">explicit=True</span></tt>, then you must
call <tt class="docutils literal"><span class="pre">megam</span></tt> with the <tt class="docutils literal"><span class="pre">-explicit</span></tt> option.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-nltk.classify.naivebayes">
<span id="naivebayes-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">naivebayes</span></tt> Module<a class="headerlink" href="#module-nltk.classify.naivebayes" title="Permalink to this headline">¶</a></h2>
<p>A classifier based on the Naive Bayes algorithm.  In order to find the
probability for a label, this algorithm first uses the Bayes rule to
express P(label|features) in terms of P(label) and P(features|label):</p>
<div class="line-block">
<div class="line-block">
<div class="line">P(label) * P(features|label)</div>
</div>
<div class="line">P(label|features) = &#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;</div>
<div class="line-block">
<div class="line">P(features)</div>
</div>
</div>
<p>The algorithm then makes the &#8216;naive&#8217; assumption that all features are
independent, given the label:</p>
<div class="line-block">
<div class="line-block">
<div class="line">P(label) * P(f1|label) * ... * P(fn|label)</div>
</div>
<div class="line">P(label|features) = &#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8211;</div>
<div class="line-block">
<div class="line">P(features)</div>
</div>
</div>
<p>Rather than computing P(featues) explicitly, the algorithm just
calculates the denominator for each label, and normalizes them so they
sum to one:</p>
<div class="line-block">
<div class="line-block">
<div class="line">P(label) * P(f1|label) * ... * P(fn|label)</div>
</div>
<div class="line">P(label|features) = &#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8211;</div>
<div class="line-block">
<div class="line">SUM[l]( P(l) * P(f1|l) * ... * P(fn|l) )</div>
</div>
</div>
<dl class="class">
<dt id="nltk.classify.naivebayes.NaiveBayesClassifier">
<em class="property">class </em><tt class="descclassname">nltk.classify.naivebayes.</tt><tt class="descname">NaiveBayesClassifier</tt><big>(</big><em>label_probdist</em>, <em>feature_probdist</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/naivebayes.html#NaiveBayesClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.naivebayes.NaiveBayesClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.api.ClassifierI" title="nltk.classify.api.ClassifierI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.api.ClassifierI</span></tt></a></p>
<p>A Naive Bayes classifier.  Naive Bayes classifiers are
paramaterized by two probability distributions:</p>
<blockquote>
<div><ul class="simple">
<li>P(label) gives the probability that an input will receive each
label, given no information about the input&#8217;s features.</li>
<li>P(fname=fval|label) gives the probability that a given feature
(fname) will receive a given value (fval), given that the
label (label).</li>
</ul>
</div></blockquote>
<p>If the classifier encounters an input with a feature that has
never been seen with any label, then rather than assigning a
probability of 0 to all labels, it will ignore that feature.</p>
<p>The feature value &#8216;None&#8217; is reserved for unseen feature values;
you generally should not use &#8216;None&#8217; as a feature value for one of
your own features.</p>
<dl class="method">
<dt id="nltk.classify.naivebayes.NaiveBayesClassifier.classify">
<tt class="descname">classify</tt><big>(</big><em>featureset</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/naivebayes.html#NaiveBayesClassifier.classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.naivebayes.NaiveBayesClassifier.classify" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.naivebayes.NaiveBayesClassifier.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/naivebayes.html#NaiveBayesClassifier.labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.naivebayes.NaiveBayesClassifier.labels" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.naivebayes.NaiveBayesClassifier.most_informative_features">
<tt class="descname">most_informative_features</tt><big>(</big><em>n=100</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/naivebayes.html#NaiveBayesClassifier.most_informative_features"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.naivebayes.NaiveBayesClassifier.most_informative_features" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a list of the &#8216;most informative&#8217; features used by this
classifier.  For the purpose of this function, the
informativeness of a feature <tt class="docutils literal"><span class="pre">(fname,fval)</span></tt> is equal to the
highest value of P(fname=fval|label), for any label, divided by
the lowest value of P(fname=fval|label), for any label:</p>
<div class="line-block">
<div class="line">max[ P(fname=fval|label1) / P(fname=fval|label2) ]</div>
</div>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.naivebayes.NaiveBayesClassifier.prob_classify">
<tt class="descname">prob_classify</tt><big>(</big><em>featureset</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/naivebayes.html#NaiveBayesClassifier.prob_classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.naivebayes.NaiveBayesClassifier.prob_classify" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.naivebayes.NaiveBayesClassifier.show_most_informative_features">
<tt class="descname">show_most_informative_features</tt><big>(</big><em>n=10</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/naivebayes.html#NaiveBayesClassifier.show_most_informative_features"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.naivebayes.NaiveBayesClassifier.show_most_informative_features" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="nltk.classify.naivebayes.NaiveBayesClassifier.train">
<em class="property">static </em><tt class="descname">train</tt><big>(</big><em>labeled_featuresets</em>, <em>estimator=&lt;class 'nltk.probability.ELEProbDist'&gt;</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/naivebayes.html#NaiveBayesClassifier.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.naivebayes.NaiveBayesClassifier.train" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>labeled_featuresets</strong> &#8211; A list of classified featuresets,</td>
</tr>
</tbody>
</table>
<p>i.e., a list of tuples <tt class="docutils literal"><span class="pre">(featureset,</span> <span class="pre">label)</span></tt>.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="nltk.classify.naivebayes.demo">
<tt class="descclassname">nltk.classify.naivebayes.</tt><tt class="descname">demo</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/naivebayes.html#demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.naivebayes.demo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-nltk.classify.positivenaivebayes">
<span id="positivenaivebayes-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">positivenaivebayes</span></tt> Module<a class="headerlink" href="#module-nltk.classify.positivenaivebayes" title="Permalink to this headline">¶</a></h2>
<p>A variant of the Naive Bayes Classifier that performs binary classification with
partially-labeled training sets. In other words, assume we want to build a classifier
that assigns each example to one of two complementary classes (e.g., male names and
female names).
If we have a training set with labeled examples for both classes, we can use a
standard Naive Bayes Classifier. However, consider the case when we only have labeled
examples for one of the classes, and other, unlabeled, examples.
Then, assuming a prior distribution on the two labels, we can use the unlabeled set
to estimate the frequencies of the various features.</p>
<p>Let the two possible labels be 1 and 0, and let&#8217;s say we only have examples labeled 1
and unlabeled examples. We are also given an estimate of P(1).</p>
<p>We compute P(feature|1) exactly as in the standard case.</p>
<p>To compute P(feature|0), we first estimate P(feature) from the unlabeled set (we are
assuming that the unlabeled examples are drawn according to the given prior distribution)
and then express the conditional probability as:</p>
<div class="line-block">
<div class="line-block">
<div class="line">P(feature) - P(feature|1) * P(1)</div>
</div>
<div class="line">P(feature|0) = &#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-</div>
<div class="line-block">
<div class="line">P(0)</div>
</div>
</div>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nltk.classify</span> <span class="kn">import</span> <span class="n">PositiveNaiveBayesClassifier</span>
</pre></div>
</div>
<p>Some sentences about sports:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">sports_sentences</span> <span class="o">=</span> <span class="p">[</span> <span class="s">&#39;The team dominated the game&#39;</span><span class="p">,</span>
<span class="gp">... </span>                     <span class="s">&#39;They lost the ball&#39;</span><span class="p">,</span>
<span class="gp">... </span>                     <span class="s">&#39;The game was intense&#39;</span><span class="p">,</span>
<span class="gp">... </span>                     <span class="s">&#39;The goalkeeper catched the ball&#39;</span><span class="p">,</span>
<span class="gp">... </span>                     <span class="s">&#39;The other team controlled the ball&#39;</span> <span class="p">]</span>
</pre></div>
</div>
<p>Mixed topics, including sports:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">various_sentences</span> <span class="o">=</span> <span class="p">[</span> <span class="s">&#39;The President did not comment&#39;</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="s">&#39;I lost the keys&#39;</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="s">&#39;The team won the game&#39;</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="s">&#39;Sara has two kids&#39;</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="s">&#39;The ball went off the court&#39;</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="s">&#39;They had the ball for the whole game&#39;</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="s">&#39;The show is over&#39;</span> <span class="p">]</span>
</pre></div>
</div>
<p>The features of a sentence are simply the words it contains:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">features</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">words</span> <span class="o">=</span> <span class="n">sentence</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="nb">dict</span><span class="p">((</span><span class="s">&#39;contains(</span><span class="si">%s</span><span class="s">)&#39;</span> <span class="o">%</span> <span class="n">w</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">)</span>
</pre></div>
</div>
<p>We use the sports sentences as positive examples, the mixed ones ad unlabeled examples:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">positive_featuresets</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">sports_sentences</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">unlabeled_featuresets</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">various_sentences</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">classifier</span> <span class="o">=</span> <span class="n">PositiveNaiveBayesClassifier</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">positive_featuresets</span><span class="p">,</span>
<span class="gp">... </span>                                                <span class="n">unlabeled_featuresets</span><span class="p">)</span>
</pre></div>
</div>
<p>Is the following sentence about sports?</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">classifier</span><span class="o">.</span><span class="n">classify</span><span class="p">(</span><span class="n">features</span><span class="p">(</span><span class="s">&#39;The cat is on the table&#39;</span><span class="p">))</span>
<span class="go">False</span>
</pre></div>
</div>
<p>What about this one?</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">classifier</span><span class="o">.</span><span class="n">classify</span><span class="p">(</span><span class="n">features</span><span class="p">(</span><span class="s">&#39;My team lost the game&#39;</span><span class="p">))</span>
<span class="go">True</span>
</pre></div>
</div>
<dl class="class">
<dt id="nltk.classify.positivenaivebayes.PositiveNaiveBayesClassifier">
<em class="property">class </em><tt class="descclassname">nltk.classify.positivenaivebayes.</tt><tt class="descname">PositiveNaiveBayesClassifier</tt><big>(</big><em>label_probdist</em>, <em>feature_probdist</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/positivenaivebayes.html#PositiveNaiveBayesClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.positivenaivebayes.PositiveNaiveBayesClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.naivebayes.NaiveBayesClassifier" title="nltk.classify.naivebayes.NaiveBayesClassifier"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.naivebayes.NaiveBayesClassifier</span></tt></a></p>
<dl class="staticmethod">
<dt id="nltk.classify.positivenaivebayes.PositiveNaiveBayesClassifier.train">
<em class="property">static </em><tt class="descname">train</tt><big>(</big><em>positive_featuresets</em>, <em>unlabeled_featuresets</em>, <em>positive_prob_prior=0.5</em>, <em>estimator=&lt;class 'nltk.probability.ELEProbDist'&gt;</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/positivenaivebayes.html#PositiveNaiveBayesClassifier.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.positivenaivebayes.PositiveNaiveBayesClassifier.train" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>positive_featuresets</strong> &#8211; A list of featuresets that are known as positive
examples (i.e., their label is <tt class="docutils literal"><span class="pre">True</span></tt>).</li>
<li><strong>unlabeled_featuresets</strong> &#8211; A list of featuresets whose label is unknown.</li>
<li><strong>positive_prob_prior</strong> &#8211; A prior estimate of the probability of the label
<tt class="docutils literal"><span class="pre">True</span></tt> (default 0.5).</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="nltk.classify.positivenaivebayes.demo">
<tt class="descclassname">nltk.classify.positivenaivebayes.</tt><tt class="descname">demo</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/positivenaivebayes.html#demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.positivenaivebayes.demo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-nltk.classify.rte_classify">
<span id="rte-classify-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">rte_classify</span></tt> Module<a class="headerlink" href="#module-nltk.classify.rte_classify" title="Permalink to this headline">¶</a></h2>
<p>Simple classifier for RTE corpus.</p>
<p>It calculates the overlap in words and named entities between text and
hypothesis, and also whether there are words / named entities in the
hypothesis which fail to occur in the text, since this is an indicator that
the hypothesis is more informative than (i.e not entailed by) the text.</p>
<p>TO DO: better Named Entity classification
TO DO: add lemmatization</p>
<dl class="class">
<dt id="nltk.classify.rte_classify.RTEFeatureExtractor">
<em class="property">class </em><tt class="descclassname">nltk.classify.rte_classify.</tt><tt class="descname">RTEFeatureExtractor</tt><big>(</big><em>rtepair</em>, <em>stop=True</em>, <em>lemmatize=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/rte_classify.html#RTEFeatureExtractor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.rte_classify.RTEFeatureExtractor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>This builds a bag of words for both the text and the hypothesis after
throwing away some stopwords, then calculates overlap and difference.</p>
<dl class="method">
<dt id="nltk.classify.rte_classify.RTEFeatureExtractor.hyp_extra">
<tt class="descname">hyp_extra</tt><big>(</big><em>toktype</em>, <em>debug=True</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/rte_classify.html#RTEFeatureExtractor.hyp_extra"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.rte_classify.RTEFeatureExtractor.hyp_extra" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the extraneous material in the hypothesis.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>toktype</strong> (<em>&#8216;ne&#8217; or &#8216;word&#8217;</em>) &#8211; distinguish Named Entities from ordinary words</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.rte_classify.RTEFeatureExtractor.overlap">
<tt class="descname">overlap</tt><big>(</big><em>toktype</em>, <em>debug=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/rte_classify.html#RTEFeatureExtractor.overlap"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.rte_classify.RTEFeatureExtractor.overlap" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the overlap between text and hypothesis.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>toktype</strong> (<em>&#8216;ne&#8217; or &#8216;word&#8217;</em>) &#8211; distinguish Named Entities from ordinary words</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="nltk.classify.rte_classify.demo">
<tt class="descclassname">nltk.classify.rte_classify.</tt><tt class="descname">demo</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/rte_classify.html#demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.rte_classify.demo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.rte_classify.demo_feature_extractor">
<tt class="descclassname">nltk.classify.rte_classify.</tt><tt class="descname">demo_feature_extractor</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/rte_classify.html#demo_feature_extractor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.rte_classify.demo_feature_extractor" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.rte_classify.demo_features">
<tt class="descclassname">nltk.classify.rte_classify.</tt><tt class="descname">demo_features</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/rte_classify.html#demo_features"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.rte_classify.demo_features" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.rte_classify.lemmatize">
<tt class="descclassname">nltk.classify.rte_classify.</tt><tt class="descname">lemmatize</tt><big>(</big><em>word</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/rte_classify.html#lemmatize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.rte_classify.lemmatize" title="Permalink to this definition">¶</a></dt>
<dd><p>Use morphy from WordNet to find the base form of verbs.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.rte_classify.ne">
<tt class="descclassname">nltk.classify.rte_classify.</tt><tt class="descname">ne</tt><big>(</big><em>token</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/rte_classify.html#ne"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.rte_classify.ne" title="Permalink to this definition">¶</a></dt>
<dd><p>This just assumes that words in all caps or titles are
named entities.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.rte_classify.rte_classifier">
<tt class="descclassname">nltk.classify.rte_classify.</tt><tt class="descname">rte_classifier</tt><big>(</big><em>trainer</em>, <em>features=&lt;function rte_features at 0x446b9b0&gt;</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/rte_classify.html#rte_classifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.rte_classify.rte_classifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Classify RTEPairs</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.rte_classify.rte_features">
<tt class="descclassname">nltk.classify.rte_classify.</tt><tt class="descname">rte_features</tt><big>(</big><em>rtepair</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/rte_classify.html#rte_features"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.rte_classify.rte_features" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-nltk.classify.scikitlearn">
<span id="scikitlearn-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">scikitlearn</span></tt> Module<a class="headerlink" href="#module-nltk.classify.scikitlearn" title="Permalink to this headline">¶</a></h2>
<p>scikit-learn (<a class="reference external" href="http://scikit-learn.org">http://scikit-learn.org</a>) is a machine learning library for
Python, supporting most of the basic classification algorithms, including SVMs,
Naive Bayes, logistic regression and decision trees.</p>
<p>This package implement a wrapper around scikit-learn classifiers. To use this
wrapper, construct a scikit-learn classifier, then use that to construct a
SklearnClassifier. E.g., to wrap a linear SVM classifier with default settings,
do</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.svm.sparse</span> <span class="kn">import</span> <span class="n">LinearSVC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nltk.classify.scikitlearn</span> <span class="kn">import</span> <span class="n">SklearnClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">classif</span> <span class="o">=</span> <span class="n">SklearnClassifier</span><span class="p">(</span><span class="n">LinearSVC</span><span class="p">())</span>
</pre></div>
</div>
<p>The scikit-learn classifier may be arbitrarily complex. E.g., the following
constructs and wraps a Naive Bayes estimator with tf-idf weighting and
chi-square feature selection:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfTransformer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">chi2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">MultinomialNB</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s">&#39;tfidf&#39;</span><span class="p">,</span> <span class="n">TfidfTransformer</span><span class="p">()),</span>
<span class="gp">... </span>                     <span class="p">(</span><span class="s">&#39;chi2&#39;</span><span class="p">,</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">chi2</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1000</span><span class="p">)),</span>
<span class="gp">... </span>                     <span class="p">(</span><span class="s">&#39;nb&#39;</span><span class="p">,</span> <span class="n">MultinomialNB</span><span class="p">())])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">classif</span> <span class="o">=</span> <span class="n">SklearnClassifier</span><span class="p">(</span><span class="n">pipeline</span><span class="p">)</span>
</pre></div>
</div>
<p>(Such a classifier could be trained on word counts for text classification.)</p>
<dl class="class">
<dt id="nltk.classify.scikitlearn.SklearnClassifier">
<em class="property">class </em><tt class="descclassname">nltk.classify.scikitlearn.</tt><tt class="descname">SklearnClassifier</tt><big>(</big><em>estimator</em>, <em>dtype=&lt;type 'float'&gt;</em>, <em>sparse=True</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/scikitlearn.html#SklearnClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.scikitlearn.SklearnClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.api.ClassifierI" title="nltk.classify.api.ClassifierI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.api.ClassifierI</span></tt></a></p>
<p>Wrapper for scikit-learn classifiers.</p>
<dl class="method">
<dt id="nltk.classify.scikitlearn.SklearnClassifier.batch_classify">
<tt class="descname">batch_classify</tt><big>(</big><em>featuresets</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/scikitlearn.html#SklearnClassifier.batch_classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.scikitlearn.SklearnClassifier.batch_classify" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.scikitlearn.SklearnClassifier.batch_prob_classify">
<tt class="descname">batch_prob_classify</tt><big>(</big><em>featuresets</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/scikitlearn.html#SklearnClassifier.batch_prob_classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.scikitlearn.SklearnClassifier.batch_prob_classify" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.scikitlearn.SklearnClassifier.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/scikitlearn.html#SklearnClassifier.labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.scikitlearn.SklearnClassifier.labels" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.scikitlearn.SklearnClassifier.train">
<tt class="descname">train</tt><big>(</big><em>labeled_featuresets</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/scikitlearn.html#SklearnClassifier.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.scikitlearn.SklearnClassifier.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Train (fit) the scikit-learn estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>labeled_featuresets</strong> &#8211; A list of classified featuresets,
i.e., a list of tuples <tt class="docutils literal"><span class="pre">(featureset,</span> <span class="pre">label)</span></tt>.</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nltk.classify.svm">
<span id="svm-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">svm</span></tt> Module<a class="headerlink" href="#module-nltk.classify.svm" title="Permalink to this headline">¶</a></h2>
<p>A classifier based on a support vector machine. This code uses Thorsten Joachims&#8217;
SVM^light implementation (<a class="reference external" href="http://svmlight.joachims.org/">http://svmlight.joachims.org/</a>), wrapped using
PySVMLight (<a class="reference external" href="https://bitbucket.org/wcauchois/pysvmlight">https://bitbucket.org/wcauchois/pysvmlight</a>). The default settings are to
train a linear classification kernel, though through minor modification, full SVMlight
capabilities should be accessible if needed. Only binary classification is possible at present.</p>
<dl class="class">
<dt id="nltk.classify.svm.SvmClassifier">
<em class="property">class </em><tt class="descclassname">nltk.classify.svm.</tt><tt class="descname">SvmClassifier</tt><big>(</big><em>labels</em>, <em>labelmapping</em>, <em>svmfeatures</em>, <em>model=None</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/svm.html#SvmClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.svm.SvmClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.api.ClassifierI" title="nltk.classify.api.ClassifierI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.api.ClassifierI</span></tt></a></p>
<p>A Support Vector Machine classifier. To explain briefly, support
vector machines (SVM) treat each feature as a dimension, and
position features in n-dimensional feature space.  An optimal
hyperplane is then determined that best divides feature space into
classes, and future instances classified based on which side of
the hyperplane they lie on, and their proximity to it.</p>
<p>This implementation is for a binary SVM - that is, only two
classes are supported. You may achieve perform classification with
more classes by training an SVM per class and then picking a best
option for new instances given results from each binary class-SVM.</p>
<dl class="method">
<dt id="nltk.classify.svm.SvmClassifier.classify">
<tt class="descname">classify</tt><big>(</big><em>featureset</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/svm.html#SvmClassifier.classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.svm.SvmClassifier.classify" title="Permalink to this definition">¶</a></dt>
<dd><p>Use a trained SVM to predict a label given for an unlabelled instance</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>featureset</strong> &#8211; a dict of feature/value pairs in NLTK format, representing a single instance</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.svm.SvmClassifier.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/svm.html#SvmClassifier.labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.svm.SvmClassifier.labels" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the list of class labels.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.svm.SvmClassifier.prob_classify">
<tt class="descname">prob_classify</tt><big>(</big><em>featureset</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/svm.html#SvmClassifier.prob_classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.svm.SvmClassifier.prob_classify" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a probability distribution of classifications</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>featureset</strong> &#8211; a dict of feature/value pairs in NLTK format, representing a single instance</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.svm.SvmClassifier.resolve_prediction">
<tt class="descname">resolve_prediction</tt><big>(</big><em>prediction</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/svm.html#SvmClassifier.resolve_prediction"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.svm.SvmClassifier.resolve_prediction" title="Permalink to this definition">¶</a></dt>
<dd><p>resolve a float (in this case, probably from
svmlight.learn().classify()) to either -1 or +1, and then look
up the label for that class in _labelmapping, and return the
text label</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>prediction</strong> &#8211; a signed float describing classifier confidence</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.svm.SvmClassifier.svm_label_name">
<tt class="descname">svm_label_name</tt><big>(</big><em>label</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/svm.html#SvmClassifier.svm_label_name"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.svm.SvmClassifier.svm_label_name" title="Permalink to this definition">¶</a></dt>
<dd><p>searches values of _labelmapping to resolve +1 or -1 to a string</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>label</strong> &#8211; the string label to look up</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="nltk.classify.svm.SvmClassifier.train">
<em class="property">static </em><tt class="descname">train</tt><big>(</big><em>featuresets</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/svm.html#SvmClassifier.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.svm.SvmClassifier.train" title="Permalink to this definition">¶</a></dt>
<dd><p>given a set of training instances in nltk format:
[ ( {feature:value, ..}, str(label) ) ]
train a support vector machine</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>featuresets</strong> &#8211; training instances</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="nltk.classify.svm.demo">
<tt class="descclassname">nltk.classify.svm.</tt><tt class="descname">demo</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/svm.html#demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.svm.demo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.svm.featurename">
<tt class="descclassname">nltk.classify.svm.</tt><tt class="descname">featurename</tt><big>(</big><em>feature</em>, <em>value</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/svm.html#featurename"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.svm.featurename" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>feature</strong> &#8211; a string denoting a feature name</li>
<li><strong>value</strong> &#8211; the value of the feature</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.svm.map_features_to_svm">
<tt class="descclassname">nltk.classify.svm.</tt><tt class="descname">map_features_to_svm</tt><big>(</big><em>features</em>, <em>svmfeatureindex</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/svm.html#map_features_to_svm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.svm.map_features_to_svm" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>features</strong> &#8211; a dict of features in the format {&#8216;feature&#8217;:value}</li>
<li><strong>svmfeatureindex</strong> &#8211; a mapping from feature:value pairs to integer SVMlight feature labels</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.svm.map_instance_to_svm">
<tt class="descclassname">nltk.classify.svm.</tt><tt class="descname">map_instance_to_svm</tt><big>(</big><em>instance</em>, <em>labelmapping</em>, <em>svmfeatureindex</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/svm.html#map_instance_to_svm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.svm.map_instance_to_svm" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>instance</strong> &#8211; an NLTK format instance, which is in the tuple format (dict(), label), where the dict contains feature:value pairs, and the label signifies the target attribute&#8217;s value for this instance (e.g. its class)</li>
<li><strong>labelmapping</strong> &#8211; a previously-defined dict mapping from text labels in the NLTK instance format to SVMlight labels of either +1 or -1</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>&#64;svmfeatureindex: a mapping from feature:value pairs to integer SVMlight feature labels</p>
</dd></dl>

</div>
<div class="section" id="module-nltk.classify.tadm">
<span id="tadm-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">tadm</span></tt> Module<a class="headerlink" href="#module-nltk.classify.tadm" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="nltk.classify.tadm.call_tadm">
<tt class="descclassname">nltk.classify.tadm.</tt><tt class="descname">call_tadm</tt><big>(</big><em>args</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/tadm.html#call_tadm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.tadm.call_tadm" title="Permalink to this definition">¶</a></dt>
<dd><p>Call the <tt class="docutils literal"><span class="pre">tadm</span></tt> binary with the given arguments.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.tadm.config_tadm">
<tt class="descclassname">nltk.classify.tadm.</tt><tt class="descname">config_tadm</tt><big>(</big><em>bin=None</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/tadm.html#config_tadm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.tadm.config_tadm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.tadm.encoding_demo">
<tt class="descclassname">nltk.classify.tadm.</tt><tt class="descname">encoding_demo</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/tadm.html#encoding_demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.tadm.encoding_demo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.tadm.names_demo">
<tt class="descclassname">nltk.classify.tadm.</tt><tt class="descname">names_demo</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/tadm.html#names_demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.tadm.names_demo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.tadm.parse_tadm_weights">
<tt class="descclassname">nltk.classify.tadm.</tt><tt class="descname">parse_tadm_weights</tt><big>(</big><em>paramfile</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/tadm.html#parse_tadm_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.tadm.parse_tadm_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Given the stdout output generated by <tt class="docutils literal"><span class="pre">tadm</span></tt> when training a
model, return a <tt class="docutils literal"><span class="pre">numpy</span></tt> array containing the corresponding weight
vector.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.tadm.write_tadm_file">
<tt class="descclassname">nltk.classify.tadm.</tt><tt class="descname">write_tadm_file</tt><big>(</big><em>train_toks</em>, <em>encoding</em>, <em>stream</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/tadm.html#write_tadm_file"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.tadm.write_tadm_file" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate an input file for <tt class="docutils literal"><span class="pre">tadm</span></tt> based on the given corpus of
classified tokens.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>train_toks</strong> (<em>list(tuple(dict, str))</em>) &#8211; Training data, represented as a list of
pairs, the first member of which is a feature dictionary,
and the second of which is a classification label.</li>
<li><strong>encoding</strong> (<em>TadmEventMaxentFeatureEncoding</em>) &#8211; A feature encoding, used to convert featuresets
into feature vectors.</li>
<li><strong>stream</strong> (<em>stream</em>) &#8211; The stream to which the <tt class="docutils literal"><span class="pre">tadm</span></tt> input file should be
written.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-nltk.classify.util">
<span id="util-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">util</span></tt> Module<a class="headerlink" href="#module-nltk.classify.util" title="Permalink to this headline">¶</a></h2>
<p>Utility functions and classes for classifiers.</p>
<dl class="class">
<dt id="nltk.classify.util.CutoffChecker">
<em class="property">class </em><tt class="descclassname">nltk.classify.util.</tt><tt class="descname">CutoffChecker</tt><big>(</big><em>cutoffs</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/util.html#CutoffChecker"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.util.CutoffChecker" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>A helper class that implements cutoff checks based on number of
iterations and log likelihood.</p>
<p>Accuracy cutoffs are also implemented, but they&#8217;re almost never
a good idea to use.</p>
<dl class="method">
<dt id="nltk.classify.util.CutoffChecker.check">
<tt class="descname">check</tt><big>(</big><em>classifier</em>, <em>train_toks</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/util.html#CutoffChecker.check"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.util.CutoffChecker.check" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="nltk.classify.util.accuracy">
<tt class="descclassname">nltk.classify.util.</tt><tt class="descname">accuracy</tt><big>(</big><em>classifier</em>, <em>gold</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/util.html#accuracy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.util.accuracy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.util.apply_features">
<tt class="descclassname">nltk.classify.util.</tt><tt class="descname">apply_features</tt><big>(</big><em>feature_func</em>, <em>toks</em>, <em>labeled=None</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/util.html#apply_features"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.util.apply_features" title="Permalink to this definition">¶</a></dt>
<dd><p>Use the <tt class="docutils literal"><span class="pre">LazyMap</span></tt> class to construct a lazy list-like
object that is analogous to <tt class="docutils literal"><span class="pre">map(feature_func,</span> <span class="pre">toks)</span></tt>.  In
particular, if <tt class="docutils literal"><span class="pre">labeled=False</span></tt>, then the returned list-like
object&#8217;s values are equal to:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="p">[</span><span class="n">feature_func</span><span class="p">(</span><span class="n">tok</span><span class="p">)</span> <span class="k">for</span> <span class="n">tok</span> <span class="ow">in</span> <span class="n">toks</span><span class="p">]</span>
</pre></div>
</div>
<p>If <tt class="docutils literal"><span class="pre">labeled=True</span></tt>, then the returned list-like object&#8217;s values
are equal to:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="p">[(</span><span class="n">feature_func</span><span class="p">(</span><span class="n">tok</span><span class="p">),</span> <span class="n">label</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">tok</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="n">toks</span><span class="p">]</span>
</pre></div>
</div>
<p>The primary purpose of this function is to avoid the memory
overhead involved in storing all the featuresets for every token
in a corpus.  Instead, these featuresets are constructed lazily,
as-needed.  The reduction in memory overhead can be especially
significant when the underlying list of tokens is itself lazy (as
is the case with many corpus readers).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>feature_func</strong> &#8211; The function that will be applied to each
token.  It should return a featureset &#8211; i.e., a dict
mapping feature names to feature values.</li>
<li><strong>toks</strong> &#8211; The list of tokens to which <tt class="docutils literal"><span class="pre">feature_func</span></tt> should be
applied.  If <tt class="docutils literal"><span class="pre">labeled=True</span></tt>, then the list elements will be
passed directly to <tt class="docutils literal"><span class="pre">feature_func()</span></tt>.  If <tt class="docutils literal"><span class="pre">labeled=False</span></tt>,
then the list elements should be tuples <tt class="docutils literal"><span class="pre">(tok,label)</span></tt>, and
<tt class="docutils literal"><span class="pre">tok</span></tt> will be passed to <tt class="docutils literal"><span class="pre">feature_func()</span></tt>.</li>
<li><strong>labeled</strong> &#8211; If true, then <tt class="docutils literal"><span class="pre">toks</span></tt> contains labeled tokens &#8211;
i.e., tuples of the form <tt class="docutils literal"><span class="pre">(tok,</span> <span class="pre">label)</span></tt>.  (Default:
auto-detect based on types.)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.util.attested_labels">
<tt class="descclassname">nltk.classify.util.</tt><tt class="descname">attested_labels</tt><big>(</big><em>tokens</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/util.html#attested_labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.util.attested_labels" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">A list of all labels that are attested in the given list
of tokens.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">list of (immutable)</td>
</tr>
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>tokens</strong> (<em>list</em>) &#8211; The list of classified tokens from which to extract
labels.  A classified token has the form <tt class="docutils literal"><span class="pre">(token,</span> <span class="pre">label)</span></tt>.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.util.binary_names_demo_features">
<tt class="descclassname">nltk.classify.util.</tt><tt class="descname">binary_names_demo_features</tt><big>(</big><em>name</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/util.html#binary_names_demo_features"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.util.binary_names_demo_features" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.util.log_likelihood">
<tt class="descclassname">nltk.classify.util.</tt><tt class="descname">log_likelihood</tt><big>(</big><em>classifier</em>, <em>gold</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/util.html#log_likelihood"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.util.log_likelihood" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.util.names_demo">
<tt class="descclassname">nltk.classify.util.</tt><tt class="descname">names_demo</tt><big>(</big><em>trainer</em>, <em>features=&lt;function names_demo_features at 0x446b668&gt;</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/util.html#names_demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.util.names_demo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.util.names_demo_features">
<tt class="descclassname">nltk.classify.util.</tt><tt class="descname">names_demo_features</tt><big>(</big><em>name</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/util.html#names_demo_features"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.util.names_demo_features" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.util.partial_names_demo">
<tt class="descclassname">nltk.classify.util.</tt><tt class="descname">partial_names_demo</tt><big>(</big><em>trainer</em>, <em>features=&lt;function names_demo_features at 0x446b668&gt;</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/util.html#partial_names_demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.util.partial_names_demo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.util.wsd_demo">
<tt class="descclassname">nltk.classify.util.</tt><tt class="descname">wsd_demo</tt><big>(</big><em>trainer</em>, <em>word</em>, <em>features</em>, <em>n=1000</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/util.html#wsd_demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.util.wsd_demo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-nltk.classify.weka">
<span id="weka-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">weka</span></tt> Module<a class="headerlink" href="#module-nltk.classify.weka" title="Permalink to this headline">¶</a></h2>
<p>Classifiers that make use of the external &#8216;Weka&#8217; package.</p>
<dl class="class">
<dt id="nltk.classify.weka.ARFF_Formatter">
<em class="property">class </em><tt class="descclassname">nltk.classify.weka.</tt><tt class="descname">ARFF_Formatter</tt><big>(</big><em>labels</em>, <em>features</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#ARFF_Formatter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.ARFF_Formatter" title="Permalink to this definition">¶</a></dt>
<dd><p>Converts featuresets and labeled featuresets to ARFF-formatted
strings, appropriate for input into Weka.</p>
<p>Features and classes can be specified manually in the constructor, or may
be determined from data using <tt class="docutils literal"><span class="pre">from_train</span></tt>.</p>
<dl class="method">
<dt id="nltk.classify.weka.ARFF_Formatter.data_section">
<tt class="descname">data_section</tt><big>(</big><em>tokens</em>, <em>labeled=None</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#ARFF_Formatter.data_section"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.ARFF_Formatter.data_section" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the ARFF data section for the given data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>tokens</strong> &#8211; a list of featuresets (dicts) or labelled featuresets
which are tuples (featureset, label).</li>
<li><strong>labeled</strong> &#8211; Indicates whether the given tokens are labeled
or not.  If None, then the tokens will be assumed to be
labeled if the first token&#8217;s value is a tuple or list.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.weka.ARFF_Formatter.format">
<tt class="descname">format</tt><big>(</big><em>tokens</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#ARFF_Formatter.format"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.ARFF_Formatter.format" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a string representation of ARFF output for the given data.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="nltk.classify.weka.ARFF_Formatter.from_train">
<em class="property">static </em><tt class="descname">from_train</tt><big>(</big><em>tokens</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#ARFF_Formatter.from_train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.ARFF_Formatter.from_train" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs an ARFF_Formatter instance with class labels and feature
types determined from the given data. Handles boolean, numeric and
string (note: not nominal) types.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.weka.ARFF_Formatter.header_section">
<tt class="descname">header_section</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#ARFF_Formatter.header_section"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.ARFF_Formatter.header_section" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an ARFF header as a string.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.weka.ARFF_Formatter.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#ARFF_Formatter.labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.ARFF_Formatter.labels" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the list of classes.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.weka.ARFF_Formatter.write">
<tt class="descname">write</tt><big>(</big><em>outfile</em>, <em>tokens</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#ARFF_Formatter.write"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.ARFF_Formatter.write" title="Permalink to this definition">¶</a></dt>
<dd><p>Writes ARFF data to a file for the given data.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.classify.weka.WekaClassifier">
<em class="property">class </em><tt class="descclassname">nltk.classify.weka.</tt><tt class="descname">WekaClassifier</tt><big>(</big><em>formatter</em>, <em>model_filename</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#WekaClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.WekaClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.api.ClassifierI" title="nltk.classify.api.ClassifierI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.api.ClassifierI</span></tt></a></p>
<dl class="method">
<dt id="nltk.classify.weka.WekaClassifier.batch_classify">
<tt class="descname">batch_classify</tt><big>(</big><em>featuresets</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#WekaClassifier.batch_classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.WekaClassifier.batch_classify" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.weka.WekaClassifier.batch_prob_classify">
<tt class="descname">batch_prob_classify</tt><big>(</big><em>featuresets</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#WekaClassifier.batch_prob_classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.WekaClassifier.batch_prob_classify" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.weka.WekaClassifier.parse_weka_distribution">
<tt class="descname">parse_weka_distribution</tt><big>(</big><em>s</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#WekaClassifier.parse_weka_distribution"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.WekaClassifier.parse_weka_distribution" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.weka.WekaClassifier.parse_weka_output">
<tt class="descname">parse_weka_output</tt><big>(</big><em>lines</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#WekaClassifier.parse_weka_output"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.WekaClassifier.parse_weka_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="classmethod">
<dt id="nltk.classify.weka.WekaClassifier.train">
<em class="property">classmethod </em><tt class="descname">train</tt><big>(</big><em>model_filename</em>, <em>featuresets</em>, <em>classifier='naivebayes'</em>, <em>options=</em><span class="optional">[</span><span class="optional">]</span>, <em>quiet=True</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#WekaClassifier.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.WekaClassifier.train" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="nltk.classify.weka.config_weka">
<tt class="descclassname">nltk.classify.weka.</tt><tt class="descname">config_weka</tt><big>(</big><em>classpath=None</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#config_weka"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.config_weka" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
</div>


          </div>
        </div>
      </div>
        </div>
        <div class="sidebar">
          <h3>Table Of Contents</h3>
          <ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">NLTK News</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installing NLTK</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data.html">Installing NLTK Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="nltk.html">nltk Package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../team.html">Team NLTK</a></li>
</ul>

          <h3 style="margin-top: 1.5em;">Search</h3>
          <form class="search" action="../search.html" method="get">
            <input type="text" name="q" />
            <input type="submit" value="Go" />
            <input type="hidden" name="check_keywords" value="yes" />
            <input type="hidden" name="area" value="default" />
          </form>
          <p class="searchtip" style="font-size: 90%">
            Enter search terms or a module, class or function name.
          </p>
        </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer-wrapper">
      <div class="footer">
        <div class="left">
          <a href="nltk.chunk.html" title="chunk Package"
             >previous</a> |
          <a href="nltk.cluster.html" title="cluster Package"
             >next</a> |
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |
          <a href="../genindex.html" title="General Index"
             >index</a>
            <br/>
            <a href="../_sources/api/nltk.classify.txt"
               rel="nofollow">Show Source</a>
        </div>

        <div class="right">
          
    <div class="footer">
        &copy; Copyright 2012, NLTK Project.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3.
    </div>
        </div>
        <div class="clearer"></div>
      </div>
    </div>

  </body>
</html>