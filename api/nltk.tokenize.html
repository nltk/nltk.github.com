<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="theme-color" content="#2D2D2D" />
  
  <title>NLTK :: nltk.tokenize package</title>
  

  <link rel="stylesheet" href="../_static/css/nltk_theme.css"/>
  <link rel="stylesheet" href="../_static/css/custom.css"/>

  <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="../_static/sphinx_highlight.js"></script>
  

  <script src="https://email.tl.fortawesome.com/c/eJxNjUEOgyAQAF8jR7Kw6wIHDh7sP1Cw2mgxgmn6-3JsMqc5zEQfE8dkxOY1KKMUOI3ACFKRJpSW2AAp7ontYIaxI6i7XPJVwyeVfCQ550Os3jLrGSNOLgbdAy6s0PBk2TFNjEbsfq31LB0OnX407pJa5v2faRadwSW63mn5KuLyR9j2tgx3zecanl-55R_-jjPs"></script> 
</head>

<body>
  <div id="nltk-theme-container">
    <header>
      <div id="logo-container">
          
          <h1>
            <a href="../index.html">NLTK</a>
          </h1>
          
      </div>
      <div id="project-container">
        
        <h1>Documentation</h1>
        
      </div>

      <a id="menu-toggle" class="fa fa-bars" aria-hidden="true"></a>

      <script type="text/javascript">
        $("#menu-toggle").click(function() {
          $("#menu-toggle").toggleClass("toggled");
          $("#side-menu-container").slideToggle(300);
        });
      </script>
    </header>

    <div id="content-container">

      <div id="side-menu-container">

        <div id="search" role="search">
        <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
            <input type="text" name="q" placeholder="Search" />
            <input type="hidden" name="check_keywords" value="yes" />
            <input type="hidden" name="area" value="default" />
        </form>
</div>

        <div id="side-menu" role="navigation">
          
  
    
  
  
    <p class="caption" role="heading"><span class="caption-text">NLTK Documentation</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="nltk.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../howto.html">Example Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../py-modindex.html">Module Index</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk/wiki">Wiki</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk/wiki/FAQ">FAQ</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk/issues">Open Issues</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk">NLTK on GitHub</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installing NLTK</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data.html">Installing NLTK Data</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contribute.html">Contributing to NLTK</a></li>
<li class="toctree-l1"><a class="reference internal" href="../team.html">NLTK Team</a></li>
</ul>

  

        </div>

        
      </div>

      <div id="main-content-container">
        <div id="main-content" role="main">
          
  <section id="nltk-tokenize-package">
<h1>nltk.tokenize package<a class="headerlink" href="#nltk-tokenize-package" title="Link to this heading">¶</a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Link to this heading">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="nltk.tokenize.api.html">nltk.tokenize.api module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.api.html#nltk.tokenize.api.StringTokenizer"><code class="docutils literal notranslate"><span class="pre">StringTokenizer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.api.html#nltk.tokenize.api.StringTokenizer.span_tokenize"><code class="docutils literal notranslate"><span class="pre">StringTokenizer.span_tokenize()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.api.html#nltk.tokenize.api.StringTokenizer.tokenize"><code class="docutils literal notranslate"><span class="pre">StringTokenizer.tokenize()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.api.html#nltk.tokenize.api.TokenizerI"><code class="docutils literal notranslate"><span class="pre">TokenizerI</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.api.html#nltk.tokenize.api.TokenizerI.span_tokenize"><code class="docutils literal notranslate"><span class="pre">TokenizerI.span_tokenize()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.api.html#nltk.tokenize.api.TokenizerI.span_tokenize_sents"><code class="docutils literal notranslate"><span class="pre">TokenizerI.span_tokenize_sents()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.api.html#nltk.tokenize.api.TokenizerI.tokenize"><code class="docutils literal notranslate"><span class="pre">TokenizerI.tokenize()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.api.html#nltk.tokenize.api.TokenizerI.tokenize_sents"><code class="docutils literal notranslate"><span class="pre">TokenizerI.tokenize_sents()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nltk.tokenize.casual.html">nltk.tokenize.casual module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.casual.html#nltk.tokenize.casual.TweetTokenizer"><code class="docutils literal notranslate"><span class="pre">TweetTokenizer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.casual.html#nltk.tokenize.casual.TweetTokenizer.PHONE_WORD_RE"><code class="docutils literal notranslate"><span class="pre">TweetTokenizer.PHONE_WORD_RE</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.casual.html#nltk.tokenize.casual.TweetTokenizer.WORD_RE"><code class="docutils literal notranslate"><span class="pre">TweetTokenizer.WORD_RE</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.casual.html#nltk.tokenize.casual.TweetTokenizer.__init__"><code class="docutils literal notranslate"><span class="pre">TweetTokenizer.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.casual.html#nltk.tokenize.casual.TweetTokenizer.tokenize"><code class="docutils literal notranslate"><span class="pre">TweetTokenizer.tokenize()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.casual.html#nltk.tokenize.casual.casual_tokenize"><code class="docutils literal notranslate"><span class="pre">casual_tokenize()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.casual.html#nltk.tokenize.casual.reduce_lengthening"><code class="docutils literal notranslate"><span class="pre">reduce_lengthening()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.casual.html#nltk.tokenize.casual.remove_handles"><code class="docutils literal notranslate"><span class="pre">remove_handles()</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nltk.tokenize.destructive.html">nltk.tokenize.destructive module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.destructive.html#nltk.tokenize.destructive.MacIntyreContractions"><code class="docutils literal notranslate"><span class="pre">MacIntyreContractions</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.destructive.html#nltk.tokenize.destructive.MacIntyreContractions.CONTRACTIONS2"><code class="docutils literal notranslate"><span class="pre">MacIntyreContractions.CONTRACTIONS2</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.destructive.html#nltk.tokenize.destructive.MacIntyreContractions.CONTRACTIONS3"><code class="docutils literal notranslate"><span class="pre">MacIntyreContractions.CONTRACTIONS3</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.destructive.html#nltk.tokenize.destructive.MacIntyreContractions.CONTRACTIONS4"><code class="docutils literal notranslate"><span class="pre">MacIntyreContractions.CONTRACTIONS4</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.destructive.html#nltk.tokenize.destructive.NLTKWordTokenizer"><code class="docutils literal notranslate"><span class="pre">NLTKWordTokenizer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.destructive.html#nltk.tokenize.destructive.NLTKWordTokenizer.CONTRACTIONS2"><code class="docutils literal notranslate"><span class="pre">NLTKWordTokenizer.CONTRACTIONS2</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.destructive.html#nltk.tokenize.destructive.NLTKWordTokenizer.CONTRACTIONS3"><code class="docutils literal notranslate"><span class="pre">NLTKWordTokenizer.CONTRACTIONS3</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.destructive.html#nltk.tokenize.destructive.NLTKWordTokenizer.CONVERT_PARENTHESES"><code class="docutils literal notranslate"><span class="pre">NLTKWordTokenizer.CONVERT_PARENTHESES</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.destructive.html#nltk.tokenize.destructive.NLTKWordTokenizer.DOUBLE_DASHES"><code class="docutils literal notranslate"><span class="pre">NLTKWordTokenizer.DOUBLE_DASHES</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.destructive.html#nltk.tokenize.destructive.NLTKWordTokenizer.ENDING_QUOTES"><code class="docutils literal notranslate"><span class="pre">NLTKWordTokenizer.ENDING_QUOTES</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.destructive.html#nltk.tokenize.destructive.NLTKWordTokenizer.PARENS_BRACKETS"><code class="docutils literal notranslate"><span class="pre">NLTKWordTokenizer.PARENS_BRACKETS</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.destructive.html#nltk.tokenize.destructive.NLTKWordTokenizer.PUNCTUATION"><code class="docutils literal notranslate"><span class="pre">NLTKWordTokenizer.PUNCTUATION</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.destructive.html#nltk.tokenize.destructive.NLTKWordTokenizer.STARTING_QUOTES"><code class="docutils literal notranslate"><span class="pre">NLTKWordTokenizer.STARTING_QUOTES</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.destructive.html#nltk.tokenize.destructive.NLTKWordTokenizer.span_tokenize"><code class="docutils literal notranslate"><span class="pre">NLTKWordTokenizer.span_tokenize()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.destructive.html#nltk.tokenize.destructive.NLTKWordTokenizer.tokenize"><code class="docutils literal notranslate"><span class="pre">NLTKWordTokenizer.tokenize()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nltk.tokenize.legality_principle.html">nltk.tokenize.legality_principle module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.legality_principle.html#nltk.tokenize.legality_principle.LegalitySyllableTokenizer"><code class="docutils literal notranslate"><span class="pre">LegalitySyllableTokenizer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.legality_principle.html#nltk.tokenize.legality_principle.LegalitySyllableTokenizer.__init__"><code class="docutils literal notranslate"><span class="pre">LegalitySyllableTokenizer.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.legality_principle.html#nltk.tokenize.legality_principle.LegalitySyllableTokenizer.find_legal_onsets"><code class="docutils literal notranslate"><span class="pre">LegalitySyllableTokenizer.find_legal_onsets()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.legality_principle.html#nltk.tokenize.legality_principle.LegalitySyllableTokenizer.onset"><code class="docutils literal notranslate"><span class="pre">LegalitySyllableTokenizer.onset()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.legality_principle.html#nltk.tokenize.legality_principle.LegalitySyllableTokenizer.tokenize"><code class="docutils literal notranslate"><span class="pre">LegalitySyllableTokenizer.tokenize()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nltk.tokenize.mwe.html">nltk.tokenize.mwe module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.mwe.html#nltk.tokenize.mwe.MWETokenizer"><code class="docutils literal notranslate"><span class="pre">MWETokenizer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.mwe.html#nltk.tokenize.mwe.MWETokenizer.__init__"><code class="docutils literal notranslate"><span class="pre">MWETokenizer.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.mwe.html#nltk.tokenize.mwe.MWETokenizer.add_mwe"><code class="docutils literal notranslate"><span class="pre">MWETokenizer.add_mwe()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.mwe.html#nltk.tokenize.mwe.MWETokenizer.tokenize"><code class="docutils literal notranslate"><span class="pre">MWETokenizer.tokenize()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nltk.tokenize.nist.html">nltk.tokenize.nist module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.nist.html#nltk.tokenize.nist.NISTTokenizer"><code class="docutils literal notranslate"><span class="pre">NISTTokenizer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.nist.html#nltk.tokenize.nist.NISTTokenizer.DASH_PRECEED_DIGIT"><code class="docutils literal notranslate"><span class="pre">NISTTokenizer.DASH_PRECEED_DIGIT</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.nist.html#nltk.tokenize.nist.NISTTokenizer.INTERNATIONAL_REGEXES"><code class="docutils literal notranslate"><span class="pre">NISTTokenizer.INTERNATIONAL_REGEXES</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.nist.html#nltk.tokenize.nist.NISTTokenizer.LANG_DEPENDENT_REGEXES"><code class="docutils literal notranslate"><span class="pre">NISTTokenizer.LANG_DEPENDENT_REGEXES</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.nist.html#nltk.tokenize.nist.NISTTokenizer.NONASCII"><code class="docutils literal notranslate"><span class="pre">NISTTokenizer.NONASCII</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.nist.html#nltk.tokenize.nist.NISTTokenizer.PERIOD_COMMA_FOLLOW"><code class="docutils literal notranslate"><span class="pre">NISTTokenizer.PERIOD_COMMA_FOLLOW</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.nist.html#nltk.tokenize.nist.NISTTokenizer.PERIOD_COMMA_PRECEED"><code class="docutils literal notranslate"><span class="pre">NISTTokenizer.PERIOD_COMMA_PRECEED</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.nist.html#nltk.tokenize.nist.NISTTokenizer.PUNCT"><code class="docutils literal notranslate"><span class="pre">NISTTokenizer.PUNCT</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.nist.html#nltk.tokenize.nist.NISTTokenizer.PUNCT_1"><code class="docutils literal notranslate"><span class="pre">NISTTokenizer.PUNCT_1</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.nist.html#nltk.tokenize.nist.NISTTokenizer.PUNCT_2"><code class="docutils literal notranslate"><span class="pre">NISTTokenizer.PUNCT_2</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.nist.html#nltk.tokenize.nist.NISTTokenizer.STRIP_EOL_HYPHEN"><code class="docutils literal notranslate"><span class="pre">NISTTokenizer.STRIP_EOL_HYPHEN</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.nist.html#nltk.tokenize.nist.NISTTokenizer.STRIP_SKIP"><code class="docutils literal notranslate"><span class="pre">NISTTokenizer.STRIP_SKIP</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.nist.html#nltk.tokenize.nist.NISTTokenizer.SYMBOLS"><code class="docutils literal notranslate"><span class="pre">NISTTokenizer.SYMBOLS</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.nist.html#nltk.tokenize.nist.NISTTokenizer.international_tokenize"><code class="docutils literal notranslate"><span class="pre">NISTTokenizer.international_tokenize()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.nist.html#nltk.tokenize.nist.NISTTokenizer.lang_independent_sub"><code class="docutils literal notranslate"><span class="pre">NISTTokenizer.lang_independent_sub()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.nist.html#nltk.tokenize.nist.NISTTokenizer.number_regex"><code class="docutils literal notranslate"><span class="pre">NISTTokenizer.number_regex</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.nist.html#nltk.tokenize.nist.NISTTokenizer.punct_regex"><code class="docutils literal notranslate"><span class="pre">NISTTokenizer.punct_regex</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.nist.html#nltk.tokenize.nist.NISTTokenizer.pup_number"><code class="docutils literal notranslate"><span class="pre">NISTTokenizer.pup_number</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.nist.html#nltk.tokenize.nist.NISTTokenizer.pup_punct"><code class="docutils literal notranslate"><span class="pre">NISTTokenizer.pup_punct</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.nist.html#nltk.tokenize.nist.NISTTokenizer.pup_symbol"><code class="docutils literal notranslate"><span class="pre">NISTTokenizer.pup_symbol</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.nist.html#nltk.tokenize.nist.NISTTokenizer.symbol_regex"><code class="docutils literal notranslate"><span class="pre">NISTTokenizer.symbol_regex</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.nist.html#nltk.tokenize.nist.NISTTokenizer.tokenize"><code class="docutils literal notranslate"><span class="pre">NISTTokenizer.tokenize()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nltk.tokenize.punkt.html">nltk.tokenize.punkt module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktBaseClass"><code class="docutils literal notranslate"><span class="pre">PunktBaseClass</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktBaseClass.__init__"><code class="docutils literal notranslate"><span class="pre">PunktBaseClass.__init__()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktLanguageVars"><code class="docutils literal notranslate"><span class="pre">PunktLanguageVars</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktLanguageVars.internal_punctuation"><code class="docutils literal notranslate"><span class="pre">PunktLanguageVars.internal_punctuation</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktLanguageVars.period_context_re"><code class="docutils literal notranslate"><span class="pre">PunktLanguageVars.period_context_re()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktLanguageVars.re_boundary_realignment"><code class="docutils literal notranslate"><span class="pre">PunktLanguageVars.re_boundary_realignment</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktLanguageVars.sent_end_chars"><code class="docutils literal notranslate"><span class="pre">PunktLanguageVars.sent_end_chars</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktLanguageVars.word_tokenize"><code class="docutils literal notranslate"><span class="pre">PunktLanguageVars.word_tokenize()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktParameters"><code class="docutils literal notranslate"><span class="pre">PunktParameters</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktParameters.__init__"><code class="docutils literal notranslate"><span class="pre">PunktParameters.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktParameters.abbrev_types"><code class="docutils literal notranslate"><span class="pre">PunktParameters.abbrev_types</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktParameters.add_ortho_context"><code class="docutils literal notranslate"><span class="pre">PunktParameters.add_ortho_context()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktParameters.clear_abbrevs"><code class="docutils literal notranslate"><span class="pre">PunktParameters.clear_abbrevs()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktParameters.clear_collocations"><code class="docutils literal notranslate"><span class="pre">PunktParameters.clear_collocations()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktParameters.clear_ortho_context"><code class="docutils literal notranslate"><span class="pre">PunktParameters.clear_ortho_context()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktParameters.clear_sent_starters"><code class="docutils literal notranslate"><span class="pre">PunktParameters.clear_sent_starters()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktParameters.collocations"><code class="docutils literal notranslate"><span class="pre">PunktParameters.collocations</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktParameters.ortho_context"><code class="docutils literal notranslate"><span class="pre">PunktParameters.ortho_context</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktParameters.sent_starters"><code class="docutils literal notranslate"><span class="pre">PunktParameters.sent_starters</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktSentenceTokenizer"><code class="docutils literal notranslate"><span class="pre">PunktSentenceTokenizer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktSentenceTokenizer.PUNCTUATION"><code class="docutils literal notranslate"><span class="pre">PunktSentenceTokenizer.PUNCTUATION</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktSentenceTokenizer.__init__"><code class="docutils literal notranslate"><span class="pre">PunktSentenceTokenizer.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktSentenceTokenizer.debug_decisions"><code class="docutils literal notranslate"><span class="pre">PunktSentenceTokenizer.debug_decisions()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktSentenceTokenizer.dump"><code class="docutils literal notranslate"><span class="pre">PunktSentenceTokenizer.dump()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktSentenceTokenizer.sentences_from_text"><code class="docutils literal notranslate"><span class="pre">PunktSentenceTokenizer.sentences_from_text()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktSentenceTokenizer.sentences_from_text_legacy"><code class="docutils literal notranslate"><span class="pre">PunktSentenceTokenizer.sentences_from_text_legacy()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktSentenceTokenizer.sentences_from_tokens"><code class="docutils literal notranslate"><span class="pre">PunktSentenceTokenizer.sentences_from_tokens()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktSentenceTokenizer.span_tokenize"><code class="docutils literal notranslate"><span class="pre">PunktSentenceTokenizer.span_tokenize()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktSentenceTokenizer.text_contains_sentbreak"><code class="docutils literal notranslate"><span class="pre">PunktSentenceTokenizer.text_contains_sentbreak()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktSentenceTokenizer.tokenize"><code class="docutils literal notranslate"><span class="pre">PunktSentenceTokenizer.tokenize()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktSentenceTokenizer.train"><code class="docutils literal notranslate"><span class="pre">PunktSentenceTokenizer.train()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktToken"><code class="docutils literal notranslate"><span class="pre">PunktToken</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktToken.__init__"><code class="docutils literal notranslate"><span class="pre">PunktToken.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktToken.abbr"><code class="docutils literal notranslate"><span class="pre">PunktToken.abbr</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktToken.ellipsis"><code class="docutils literal notranslate"><span class="pre">PunktToken.ellipsis</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktToken.first_case"><code class="docutils literal notranslate"><span class="pre">PunktToken.first_case</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktToken.first_lower"><code class="docutils literal notranslate"><span class="pre">PunktToken.first_lower</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktToken.first_upper"><code class="docutils literal notranslate"><span class="pre">PunktToken.first_upper</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktToken.is_alpha"><code class="docutils literal notranslate"><span class="pre">PunktToken.is_alpha</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktToken.is_ellipsis"><code class="docutils literal notranslate"><span class="pre">PunktToken.is_ellipsis</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktToken.is_initial"><code class="docutils literal notranslate"><span class="pre">PunktToken.is_initial</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktToken.is_non_punct"><code class="docutils literal notranslate"><span class="pre">PunktToken.is_non_punct</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktToken.is_number"><code class="docutils literal notranslate"><span class="pre">PunktToken.is_number</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktToken.linestart"><code class="docutils literal notranslate"><span class="pre">PunktToken.linestart</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktToken.parastart"><code class="docutils literal notranslate"><span class="pre">PunktToken.parastart</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktToken.period_final"><code class="docutils literal notranslate"><span class="pre">PunktToken.period_final</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktToken.sentbreak"><code class="docutils literal notranslate"><span class="pre">PunktToken.sentbreak</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktToken.tok"><code class="docutils literal notranslate"><span class="pre">PunktToken.tok</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktToken.type"><code class="docutils literal notranslate"><span class="pre">PunktToken.type</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktToken.type_no_period"><code class="docutils literal notranslate"><span class="pre">PunktToken.type_no_period</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktToken.type_no_sentperiod"><code class="docutils literal notranslate"><span class="pre">PunktToken.type_no_sentperiod</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktTokenizer"><code class="docutils literal notranslate"><span class="pre">PunktTokenizer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktTokenizer.__init__"><code class="docutils literal notranslate"><span class="pre">PunktTokenizer.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktTokenizer.load_lang"><code class="docutils literal notranslate"><span class="pre">PunktTokenizer.load_lang()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktTokenizer.save_params"><code class="docutils literal notranslate"><span class="pre">PunktTokenizer.save_params()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktTrainer"><code class="docutils literal notranslate"><span class="pre">PunktTrainer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktTrainer.ABBREV"><code class="docutils literal notranslate"><span class="pre">PunktTrainer.ABBREV</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktTrainer.ABBREV_BACKOFF"><code class="docutils literal notranslate"><span class="pre">PunktTrainer.ABBREV_BACKOFF</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktTrainer.COLLOCATION"><code class="docutils literal notranslate"><span class="pre">PunktTrainer.COLLOCATION</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktTrainer.IGNORE_ABBREV_PENALTY"><code class="docutils literal notranslate"><span class="pre">PunktTrainer.IGNORE_ABBREV_PENALTY</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktTrainer.INCLUDE_ABBREV_COLLOCS"><code class="docutils literal notranslate"><span class="pre">PunktTrainer.INCLUDE_ABBREV_COLLOCS</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktTrainer.INCLUDE_ALL_COLLOCS"><code class="docutils literal notranslate"><span class="pre">PunktTrainer.INCLUDE_ALL_COLLOCS</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktTrainer.MIN_COLLOC_FREQ"><code class="docutils literal notranslate"><span class="pre">PunktTrainer.MIN_COLLOC_FREQ</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktTrainer.SENT_STARTER"><code class="docutils literal notranslate"><span class="pre">PunktTrainer.SENT_STARTER</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktTrainer.__init__"><code class="docutils literal notranslate"><span class="pre">PunktTrainer.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktTrainer.finalize_training"><code class="docutils literal notranslate"><span class="pre">PunktTrainer.finalize_training()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktTrainer.find_abbrev_types"><code class="docutils literal notranslate"><span class="pre">PunktTrainer.find_abbrev_types()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktTrainer.freq_threshold"><code class="docutils literal notranslate"><span class="pre">PunktTrainer.freq_threshold()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktTrainer.get_params"><code class="docutils literal notranslate"><span class="pre">PunktTrainer.get_params()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktTrainer.train"><code class="docutils literal notranslate"><span class="pre">PunktTrainer.train()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktTrainer.train_tokens"><code class="docutils literal notranslate"><span class="pre">PunktTrainer.train_tokens()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.demo"><code class="docutils literal notranslate"><span class="pre">demo()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.format_debug_decision"><code class="docutils literal notranslate"><span class="pre">format_debug_decision()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.load_punkt_params"><code class="docutils literal notranslate"><span class="pre">load_punkt_params()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.save_punkt_params"><code class="docutils literal notranslate"><span class="pre">save_punkt_params()</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nltk.tokenize.regexp.html">nltk.tokenize.regexp module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.regexp.html#nltk.tokenize.regexp.BlanklineTokenizer"><code class="docutils literal notranslate"><span class="pre">BlanklineTokenizer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.regexp.html#nltk.tokenize.regexp.BlanklineTokenizer.__init__"><code class="docutils literal notranslate"><span class="pre">BlanklineTokenizer.__init__()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.regexp.html#nltk.tokenize.regexp.RegexpTokenizer"><code class="docutils literal notranslate"><span class="pre">RegexpTokenizer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.regexp.html#nltk.tokenize.regexp.RegexpTokenizer.__init__"><code class="docutils literal notranslate"><span class="pre">RegexpTokenizer.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.regexp.html#nltk.tokenize.regexp.RegexpTokenizer.span_tokenize"><code class="docutils literal notranslate"><span class="pre">RegexpTokenizer.span_tokenize()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.regexp.html#nltk.tokenize.regexp.RegexpTokenizer.tokenize"><code class="docutils literal notranslate"><span class="pre">RegexpTokenizer.tokenize()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.regexp.html#nltk.tokenize.regexp.WhitespaceTokenizer"><code class="docutils literal notranslate"><span class="pre">WhitespaceTokenizer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.regexp.html#nltk.tokenize.regexp.WhitespaceTokenizer.__init__"><code class="docutils literal notranslate"><span class="pre">WhitespaceTokenizer.__init__()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.regexp.html#nltk.tokenize.regexp.WordPunctTokenizer"><code class="docutils literal notranslate"><span class="pre">WordPunctTokenizer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.regexp.html#nltk.tokenize.regexp.WordPunctTokenizer.__init__"><code class="docutils literal notranslate"><span class="pre">WordPunctTokenizer.__init__()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.regexp.html#nltk.tokenize.regexp.blankline_tokenize"><code class="docutils literal notranslate"><span class="pre">blankline_tokenize()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.regexp.html#nltk.tokenize.regexp.regexp_tokenize"><code class="docutils literal notranslate"><span class="pre">regexp_tokenize()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.regexp.html#nltk.tokenize.regexp.wordpunct_tokenize"><code class="docutils literal notranslate"><span class="pre">wordpunct_tokenize()</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nltk.tokenize.repp.html">nltk.tokenize.repp module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.repp.html#nltk.tokenize.repp.ReppTokenizer"><code class="docutils literal notranslate"><span class="pre">ReppTokenizer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.repp.html#nltk.tokenize.repp.ReppTokenizer.__init__"><code class="docutils literal notranslate"><span class="pre">ReppTokenizer.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.repp.html#nltk.tokenize.repp.ReppTokenizer.find_repptokenizer"><code class="docutils literal notranslate"><span class="pre">ReppTokenizer.find_repptokenizer()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.repp.html#nltk.tokenize.repp.ReppTokenizer.generate_repp_command"><code class="docutils literal notranslate"><span class="pre">ReppTokenizer.generate_repp_command()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.repp.html#nltk.tokenize.repp.ReppTokenizer.parse_repp_outputs"><code class="docutils literal notranslate"><span class="pre">ReppTokenizer.parse_repp_outputs()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.repp.html#nltk.tokenize.repp.ReppTokenizer.tokenize"><code class="docutils literal notranslate"><span class="pre">ReppTokenizer.tokenize()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.repp.html#nltk.tokenize.repp.ReppTokenizer.tokenize_sents"><code class="docutils literal notranslate"><span class="pre">ReppTokenizer.tokenize_sents()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nltk.tokenize.sexpr.html">nltk.tokenize.sexpr module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.sexpr.html#nltk.tokenize.sexpr.SExprTokenizer"><code class="docutils literal notranslate"><span class="pre">SExprTokenizer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.sexpr.html#nltk.tokenize.sexpr.SExprTokenizer.__init__"><code class="docutils literal notranslate"><span class="pre">SExprTokenizer.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.sexpr.html#nltk.tokenize.sexpr.SExprTokenizer.tokenize"><code class="docutils literal notranslate"><span class="pre">SExprTokenizer.tokenize()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.sexpr.html#nltk.tokenize.sexpr.sexpr_tokenize"><code class="docutils literal notranslate"><span class="pre">sexpr_tokenize()</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nltk.tokenize.simple.html">nltk.tokenize.simple module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.simple.html#nltk.tokenize.simple.CharTokenizer"><code class="docutils literal notranslate"><span class="pre">CharTokenizer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.simple.html#nltk.tokenize.simple.CharTokenizer.span_tokenize"><code class="docutils literal notranslate"><span class="pre">CharTokenizer.span_tokenize()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.simple.html#nltk.tokenize.simple.CharTokenizer.tokenize"><code class="docutils literal notranslate"><span class="pre">CharTokenizer.tokenize()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.simple.html#nltk.tokenize.simple.LineTokenizer"><code class="docutils literal notranslate"><span class="pre">LineTokenizer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.simple.html#nltk.tokenize.simple.LineTokenizer.__init__"><code class="docutils literal notranslate"><span class="pre">LineTokenizer.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.simple.html#nltk.tokenize.simple.LineTokenizer.span_tokenize"><code class="docutils literal notranslate"><span class="pre">LineTokenizer.span_tokenize()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.simple.html#nltk.tokenize.simple.LineTokenizer.tokenize"><code class="docutils literal notranslate"><span class="pre">LineTokenizer.tokenize()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.simple.html#nltk.tokenize.simple.SpaceTokenizer"><code class="docutils literal notranslate"><span class="pre">SpaceTokenizer</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.simple.html#nltk.tokenize.simple.TabTokenizer"><code class="docutils literal notranslate"><span class="pre">TabTokenizer</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.simple.html#nltk.tokenize.simple.line_tokenize"><code class="docutils literal notranslate"><span class="pre">line_tokenize()</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nltk.tokenize.sonority_sequencing.html">nltk.tokenize.sonority_sequencing module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.sonority_sequencing.html#nltk.tokenize.sonority_sequencing.SyllableTokenizer"><code class="docutils literal notranslate"><span class="pre">SyllableTokenizer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.sonority_sequencing.html#nltk.tokenize.sonority_sequencing.SyllableTokenizer.__init__"><code class="docutils literal notranslate"><span class="pre">SyllableTokenizer.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.sonority_sequencing.html#nltk.tokenize.sonority_sequencing.SyllableTokenizer.assign_values"><code class="docutils literal notranslate"><span class="pre">SyllableTokenizer.assign_values()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.sonority_sequencing.html#nltk.tokenize.sonority_sequencing.SyllableTokenizer.tokenize"><code class="docutils literal notranslate"><span class="pre">SyllableTokenizer.tokenize()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.sonority_sequencing.html#nltk.tokenize.sonority_sequencing.SyllableTokenizer.validate_syllables"><code class="docutils literal notranslate"><span class="pre">SyllableTokenizer.validate_syllables()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nltk.tokenize.stanford.html">nltk.tokenize.stanford module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.stanford.html#nltk.tokenize.stanford.StanfordTokenizer"><code class="docutils literal notranslate"><span class="pre">StanfordTokenizer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.stanford.html#nltk.tokenize.stanford.StanfordTokenizer.__init__"><code class="docutils literal notranslate"><span class="pre">StanfordTokenizer.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.stanford.html#nltk.tokenize.stanford.StanfordTokenizer.tokenize"><code class="docutils literal notranslate"><span class="pre">StanfordTokenizer.tokenize()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nltk.tokenize.stanford_segmenter.html">nltk.tokenize.stanford_segmenter module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.stanford_segmenter.html#nltk.tokenize.stanford_segmenter.StanfordSegmenter"><code class="docutils literal notranslate"><span class="pre">StanfordSegmenter</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.stanford_segmenter.html#nltk.tokenize.stanford_segmenter.StanfordSegmenter.__init__"><code class="docutils literal notranslate"><span class="pre">StanfordSegmenter.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.stanford_segmenter.html#nltk.tokenize.stanford_segmenter.StanfordSegmenter.default_config"><code class="docutils literal notranslate"><span class="pre">StanfordSegmenter.default_config()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.stanford_segmenter.html#nltk.tokenize.stanford_segmenter.StanfordSegmenter.segment"><code class="docutils literal notranslate"><span class="pre">StanfordSegmenter.segment()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.stanford_segmenter.html#nltk.tokenize.stanford_segmenter.StanfordSegmenter.segment_file"><code class="docutils literal notranslate"><span class="pre">StanfordSegmenter.segment_file()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.stanford_segmenter.html#nltk.tokenize.stanford_segmenter.StanfordSegmenter.segment_sents"><code class="docutils literal notranslate"><span class="pre">StanfordSegmenter.segment_sents()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.stanford_segmenter.html#nltk.tokenize.stanford_segmenter.StanfordSegmenter.tokenize"><code class="docutils literal notranslate"><span class="pre">StanfordSegmenter.tokenize()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nltk.tokenize.texttiling.html">nltk.tokenize.texttiling module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.texttiling.html#nltk.tokenize.texttiling.TextTilingTokenizer"><code class="docutils literal notranslate"><span class="pre">TextTilingTokenizer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.texttiling.html#nltk.tokenize.texttiling.TextTilingTokenizer.__init__"><code class="docutils literal notranslate"><span class="pre">TextTilingTokenizer.__init__()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.texttiling.html#nltk.tokenize.texttiling.TextTilingTokenizer.tokenize"><code class="docutils literal notranslate"><span class="pre">TextTilingTokenizer.tokenize()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.texttiling.html#nltk.tokenize.texttiling.TokenSequence"><code class="docutils literal notranslate"><span class="pre">TokenSequence</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.texttiling.html#nltk.tokenize.texttiling.TokenSequence.__init__"><code class="docutils literal notranslate"><span class="pre">TokenSequence.__init__()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.texttiling.html#nltk.tokenize.texttiling.TokenTableField"><code class="docutils literal notranslate"><span class="pre">TokenTableField</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.texttiling.html#nltk.tokenize.texttiling.TokenTableField.__init__"><code class="docutils literal notranslate"><span class="pre">TokenTableField.__init__()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.texttiling.html#nltk.tokenize.texttiling.demo"><code class="docutils literal notranslate"><span class="pre">demo()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.texttiling.html#nltk.tokenize.texttiling.smooth"><code class="docutils literal notranslate"><span class="pre">smooth()</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nltk.tokenize.toktok.html">nltk.tokenize.toktok module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.AMPERCENT"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.AMPERCENT</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.CLOSE_PUNCT"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.CLOSE_PUNCT</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.CLOSE_PUNCT_RE"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.CLOSE_PUNCT_RE</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.COMMA_IN_NUM"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.COMMA_IN_NUM</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.CURRENCY_SYM"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.CURRENCY_SYM</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.CURRENCY_SYM_RE"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.CURRENCY_SYM_RE</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.EN_EM_DASHES"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.EN_EM_DASHES</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.FINAL_PERIOD_1"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.FINAL_PERIOD_1</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.FINAL_PERIOD_2"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.FINAL_PERIOD_2</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.FUNKY_PUNCT_1"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.FUNKY_PUNCT_1</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.FUNKY_PUNCT_2"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.FUNKY_PUNCT_2</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.LSTRIP"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.LSTRIP</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.MULTI_COMMAS"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.MULTI_COMMAS</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.MULTI_DASHES"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.MULTI_DASHES</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.MULTI_DOTS"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.MULTI_DOTS</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.NON_BREAKING"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.NON_BREAKING</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.ONE_SPACE"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.ONE_SPACE</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.OPEN_PUNCT"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.OPEN_PUNCT</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.OPEN_PUNCT_RE"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.OPEN_PUNCT_RE</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.PIPE"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.PIPE</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.PROB_SINGLE_QUOTES"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.PROB_SINGLE_QUOTES</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.RSTRIP"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.RSTRIP</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.STUPID_QUOTES_1"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.STUPID_QUOTES_1</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.STUPID_QUOTES_2"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.STUPID_QUOTES_2</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.TAB"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.TAB</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.TOKTOK_REGEXES"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.TOKTOK_REGEXES</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.URL_FOE_1"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.URL_FOE_1</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.URL_FOE_2"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.URL_FOE_2</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.URL_FOE_3"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.URL_FOE_3</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.URL_FOE_4"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.URL_FOE_4</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.toktok.html#nltk.tokenize.toktok.ToktokTokenizer.tokenize"><code class="docutils literal notranslate"><span class="pre">ToktokTokenizer.tokenize()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nltk.tokenize.treebank.html">nltk.tokenize.treebank module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.treebank.html#nltk.tokenize.treebank.TreebankWordDetokenizer"><code class="docutils literal notranslate"><span class="pre">TreebankWordDetokenizer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.treebank.html#nltk.tokenize.treebank.TreebankWordDetokenizer.CONTRACTIONS2"><code class="docutils literal notranslate"><span class="pre">TreebankWordDetokenizer.CONTRACTIONS2</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.treebank.html#nltk.tokenize.treebank.TreebankWordDetokenizer.CONTRACTIONS3"><code class="docutils literal notranslate"><span class="pre">TreebankWordDetokenizer.CONTRACTIONS3</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.treebank.html#nltk.tokenize.treebank.TreebankWordDetokenizer.CONVERT_PARENTHESES"><code class="docutils literal notranslate"><span class="pre">TreebankWordDetokenizer.CONVERT_PARENTHESES</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.treebank.html#nltk.tokenize.treebank.TreebankWordDetokenizer.DOUBLE_DASHES"><code class="docutils literal notranslate"><span class="pre">TreebankWordDetokenizer.DOUBLE_DASHES</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.treebank.html#nltk.tokenize.treebank.TreebankWordDetokenizer.ENDING_QUOTES"><code class="docutils literal notranslate"><span class="pre">TreebankWordDetokenizer.ENDING_QUOTES</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.treebank.html#nltk.tokenize.treebank.TreebankWordDetokenizer.PARENS_BRACKETS"><code class="docutils literal notranslate"><span class="pre">TreebankWordDetokenizer.PARENS_BRACKETS</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.treebank.html#nltk.tokenize.treebank.TreebankWordDetokenizer.PUNCTUATION"><code class="docutils literal notranslate"><span class="pre">TreebankWordDetokenizer.PUNCTUATION</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.treebank.html#nltk.tokenize.treebank.TreebankWordDetokenizer.STARTING_QUOTES"><code class="docutils literal notranslate"><span class="pre">TreebankWordDetokenizer.STARTING_QUOTES</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.treebank.html#nltk.tokenize.treebank.TreebankWordDetokenizer.detokenize"><code class="docutils literal notranslate"><span class="pre">TreebankWordDetokenizer.detokenize()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.treebank.html#nltk.tokenize.treebank.TreebankWordDetokenizer.tokenize"><code class="docutils literal notranslate"><span class="pre">TreebankWordDetokenizer.tokenize()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.treebank.html#nltk.tokenize.treebank.TreebankWordTokenizer"><code class="docutils literal notranslate"><span class="pre">TreebankWordTokenizer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.treebank.html#nltk.tokenize.treebank.TreebankWordTokenizer.CONTRACTIONS2"><code class="docutils literal notranslate"><span class="pre">TreebankWordTokenizer.CONTRACTIONS2</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.treebank.html#nltk.tokenize.treebank.TreebankWordTokenizer.CONTRACTIONS3"><code class="docutils literal notranslate"><span class="pre">TreebankWordTokenizer.CONTRACTIONS3</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.treebank.html#nltk.tokenize.treebank.TreebankWordTokenizer.CONVERT_PARENTHESES"><code class="docutils literal notranslate"><span class="pre">TreebankWordTokenizer.CONVERT_PARENTHESES</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.treebank.html#nltk.tokenize.treebank.TreebankWordTokenizer.DOUBLE_DASHES"><code class="docutils literal notranslate"><span class="pre">TreebankWordTokenizer.DOUBLE_DASHES</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.treebank.html#nltk.tokenize.treebank.TreebankWordTokenizer.ENDING_QUOTES"><code class="docutils literal notranslate"><span class="pre">TreebankWordTokenizer.ENDING_QUOTES</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.treebank.html#nltk.tokenize.treebank.TreebankWordTokenizer.PARENS_BRACKETS"><code class="docutils literal notranslate"><span class="pre">TreebankWordTokenizer.PARENS_BRACKETS</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.treebank.html#nltk.tokenize.treebank.TreebankWordTokenizer.PUNCTUATION"><code class="docutils literal notranslate"><span class="pre">TreebankWordTokenizer.PUNCTUATION</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.treebank.html#nltk.tokenize.treebank.TreebankWordTokenizer.STARTING_QUOTES"><code class="docutils literal notranslate"><span class="pre">TreebankWordTokenizer.STARTING_QUOTES</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.treebank.html#nltk.tokenize.treebank.TreebankWordTokenizer.span_tokenize"><code class="docutils literal notranslate"><span class="pre">TreebankWordTokenizer.span_tokenize()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.treebank.html#nltk.tokenize.treebank.TreebankWordTokenizer.tokenize"><code class="docutils literal notranslate"><span class="pre">TreebankWordTokenizer.tokenize()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nltk.tokenize.util.html">nltk.tokenize.util module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.util.html#nltk.tokenize.util.CJKChars"><code class="docutils literal notranslate"><span class="pre">CJKChars</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.util.html#nltk.tokenize.util.CJKChars.CJK_Compatibility_Forms"><code class="docutils literal notranslate"><span class="pre">CJKChars.CJK_Compatibility_Forms</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.util.html#nltk.tokenize.util.CJKChars.CJK_Compatibility_Ideographs"><code class="docutils literal notranslate"><span class="pre">CJKChars.CJK_Compatibility_Ideographs</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.util.html#nltk.tokenize.util.CJKChars.CJK_Radicals"><code class="docutils literal notranslate"><span class="pre">CJKChars.CJK_Radicals</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.util.html#nltk.tokenize.util.CJKChars.Hangul_Jamo"><code class="docutils literal notranslate"><span class="pre">CJKChars.Hangul_Jamo</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.util.html#nltk.tokenize.util.CJKChars.Hangul_Syllables"><code class="docutils literal notranslate"><span class="pre">CJKChars.Hangul_Syllables</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.util.html#nltk.tokenize.util.CJKChars.Katakana_Hangul_Halfwidth"><code class="docutils literal notranslate"><span class="pre">CJKChars.Katakana_Hangul_Halfwidth</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.util.html#nltk.tokenize.util.CJKChars.Phags_Pa"><code class="docutils literal notranslate"><span class="pre">CJKChars.Phags_Pa</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.util.html#nltk.tokenize.util.CJKChars.Supplementary_Ideographic_Plane"><code class="docutils literal notranslate"><span class="pre">CJKChars.Supplementary_Ideographic_Plane</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="nltk.tokenize.util.html#nltk.tokenize.util.CJKChars.ranges"><code class="docutils literal notranslate"><span class="pre">CJKChars.ranges</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.util.html#nltk.tokenize.util.align_tokens"><code class="docutils literal notranslate"><span class="pre">align_tokens()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.util.html#nltk.tokenize.util.is_cjk"><code class="docutils literal notranslate"><span class="pre">is_cjk()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.util.html#nltk.tokenize.util.regexp_span_tokenize"><code class="docutils literal notranslate"><span class="pre">regexp_span_tokenize()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.util.html#nltk.tokenize.util.spans_to_relative"><code class="docutils literal notranslate"><span class="pre">spans_to_relative()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.util.html#nltk.tokenize.util.string_span_tokenize"><code class="docutils literal notranslate"><span class="pre">string_span_tokenize()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.util.html#nltk.tokenize.util.xml_escape"><code class="docutils literal notranslate"><span class="pre">xml_escape()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="nltk.tokenize.util.html#nltk.tokenize.util.xml_unescape"><code class="docutils literal notranslate"><span class="pre">xml_unescape()</span></code></a></li>
</ul>
</li>
</ul>
</div>
</section>
<section id="module-nltk.tokenize">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-nltk.tokenize" title="Link to this heading">¶</a></h2>
<p>NLTK Tokenizer Package</p>
<p>Tokenizers divide strings into lists of substrings.  For example,
tokenizers can be used to find the words and punctuation in a string:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">word_tokenize</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span> <span class="o">=</span> <span class="s1">&#39;&#39;&#39;Good muffins cost $3.88</span><span class="se">\n</span><span class="s1">in New York.  Please buy me</span>
<span class="gp">... </span><span class="s1">two of them.</span><span class="se">\n\n</span><span class="s1">Thanks.&#39;&#39;&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> 
<span class="go">[&#39;Good&#39;, &#39;muffins&#39;, &#39;cost&#39;, &#39;$&#39;, &#39;3.88&#39;, &#39;in&#39;, &#39;New&#39;, &#39;York&#39;, &#39;.&#39;,</span>
<span class="go">&#39;Please&#39;, &#39;buy&#39;, &#39;me&#39;, &#39;two&#39;, &#39;of&#39;, &#39;them&#39;, &#39;.&#39;, &#39;Thanks&#39;, &#39;.&#39;]</span>
</pre></div>
</div>
<p>This particular tokenizer requires the Punkt sentence tokenization
models to be installed. NLTK also provides a simpler,
regular-expression based tokenizer, which splits text on whitespace
and punctuation:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">wordpunct_tokenize</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">wordpunct_tokenize</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> 
<span class="go">[&#39;Good&#39;, &#39;muffins&#39;, &#39;cost&#39;, &#39;$&#39;, &#39;3&#39;, &#39;.&#39;, &#39;88&#39;, &#39;in&#39;, &#39;New&#39;, &#39;York&#39;, &#39;.&#39;,</span>
<span class="go">&#39;Please&#39;, &#39;buy&#39;, &#39;me&#39;, &#39;two&#39;, &#39;of&#39;, &#39;them&#39;, &#39;.&#39;, &#39;Thanks&#39;, &#39;.&#39;]</span>
</pre></div>
</div>
<p>We can also operate at the level of sentences, using the sentence
tokenizer directly as follows:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">sent_tokenize</span><span class="p">,</span> <span class="n">word_tokenize</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sent_tokenize</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
<span class="go">[&#39;Good muffins cost $3.88\nin New York.&#39;, &#39;Please buy me\ntwo of them.&#39;, &#39;Thanks.&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">[</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">sent_tokenize</span><span class="p">(</span><span class="n">s</span><span class="p">)]</span> 
<span class="go">[[&#39;Good&#39;, &#39;muffins&#39;, &#39;cost&#39;, &#39;$&#39;, &#39;3.88&#39;, &#39;in&#39;, &#39;New&#39;, &#39;York&#39;, &#39;.&#39;],</span>
<span class="go">[&#39;Please&#39;, &#39;buy&#39;, &#39;me&#39;, &#39;two&#39;, &#39;of&#39;, &#39;them&#39;, &#39;.&#39;], [&#39;Thanks&#39;, &#39;.&#39;]]</span>
</pre></div>
</div>
<p>Caution: when tokenizing a Unicode string, make sure you are not
using an encoded version of the string (it may be necessary to
decode it first, e.g. with <code class="docutils literal notranslate"><span class="pre">s.decode(&quot;utf8&quot;)</span></code>.</p>
<p>NLTK tokenizers can produce token-spans, represented as tuples of integers
having the same semantics as string slices, to support efficient comparison
of tokenizers.  (These methods are implemented as generators.)</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">WhitespaceTokenizer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">list</span><span class="p">(</span><span class="n">WhitespaceTokenizer</span><span class="p">()</span><span class="o">.</span><span class="n">span_tokenize</span><span class="p">(</span><span class="n">s</span><span class="p">))</span> 
<span class="go">[(0, 4), (5, 12), (13, 17), (18, 23), (24, 26), (27, 30), (31, 36), (38, 44),</span>
<span class="go">(45, 48), (49, 51), (52, 55), (56, 58), (59, 64), (66, 73)]</span>
</pre></div>
</div>
<p>There are numerous ways to tokenize text.  If you need more control over
tokenization, see the other methods provided in this package.</p>
<p>For further information, please see Chapter 3 of the NLTK book.</p>
<dl class="py function">
<dt class="sig sig-object py" id="nltk.tokenize.sent_tokenize">
<span class="sig-prename descclassname"><span class="pre">nltk.tokenize.</span></span><span class="sig-name descname"><span class="pre">sent_tokenize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">language</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'english'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/tokenize.html#sent_tokenize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nltk.tokenize.sent_tokenize" title="Link to this definition">¶</a></dt>
<dd><p>Return a sentence-tokenized copy of <em>text</em>,
using NLTK’s recommended sentence tokenizer
(currently <a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktSentenceTokenizer" title="nltk.tokenize.punkt.PunktSentenceTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">PunktSentenceTokenizer</span></code></a>
for the specified language).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> – text to split into sentences</p></li>
<li><p><strong>language</strong> – the model name in the Punkt corpus</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nltk.tokenize.word_tokenize">
<span class="sig-prename descclassname"><span class="pre">nltk.tokenize.</span></span><span class="sig-name descname"><span class="pre">word_tokenize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">language</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'english'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preserve_line</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/tokenize.html#word_tokenize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nltk.tokenize.word_tokenize" title="Link to this definition">¶</a></dt>
<dd><p>Return a tokenized copy of <em>text</em>,
using NLTK’s recommended word tokenizer
(currently an improved <a class="reference internal" href="nltk.tokenize.treebank.html#nltk.tokenize.treebank.TreebankWordTokenizer" title="nltk.tokenize.treebank.TreebankWordTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">TreebankWordTokenizer</span></code></a>
along with <a class="reference internal" href="nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktSentenceTokenizer" title="nltk.tokenize.punkt.PunktSentenceTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">PunktSentenceTokenizer</span></code></a>
for the specified language).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) – text to split into words</p></li>
<li><p><strong>language</strong> (<em>str</em>) – the model name in the Punkt corpus</p></li>
<li><p><strong>preserve_line</strong> (<em>bool</em>) – A flag to decide whether to sentence tokenize the text or not.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
</section>


        </div>
      </div>

    </div>

<footer>
    <div id="footer-info">
        <ul id="build-details">
            
                <li class="footer-element">
                    
                        <a href="../_sources/api/nltk.tokenize.rst.txt" rel="nofollow"> source</a>
                    
                </li>
            

            
                <li class="footer-element">
                    <a href="https://github.com/nltk/nltk/tree/3.9.1">3.9.1</a>
                </li>
            

            
                <li class="footer-element">
                    Aug 19, 2024
                </li>
            
        </ul>

        
            <div id="copyright">
                &copy; 2024, NLTK Project
            </div>
        

        <div id="credit">
            created with <a href="http://sphinx-doc.org/">Sphinx</a> and <a href="https://github.com/tomaarsen/nltk_theme">NLTK Theme</a>
        </div>
    </div>
</footer> 

</div>

</body>
</html>