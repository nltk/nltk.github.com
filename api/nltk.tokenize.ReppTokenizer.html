<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="theme-color" content="#2D2D2D" />
  
  <title>NLTK :: nltk.tokenize.ReppTokenizer</title>
  

  <link rel="stylesheet" href="../_static/css/nltk_theme.css"/>
  <link rel="stylesheet" href="../_static/css/custom.css"/>

  <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
  

  <script src="https://email.tl.fortawesome.com/c/eJxNjUEOgyAQAF8jR7Kw6wIHDh7sP1Cw2mgxgmn6-3JsMqc5zEQfE8dkxOY1KKMUOI3ACFKRJpSW2AAp7ontYIaxI6i7XPJVwyeVfCQ550Os3jLrGSNOLgbdAy6s0PBk2TFNjEbsfq31LB0OnX407pJa5v2faRadwSW63mn5KuLyR9j2tgx3zecanl-55R_-jjPs"></script> 
</head>

<body>
  <div id="nltk-theme-container">
    <header>
      <div id="logo-container">
          
          <h1>
            <a href="../index.html">NLTK</a>
          </h1>
          
      </div>
      <div id="project-container">
        
        <h1>Documentation</h1>
        
      </div>

      <a id="menu-toggle" class="fa fa-bars" aria-hidden="true"></a>

      <script type="text/javascript">
        $("#menu-toggle").click(function() {
          $("#menu-toggle").toggleClass("toggled");
          $("#side-menu-container").slideToggle(300);
        });
      </script>
    </header>

    <div id="content-container">

      <div id="side-menu-container">

        <div id="search" role="search">
        <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
            <input type="text" name="q" placeholder="Search" />
            <input type="hidden" name="check_keywords" value="yes" />
            <input type="hidden" name="area" value="default" />
        </form>
</div>

        <div id="side-menu" role="navigation">
          
  
    
  
  
    <p class="caption" role="heading"><span class="caption-text">NLTK Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="nltk.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../howto.html">Example Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../py-modindex.html">Module Index</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk/wiki">Wiki</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk/wiki/FAQ">FAQ</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk/issues">Open Issues</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk">NLTK on GitHub</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installing NLTK</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data.html">Installing NLTK Data</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contribute.html">Contributing to NLTK</a></li>
<li class="toctree-l1"><a class="reference internal" href="../team.html">NLTK Team</a></li>
</ul>

  

        </div>

        
      </div>

      <div id="main-content-container">
        <div id="main-content" role="main">
          
  <section id="nltk-tokenize-repptokenizer">
<h1>nltk.tokenize.ReppTokenizer<a class="headerlink" href="#nltk-tokenize-repptokenizer" title="Permalink to this heading">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="nltk.tokenize.ReppTokenizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">nltk.tokenize.</span></span><span class="sig-name descname"><span class="pre">ReppTokenizer</span></span><a class="reference internal" href="../_modules/nltk/tokenize/repp.html#ReppTokenizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nltk.tokenize.ReppTokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="nltk.tokenize.api.html#nltk.tokenize.api.TokenizerI" title="nltk.tokenize.api.TokenizerI"><code class="xref py py-class docutils literal notranslate"><span class="pre">TokenizerI</span></code></a></p>
<p>A class for word tokenization using the REPP parser described in
Rebecca Dridan and Stephan Oepen (2012) Tokenization: Returning to a
Long Solved Problem - A Survey, Contrastive  Experiment, Recommendations,
and Toolkit. In ACL. <a class="reference external" href="http://anthology.aclweb.org/P/P12/P12-2.pdf#page=406">http://anthology.aclweb.org/P/P12/P12-2.pdf#page=406</a></p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sents</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Tokenization is widely regarded as a solved problem due to the high accuracy that rulebased tokenizers achieve.&#39;</span> <span class="p">,</span>
<span class="gp">... </span><span class="s1">&#39;But rule-based tokenizers are hard to maintain and their rules language specific.&#39;</span> <span class="p">,</span>
<span class="gp">... </span><span class="s1">&#39;We evaluated our method on three languages and obtained error rates of 0.27% (English), 0.35% (Dutch) and 0.76% (Italian) for our best models.&#39;</span>
<span class="gp">... </span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">ReppTokenizer</span><span class="p">(</span><span class="s1">&#39;/home/alvas/repp/&#39;</span><span class="p">)</span> 
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">sents</span><span class="p">:</span>                             
<span class="gp">... </span>    <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span>                   
<span class="gp">...</span>
<span class="go">(u&#39;Tokenization&#39;, u&#39;is&#39;, u&#39;widely&#39;, u&#39;regarded&#39;, u&#39;as&#39;, u&#39;a&#39;, u&#39;solved&#39;, u&#39;problem&#39;, u&#39;due&#39;, u&#39;to&#39;, u&#39;the&#39;, u&#39;high&#39;, u&#39;accuracy&#39;, u&#39;that&#39;, u&#39;rulebased&#39;, u&#39;tokenizers&#39;, u&#39;achieve&#39;, u&#39;.&#39;)</span>
<span class="go">(u&#39;But&#39;, u&#39;rule-based&#39;, u&#39;tokenizers&#39;, u&#39;are&#39;, u&#39;hard&#39;, u&#39;to&#39;, u&#39;maintain&#39;, u&#39;and&#39;, u&#39;their&#39;, u&#39;rules&#39;, u&#39;language&#39;, u&#39;specific&#39;, u&#39;.&#39;)</span>
<span class="go">(u&#39;We&#39;, u&#39;evaluated&#39;, u&#39;our&#39;, u&#39;method&#39;, u&#39;on&#39;, u&#39;three&#39;, u&#39;languages&#39;, u&#39;and&#39;, u&#39;obtained&#39;, u&#39;error&#39;, u&#39;rates&#39;, u&#39;of&#39;, u&#39;0.27&#39;, u&#39;%&#39;, u&#39;(&#39;, u&#39;English&#39;, u&#39;)&#39;, u&#39;,&#39;, u&#39;0.35&#39;, u&#39;%&#39;, u&#39;(&#39;, u&#39;Dutch&#39;, u&#39;)&#39;, u&#39;and&#39;, u&#39;0.76&#39;, u&#39;%&#39;, u&#39;(&#39;, u&#39;Italian&#39;, u&#39;)&#39;, u&#39;for&#39;, u&#39;our&#39;, u&#39;best&#39;, u&#39;models&#39;, u&#39;.&#39;)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize_sents</span><span class="p">(</span><span class="n">sents</span><span class="p">):</span> 
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span>                              
<span class="gp">...</span>
<span class="go">(u&#39;Tokenization&#39;, u&#39;is&#39;, u&#39;widely&#39;, u&#39;regarded&#39;, u&#39;as&#39;, u&#39;a&#39;, u&#39;solved&#39;, u&#39;problem&#39;, u&#39;due&#39;, u&#39;to&#39;, u&#39;the&#39;, u&#39;high&#39;, u&#39;accuracy&#39;, u&#39;that&#39;, u&#39;rulebased&#39;, u&#39;tokenizers&#39;, u&#39;achieve&#39;, u&#39;.&#39;)</span>
<span class="go">(u&#39;But&#39;, u&#39;rule-based&#39;, u&#39;tokenizers&#39;, u&#39;are&#39;, u&#39;hard&#39;, u&#39;to&#39;, u&#39;maintain&#39;, u&#39;and&#39;, u&#39;their&#39;, u&#39;rules&#39;, u&#39;language&#39;, u&#39;specific&#39;, u&#39;.&#39;)</span>
<span class="go">(u&#39;We&#39;, u&#39;evaluated&#39;, u&#39;our&#39;, u&#39;method&#39;, u&#39;on&#39;, u&#39;three&#39;, u&#39;languages&#39;, u&#39;and&#39;, u&#39;obtained&#39;, u&#39;error&#39;, u&#39;rates&#39;, u&#39;of&#39;, u&#39;0.27&#39;, u&#39;%&#39;, u&#39;(&#39;, u&#39;English&#39;, u&#39;)&#39;, u&#39;,&#39;, u&#39;0.35&#39;, u&#39;%&#39;, u&#39;(&#39;, u&#39;Dutch&#39;, u&#39;)&#39;, u&#39;and&#39;, u&#39;0.76&#39;, u&#39;%&#39;, u&#39;(&#39;, u&#39;Italian&#39;, u&#39;)&#39;, u&#39;for&#39;, u&#39;our&#39;, u&#39;best&#39;, u&#39;models&#39;, u&#39;.&#39;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize_sents</span><span class="p">(</span><span class="n">sents</span><span class="p">,</span> <span class="n">keep_token_positions</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span> 
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span>                                                         
<span class="gp">...</span>
<span class="go">[(u&#39;Tokenization&#39;, 0, 12), (u&#39;is&#39;, 13, 15), (u&#39;widely&#39;, 16, 22), (u&#39;regarded&#39;, 23, 31), (u&#39;as&#39;, 32, 34), (u&#39;a&#39;, 35, 36), (u&#39;solved&#39;, 37, 43), (u&#39;problem&#39;, 44, 51), (u&#39;due&#39;, 52, 55), (u&#39;to&#39;, 56, 58), (u&#39;the&#39;, 59, 62), (u&#39;high&#39;, 63, 67), (u&#39;accuracy&#39;, 68, 76), (u&#39;that&#39;, 77, 81), (u&#39;rulebased&#39;, 82, 91), (u&#39;tokenizers&#39;, 92, 102), (u&#39;achieve&#39;, 103, 110), (u&#39;.&#39;, 110, 111)]</span>
<span class="go">[(u&#39;But&#39;, 0, 3), (u&#39;rule-based&#39;, 4, 14), (u&#39;tokenizers&#39;, 15, 25), (u&#39;are&#39;, 26, 29), (u&#39;hard&#39;, 30, 34), (u&#39;to&#39;, 35, 37), (u&#39;maintain&#39;, 38, 46), (u&#39;and&#39;, 47, 50), (u&#39;their&#39;, 51, 56), (u&#39;rules&#39;, 57, 62), (u&#39;language&#39;, 63, 71), (u&#39;specific&#39;, 72, 80), (u&#39;.&#39;, 80, 81)]</span>
<span class="go">[(u&#39;We&#39;, 0, 2), (u&#39;evaluated&#39;, 3, 12), (u&#39;our&#39;, 13, 16), (u&#39;method&#39;, 17, 23), (u&#39;on&#39;, 24, 26), (u&#39;three&#39;, 27, 32), (u&#39;languages&#39;, 33, 42), (u&#39;and&#39;, 43, 46), (u&#39;obtained&#39;, 47, 55), (u&#39;error&#39;, 56, 61), (u&#39;rates&#39;, 62, 67), (u&#39;of&#39;, 68, 70), (u&#39;0.27&#39;, 71, 75), (u&#39;%&#39;, 75, 76), (u&#39;(&#39;, 77, 78), (u&#39;English&#39;, 78, 85), (u&#39;)&#39;, 85, 86), (u&#39;,&#39;, 86, 87), (u&#39;0.35&#39;, 88, 92), (u&#39;%&#39;, 92, 93), (u&#39;(&#39;, 94, 95), (u&#39;Dutch&#39;, 95, 100), (u&#39;)&#39;, 100, 101), (u&#39;and&#39;, 102, 105), (u&#39;0.76&#39;, 106, 110), (u&#39;%&#39;, 110, 111), (u&#39;(&#39;, 112, 113), (u&#39;Italian&#39;, 113, 120), (u&#39;)&#39;, 120, 121), (u&#39;for&#39;, 122, 125), (u&#39;our&#39;, 126, 129), (u&#39;best&#39;, 130, 134), (u&#39;models&#39;, 135, 141), (u&#39;.&#39;, 141, 142)]</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="nltk.tokenize.ReppTokenizer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">repp_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'utf8'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/tokenize/repp.html#ReppTokenizer.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nltk.tokenize.ReppTokenizer.__init__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nltk.tokenize.ReppTokenizer.tokenize">
<span class="sig-name descname"><span class="pre">tokenize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sentence</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/tokenize/repp.html#ReppTokenizer.tokenize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nltk.tokenize.ReppTokenizer.tokenize" title="Permalink to this definition">¶</a></dt>
<dd><p>Use Repp to tokenize a single sentence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>sentence</strong> (<em>str</em>) – A single sentence string.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tuple of tokens.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple(str)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nltk.tokenize.ReppTokenizer.tokenize_sents">
<span class="sig-name descname"><span class="pre">tokenize_sents</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sentences</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_token_positions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/tokenize/repp.html#ReppTokenizer.tokenize_sents"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nltk.tokenize.ReppTokenizer.tokenize_sents" title="Permalink to this definition">¶</a></dt>
<dd><p>Tokenize multiple sentences using Repp.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>sentences</strong> (<em>list</em><em>(</em><em>str</em><em>)</em>) – A list of sentence strings.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A list of tuples of tokens</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>iter(tuple(str))</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nltk.tokenize.ReppTokenizer.generate_repp_command">
<span class="sig-name descname"><span class="pre">generate_repp_command</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputfilename</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/tokenize/repp.html#ReppTokenizer.generate_repp_command"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nltk.tokenize.ReppTokenizer.generate_repp_command" title="Permalink to this definition">¶</a></dt>
<dd><p>This module generates the REPP command to be used at the terminal.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputfilename</strong> (<em>str</em>) – path to the input file</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nltk.tokenize.ReppTokenizer.parse_repp_outputs">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">parse_repp_outputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">repp_output</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/tokenize/repp.html#ReppTokenizer.parse_repp_outputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nltk.tokenize.ReppTokenizer.parse_repp_outputs" title="Permalink to this definition">¶</a></dt>
<dd><p>This module parses the tri-tuple format that REPP outputs using the
“–format triple” option and returns an generator with tuple of string
tokens.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>repp_output</strong> (<em>type</em>) – </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>an iterable of the tokenized sentences as tuples of strings</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>iter(tuple)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nltk.tokenize.ReppTokenizer.find_repptokenizer">
<span class="sig-name descname"><span class="pre">find_repptokenizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">repp_dirname</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/tokenize/repp.html#ReppTokenizer.find_repptokenizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nltk.tokenize.ReppTokenizer.find_repptokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>A module to find REPP tokenizer binary and its <em>repp.set</em> config file.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nltk.tokenize.ReppTokenizer.span_tokenize">
<span class="sig-name descname"><span class="pre">span_tokenize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">s</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#nltk.tokenize.ReppTokenizer.span_tokenize" title="Permalink to this definition">¶</a></dt>
<dd><p>Identify the tokens using integer offsets <code class="docutils literal notranslate"><span class="pre">(start_i,</span> <span class="pre">end_i)</span></code>,
where <code class="docutils literal notranslate"><span class="pre">s[start_i:end_i]</span></code> is the corresponding token.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Iterator[Tuple[int, int]]</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><p><strong>s</strong> (<em>str</em>) – </p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nltk.tokenize.ReppTokenizer.span_tokenize_sents">
<span class="sig-name descname"><span class="pre">span_tokenize_sents</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">strings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#nltk.tokenize.ReppTokenizer.span_tokenize_sents" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply <code class="docutils literal notranslate"><span class="pre">self.span_tokenize()</span></code> to each element of <code class="docutils literal notranslate"><span class="pre">strings</span></code>.  I.e.:</p>
<blockquote>
<div><p>return [self.span_tokenize(s) for s in strings]</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Yield</dt>
<dd class="field-odd"><p>List[Tuple[int, int]]</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><p><strong>strings</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – </p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><em>Iterator</em>[<em>List</em>[<em>Tuple</em>[int, int]]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>


        </div>
      </div>

    </div>

<footer>
    <div id="footer-info">
        <ul id="build-details">
            
                <li class="footer-element">
                    
                        <a href="../_sources/api/nltk.tokenize.ReppTokenizer.rst.txt" rel="nofollow"> source</a>
                    
                </li>
            

            
                <li class="footer-element">
                    <a href="https://github.com/nltk/nltk/tree/3.8.1">3.8.1</a>
                </li>
            

            
                <li class="footer-element">
                    Jan 02, 2023
                </li>
            
        </ul>

        
            <div id="copyright">
                &copy; 2023, NLTK Project
            </div>
        

        <div id="credit">
            created with <a href="http://sphinx-doc.org/">Sphinx</a> and <a href="https://github.com/tomaarsen/nltk_theme">NLTK Theme</a>
        </div>
    </div>
</footer> 

</div>

</body>
</html>