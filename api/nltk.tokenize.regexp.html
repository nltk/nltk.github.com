<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="theme-color" content="#2D2D2D" />
  
  <title>NLTK :: nltk.tokenize.regexp module</title>
  

  <link rel="stylesheet" href="../_static/css/nltk_theme.css"/>
  <link rel="stylesheet" href="../_static/css/custom.css"/>

  <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
  

  <script src="https://email.tl.fortawesome.com/c/eJxNjUEOgyAQAF8jR7Kw6wIHDh7sP1Cw2mgxgmn6-3JsMqc5zEQfE8dkxOY1KKMUOI3ACFKRJpSW2AAp7ontYIaxI6i7XPJVwyeVfCQ550Os3jLrGSNOLgbdAy6s0PBk2TFNjEbsfq31LB0OnX407pJa5v2faRadwSW63mn5KuLyR9j2tgx3zecanl-55R_-jjPs"></script> 
</head>

<body>
  <div id="nltk-theme-container">
    <header>
      <div id="logo-container">
          
          <h1>
            <a href="../index.html">NLTK</a>
          </h1>
          
      </div>
      <div id="project-container">
        
        <h1>Documentation</h1>
        
      </div>

      <a id="menu-toggle" class="fa fa-bars" aria-hidden="true"></a>

      <script type="text/javascript">
        $("#menu-toggle").click(function() {
          $("#menu-toggle").toggleClass("toggled");
          $("#side-menu-container").slideToggle(300);
        });
      </script>
    </header>

    <div id="content-container">

      <div id="side-menu-container">

        <div id="search" role="search">
        <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
            <input type="text" name="q" placeholder="Search" />
            <input type="hidden" name="check_keywords" value="yes" />
            <input type="hidden" name="area" value="default" />
        </form>
</div>

        <div id="side-menu" role="navigation">
          
  
    
  
  
    <p class="caption" role="heading"><span class="caption-text">NLTK Documentation</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="nltk.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../howto.html">Example Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../py-modindex.html">Module Index</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk/wiki">Wiki</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk/wiki/FAQ">FAQ</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk/issues">Open Issues</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk">NLTK on GitHub</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installing NLTK</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data.html">Installing NLTK Data</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contribute.html">Contributing to NLTK</a></li>
<li class="toctree-l1"><a class="reference internal" href="../team.html">NLTK Team</a></li>
</ul>

  

        </div>

        
      </div>

      <div id="main-content-container">
        <div id="main-content" role="main">
          
  <section id="module-nltk.tokenize.regexp">
<span id="nltk-tokenize-regexp-module"></span><h1>nltk.tokenize.regexp module<a class="headerlink" href="#module-nltk.tokenize.regexp" title="Permalink to this heading">Â¶</a></h1>
<p>Regular-Expression Tokenizers</p>
<p>A <code class="docutils literal notranslate"><span class="pre">RegexpTokenizer</span></code> splits a string into substrings using a regular expression.
For example, the following tokenizer forms tokens out of alphabetic sequences,
money expressions, and any other non-whitespace sequences:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">RegexpTokenizer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span> <span class="o">=</span> <span class="s2">&quot;Good muffins cost $3.88</span><span class="se">\n</span><span class="s2">in New York.  Please buy me</span><span class="se">\n</span><span class="s2">two of them.</span><span class="se">\n\n</span><span class="s2">Thanks.&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">RegexpTokenizer</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\w+|\$[\d\.]+|\S+&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> 
<span class="go">[&#39;Good&#39;, &#39;muffins&#39;, &#39;cost&#39;, &#39;$3.88&#39;, &#39;in&#39;, &#39;New&#39;, &#39;York&#39;, &#39;.&#39;,</span>
<span class="go">&#39;Please&#39;, &#39;buy&#39;, &#39;me&#39;, &#39;two&#39;, &#39;of&#39;, &#39;them&#39;, &#39;.&#39;, &#39;Thanks&#39;, &#39;.&#39;]</span>
</pre></div>
</div>
<p>A <code class="docutils literal notranslate"><span class="pre">RegexpTokenizer</span></code> can use its regexp to match delimiters instead:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">RegexpTokenizer</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\s+&#39;</span><span class="p">,</span> <span class="n">gaps</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> 
<span class="go">[&#39;Good&#39;, &#39;muffins&#39;, &#39;cost&#39;, &#39;$3.88&#39;, &#39;in&#39;, &#39;New&#39;, &#39;York.&#39;,</span>
<span class="go">&#39;Please&#39;, &#39;buy&#39;, &#39;me&#39;, &#39;two&#39;, &#39;of&#39;, &#39;them.&#39;, &#39;Thanks.&#39;]</span>
</pre></div>
</div>
<p>Note that empty tokens are not returned when the delimiter appears at
the start or end of the string.</p>
<p>The material between the tokens is discarded.  For example,
the following tokenizer selects just the capitalized words:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">capword_tokenizer</span> <span class="o">=</span> <span class="n">RegexpTokenizer</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[A-Z]\w+&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">capword_tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
<span class="go">[&#39;Good&#39;, &#39;New&#39;, &#39;York&#39;, &#39;Please&#39;, &#39;Thanks&#39;]</span>
</pre></div>
</div>
<p>This module contains several subclasses of <code class="docutils literal notranslate"><span class="pre">RegexpTokenizer</span></code>
that use pre-defined regular expressions.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">BlanklineTokenizer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Uses &#39;\s*\n\s*\n\s*&#39;:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">BlanklineTokenizer</span><span class="p">()</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> 
<span class="go">[&#39;Good muffins cost $3.88\nin New York.  Please buy me\ntwo of them.&#39;,</span>
<span class="go">&#39;Thanks.&#39;]</span>
</pre></div>
</div>
<p>All of the regular expression tokenizers are also available as functions:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">regexp_tokenize</span><span class="p">,</span> <span class="n">wordpunct_tokenize</span><span class="p">,</span> <span class="n">blankline_tokenize</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regexp_tokenize</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">pattern</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;\w+|\$[\d\.]+|\S+&#39;</span><span class="p">)</span> 
<span class="go">[&#39;Good&#39;, &#39;muffins&#39;, &#39;cost&#39;, &#39;$3.88&#39;, &#39;in&#39;, &#39;New&#39;, &#39;York&#39;, &#39;.&#39;,</span>
<span class="go">&#39;Please&#39;, &#39;buy&#39;, &#39;me&#39;, &#39;two&#39;, &#39;of&#39;, &#39;them&#39;, &#39;.&#39;, &#39;Thanks&#39;, &#39;.&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">wordpunct_tokenize</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> 
<span class="go">[&#39;Good&#39;, &#39;muffins&#39;, &#39;cost&#39;, &#39;$&#39;, &#39;3&#39;, &#39;.&#39;, &#39;88&#39;, &#39;in&#39;, &#39;New&#39;, &#39;York&#39;,</span>
<span class="go"> &#39;.&#39;, &#39;Please&#39;, &#39;buy&#39;, &#39;me&#39;, &#39;two&#39;, &#39;of&#39;, &#39;them&#39;, &#39;.&#39;, &#39;Thanks&#39;, &#39;.&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">blankline_tokenize</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
<span class="go">[&#39;Good muffins cost $3.88\nin New York.  Please buy me\ntwo of them.&#39;, &#39;Thanks.&#39;]</span>
</pre></div>
</div>
<p>Caution: The function <code class="docutils literal notranslate"><span class="pre">regexp_tokenize()</span></code> takes the text as its
first argument, and the regular expression pattern as its second
argument.  This differs from the conventions used by Pythonâs
<code class="docutils literal notranslate"><span class="pre">re</span></code> functions, where the pattern is always the first argument.
(This is for consistency with the other NLTK tokenizers.)</p>
<dl class="py class">
<dt class="sig sig-object py" id="nltk.tokenize.regexp.BlanklineTokenizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">nltk.tokenize.regexp.</span></span><span class="sig-name descname"><span class="pre">BlanklineTokenizer</span></span><a class="reference internal" href="../_modules/nltk/tokenize/regexp.html#BlanklineTokenizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nltk.tokenize.regexp.BlanklineTokenizer" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tokenize.regexp.RegexpTokenizer" title="nltk.tokenize.regexp.RegexpTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">RegexpTokenizer</span></code></a></p>
<p>Tokenize a string, treating any sequence of blank lines as a delimiter.
Blank lines are defined as lines containing no characters, except for
space or tab characters.</p>
<dl class="py method">
<dt class="sig sig-object py" id="nltk.tokenize.regexp.BlanklineTokenizer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/tokenize/regexp.html#BlanklineTokenizer.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nltk.tokenize.regexp.BlanklineTokenizer.__init__" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="nltk.tokenize.regexp.RegexpTokenizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">nltk.tokenize.regexp.</span></span><span class="sig-name descname"><span class="pre">RegexpTokenizer</span></span><a class="reference internal" href="../_modules/nltk/tokenize/regexp.html#RegexpTokenizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nltk.tokenize.regexp.RegexpTokenizer" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="nltk.tokenize.api.html#nltk.tokenize.api.TokenizerI" title="nltk.tokenize.api.TokenizerI"><code class="xref py py-class docutils literal notranslate"><span class="pre">TokenizerI</span></code></a></p>
<p>A tokenizer that splits a string using a regular expression, which
matches either the tokens or the separators between tokens.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">RegexpTokenizer</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\w+|\$[\d\.]+|\S+&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pattern</strong> (<em>str</em>) â The pattern used to build this tokenizer.
(This pattern must not contain capturing parentheses;
Use non-capturing parentheses, e.g. (?:â¦), instead)</p></li>
<li><p><strong>gaps</strong> (<em>bool</em>) â True if this tokenizerâs pattern should be used
to find separators between tokens; False if this
tokenizerâs pattern should be used to find the tokens
themselves.</p></li>
<li><p><strong>discard_empty</strong> (<em>bool</em>) â True if any empty tokens <cite>ââ</cite>
generated by the tokenizer should be discarded.  Empty
tokens can only be generated if <cite>_gaps == True</cite>.</p></li>
<li><p><strong>flags</strong> (<em>int</em>) â The regexp flags used to compile this
tokenizerâs pattern.  By default, the following flags are
used: <cite>re.UNICODE | re.MULTILINE | re.DOTALL</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="nltk.tokenize.regexp.RegexpTokenizer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pattern</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gaps=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discard_empty=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">flags=RegexFlag.None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/tokenize/regexp.html#RegexpTokenizer.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nltk.tokenize.regexp.RegexpTokenizer.__init__" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nltk.tokenize.regexp.RegexpTokenizer.span_tokenize">
<span class="sig-name descname"><span class="pre">span_tokenize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/tokenize/regexp.html#RegexpTokenizer.span_tokenize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nltk.tokenize.regexp.RegexpTokenizer.span_tokenize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Identify the tokens using integer offsets <code class="docutils literal notranslate"><span class="pre">(start_i,</span> <span class="pre">end_i)</span></code>,
where <code class="docutils literal notranslate"><span class="pre">s[start_i:end_i]</span></code> is the corresponding token.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Iterator[Tuple[int, int]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nltk.tokenize.regexp.RegexpTokenizer.tokenize">
<span class="sig-name descname"><span class="pre">tokenize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/tokenize/regexp.html#RegexpTokenizer.tokenize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nltk.tokenize.regexp.RegexpTokenizer.tokenize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Return a tokenized copy of <em>s</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="nltk.corpus.reader.markdown.html#nltk.corpus.reader.markdown.List" title="nltk.corpus.reader.markdown.List">List</a>[str]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="nltk.tokenize.regexp.WhitespaceTokenizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">nltk.tokenize.regexp.</span></span><span class="sig-name descname"><span class="pre">WhitespaceTokenizer</span></span><a class="reference internal" href="../_modules/nltk/tokenize/regexp.html#WhitespaceTokenizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nltk.tokenize.regexp.WhitespaceTokenizer" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tokenize.regexp.RegexpTokenizer" title="nltk.tokenize.regexp.RegexpTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">RegexpTokenizer</span></code></a></p>
<p>Tokenize a string on whitespace (space, tab, newline).
In general, users should use the string <code class="docutils literal notranslate"><span class="pre">split()</span></code> method instead.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">WhitespaceTokenizer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span> <span class="o">=</span> <span class="s2">&quot;Good muffins cost $3.88</span><span class="se">\n</span><span class="s2">in New York.  Please buy me</span><span class="se">\n</span><span class="s2">two of them.</span><span class="se">\n\n</span><span class="s2">Thanks.&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">WhitespaceTokenizer</span><span class="p">()</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> 
<span class="go">[&#39;Good&#39;, &#39;muffins&#39;, &#39;cost&#39;, &#39;$3.88&#39;, &#39;in&#39;, &#39;New&#39;, &#39;York.&#39;,</span>
<span class="go">&#39;Please&#39;, &#39;buy&#39;, &#39;me&#39;, &#39;two&#39;, &#39;of&#39;, &#39;them.&#39;, &#39;Thanks.&#39;]</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="nltk.tokenize.regexp.WhitespaceTokenizer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/tokenize/regexp.html#WhitespaceTokenizer.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nltk.tokenize.regexp.WhitespaceTokenizer.__init__" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="nltk.tokenize.regexp.WordPunctTokenizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">nltk.tokenize.regexp.</span></span><span class="sig-name descname"><span class="pre">WordPunctTokenizer</span></span><a class="reference internal" href="../_modules/nltk/tokenize/regexp.html#WordPunctTokenizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nltk.tokenize.regexp.WordPunctTokenizer" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tokenize.regexp.RegexpTokenizer" title="nltk.tokenize.regexp.RegexpTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">RegexpTokenizer</span></code></a></p>
<p>Tokenize a text into a sequence of alphabetic and
non-alphabetic characters, using the regexp <code class="docutils literal notranslate"><span class="pre">\w+|[^\w\s]+</span></code>.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">WordPunctTokenizer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span> <span class="o">=</span> <span class="s2">&quot;Good muffins cost $3.88</span><span class="se">\n</span><span class="s2">in New York.  Please buy me</span><span class="se">\n</span><span class="s2">two of them.</span><span class="se">\n\n</span><span class="s2">Thanks.&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">WordPunctTokenizer</span><span class="p">()</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> 
<span class="go">[&#39;Good&#39;, &#39;muffins&#39;, &#39;cost&#39;, &#39;$&#39;, &#39;3&#39;, &#39;.&#39;, &#39;88&#39;, &#39;in&#39;, &#39;New&#39;, &#39;York&#39;,</span>
<span class="go">&#39;.&#39;, &#39;Please&#39;, &#39;buy&#39;, &#39;me&#39;, &#39;two&#39;, &#39;of&#39;, &#39;them&#39;, &#39;.&#39;, &#39;Thanks&#39;, &#39;.&#39;]</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="nltk.tokenize.regexp.WordPunctTokenizer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/tokenize/regexp.html#WordPunctTokenizer.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nltk.tokenize.regexp.WordPunctTokenizer.__init__" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nltk.tokenize.regexp.blankline_tokenize">
<span class="sig-prename descclassname"><span class="pre">nltk.tokenize.regexp.</span></span><span class="sig-name descname"><span class="pre">blankline_tokenize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nltk.tokenize.regexp.blankline_tokenize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Return a tokenized copy of <em>s</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="nltk.corpus.reader.markdown.html#nltk.corpus.reader.markdown.List" title="nltk.corpus.reader.markdown.List">List</a>[str]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nltk.tokenize.regexp.regexp_tokenize">
<span class="sig-prename descclassname"><span class="pre">nltk.tokenize.regexp.</span></span><span class="sig-name descname"><span class="pre">regexp_tokenize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pattern</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gaps=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discard_empty=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">flags=RegexFlag.None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/tokenize/regexp.html#regexp_tokenize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nltk.tokenize.regexp.regexp_tokenize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Return a tokenized copy of <em>text</em>.  See <a class="reference internal" href="#nltk.tokenize.regexp.RegexpTokenizer" title="nltk.tokenize.regexp.RegexpTokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">RegexpTokenizer</span></code></a>
for descriptions of the arguments.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="nltk.tokenize.regexp.wordpunct_tokenize">
<span class="sig-prename descclassname"><span class="pre">nltk.tokenize.regexp.</span></span><span class="sig-name descname"><span class="pre">wordpunct_tokenize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nltk.tokenize.regexp.wordpunct_tokenize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Return a tokenized copy of <em>s</em>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="nltk.corpus.reader.markdown.html#nltk.corpus.reader.markdown.List" title="nltk.corpus.reader.markdown.List">List</a>[str]</p>
</dd>
</dl>
</dd></dl>

</section>


        </div>
      </div>

    </div>

<footer>
    <div id="footer-info">
        <ul id="build-details">
            
                <li class="footer-element">
                    
                        <a href="../_sources/api/nltk.tokenize.regexp.rst.txt" rel="nofollow"> source</a>
                    
                </li>
            

            
                <li class="footer-element">
                    <a href="https://github.com/nltk/nltk/tree/3.8.1">3.8.1</a>
                </li>
            

            
                <li class="footer-element">
                    Jan 02, 2023
                </li>
            
        </ul>

        
            <div id="copyright">
                &copy; 2023, NLTK Project
            </div>
        

        <div id="credit">
            created with <a href="http://sphinx-doc.org/">Sphinx</a> and <a href="https://github.com/tomaarsen/nltk_theme">NLTK Theme</a>
        </div>
    </div>
</footer> 

</div>

</body>
</html>