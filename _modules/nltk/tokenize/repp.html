<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="theme-color" content="#2D2D2D" />
  
  <title>NLTK :: nltk.tokenize.repp</title>
  

  <link rel="stylesheet" href="../../../_static/css/nltk_theme.css"/>
  <link rel="stylesheet" href="../../../_static/css/custom.css"/>

  <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../../../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
      <script type="text/javascript" src="../../../_static/doctools.js"></script>
  

  <script src="https://email.tl.fortawesome.com/c/eJxNjUEOgyAQAF8jR7Kw6wIHDh7sP1Cw2mgxgmn6-3JsMqc5zEQfE8dkxOY1KKMUOI3ACFKRJpSW2AAp7ontYIaxI6i7XPJVwyeVfCQ550Os3jLrGSNOLgbdAy6s0PBk2TFNjEbsfq31LB0OnX407pJa5v2faRadwSW63mn5KuLyR9j2tgx3zecanl-55R_-jjPs"></script> 
</head>

<body>
  <div id="nltk-theme-container">
    <header>
      <div id="logo-container">
          
          <h1>
            <a href="../../../index.html">NLTK</a>
          </h1>
          
      </div>
      <div id="project-container">
        
        <h1>Documentation</h1>
        
      </div>

      <a id="menu-toggle" class="fa fa-bars" aria-hidden="true"></a>

      <script type="text/javascript">
        $("#menu-toggle").click(function() {
          $("#menu-toggle").toggleClass("toggled");
          $("#side-menu-container").slideToggle(300);
        });
      </script>
    </header>

    <div id="content-container">

      <div id="side-menu-container">

        <div id="search" role="search">
        <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
            <input type="text" name="q" placeholder="Search" />
            <input type="hidden" name="check_keywords" value="yes" />
            <input type="hidden" name="area" value="default" />
        </form>
</div>

        <div id="side-menu" role="navigation">
          
  
    
  
  
    <p class="caption" role="heading"><span class="caption-text">NLTK Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api/nltk.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../howto.html">Example Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../py-modindex.html">Module Index</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk/wiki">Wiki</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk/wiki/FAQ">FAQ</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk/issues">Open Issues</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk">NLTK on GitHub</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../install.html">Installing NLTK</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../data.html">Installing NLTK Data</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../news.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../contribute.html">Contributing to NLTK</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../team.html">NLTK Team</a></li>
</ul>

  

        </div>

        
      </div>

      <div id="main-content-container">
        <div id="main-content" role="main">
          
  <h1>Source code for nltk.tokenize.repp</h1><div class="highlight"><pre>
<span></span><span class="c1"># Natural Language Toolkit: Interface to the Repp Tokenizer</span>
<span class="c1">#</span>
<span class="c1"># Copyright (C) 2001-2015 NLTK Project</span>
<span class="c1"># Authors: Rebecca Dridan and Stephan Oepen</span>
<span class="c1"># Contributors: Liling Tan</span>
<span class="c1">#</span>
<span class="c1"># URL: &lt;https://www.nltk.org/&gt;</span>
<span class="c1"># For license information, see LICENSE.TXT</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">subprocess</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">tempfile</span>

<span class="kn">from</span> <span class="nn">nltk.data</span> <span class="kn">import</span> <span class="n">ZipFilePathPointer</span>
<span class="kn">from</span> <span class="nn">nltk.internals</span> <span class="kn">import</span> <span class="n">find_dir</span>
<span class="kn">from</span> <span class="nn">nltk.tokenize.api</span> <span class="kn">import</span> <span class="n">TokenizerI</span>


<div class="viewcode-block" id="ReppTokenizer"><a class="viewcode-back" href="../../../api/nltk.tokenize.repp.html#nltk.tokenize.ReppTokenizer">[docs]</a><span class="k">class</span> <span class="nc">ReppTokenizer</span><span class="p">(</span><span class="n">TokenizerI</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class for word tokenization using the REPP parser described in</span>
<span class="sd">    Rebecca Dridan and Stephan Oepen (2012) Tokenization: Returning to a</span>
<span class="sd">    Long Solved Problem - A Survey, Contrastive  Experiment, Recommendations,</span>
<span class="sd">    and Toolkit. In ACL. http://anthology.aclweb.org/P/P12/P12-2.pdf#page=406</span>

<span class="sd">    &gt;&gt;&gt; sents = [&#39;Tokenization is widely regarded as a solved problem due to the high accuracy that rulebased tokenizers achieve.&#39; ,</span>
<span class="sd">    ... &#39;But rule-based tokenizers are hard to maintain and their rules language specific.&#39; ,</span>
<span class="sd">    ... &#39;We evaluated our method on three languages and obtained error rates of 0.27% (English), 0.35% (Dutch) and 0.76% (Italian) for our best models.&#39;</span>
<span class="sd">    ... ]</span>
<span class="sd">    &gt;&gt;&gt; tokenizer = ReppTokenizer(&#39;/home/alvas/repp/&#39;) # doctest: +SKIP</span>
<span class="sd">    &gt;&gt;&gt; for sent in sents:                             # doctest: +SKIP</span>
<span class="sd">    ...     tokenizer.tokenize(sent)                   # doctest: +SKIP</span>
<span class="sd">    ...</span>
<span class="sd">    (u&#39;Tokenization&#39;, u&#39;is&#39;, u&#39;widely&#39;, u&#39;regarded&#39;, u&#39;as&#39;, u&#39;a&#39;, u&#39;solved&#39;, u&#39;problem&#39;, u&#39;due&#39;, u&#39;to&#39;, u&#39;the&#39;, u&#39;high&#39;, u&#39;accuracy&#39;, u&#39;that&#39;, u&#39;rulebased&#39;, u&#39;tokenizers&#39;, u&#39;achieve&#39;, u&#39;.&#39;)</span>
<span class="sd">    (u&#39;But&#39;, u&#39;rule-based&#39;, u&#39;tokenizers&#39;, u&#39;are&#39;, u&#39;hard&#39;, u&#39;to&#39;, u&#39;maintain&#39;, u&#39;and&#39;, u&#39;their&#39;, u&#39;rules&#39;, u&#39;language&#39;, u&#39;specific&#39;, u&#39;.&#39;)</span>
<span class="sd">    (u&#39;We&#39;, u&#39;evaluated&#39;, u&#39;our&#39;, u&#39;method&#39;, u&#39;on&#39;, u&#39;three&#39;, u&#39;languages&#39;, u&#39;and&#39;, u&#39;obtained&#39;, u&#39;error&#39;, u&#39;rates&#39;, u&#39;of&#39;, u&#39;0.27&#39;, u&#39;%&#39;, u&#39;(&#39;, u&#39;English&#39;, u&#39;)&#39;, u&#39;,&#39;, u&#39;0.35&#39;, u&#39;%&#39;, u&#39;(&#39;, u&#39;Dutch&#39;, u&#39;)&#39;, u&#39;and&#39;, u&#39;0.76&#39;, u&#39;%&#39;, u&#39;(&#39;, u&#39;Italian&#39;, u&#39;)&#39;, u&#39;for&#39;, u&#39;our&#39;, u&#39;best&#39;, u&#39;models&#39;, u&#39;.&#39;)</span>

<span class="sd">    &gt;&gt;&gt; for sent in tokenizer.tokenize_sents(sents): # doctest: +SKIP</span>
<span class="sd">    ...     print(sent)                              # doctest: +SKIP</span>
<span class="sd">    ...</span>
<span class="sd">    (u&#39;Tokenization&#39;, u&#39;is&#39;, u&#39;widely&#39;, u&#39;regarded&#39;, u&#39;as&#39;, u&#39;a&#39;, u&#39;solved&#39;, u&#39;problem&#39;, u&#39;due&#39;, u&#39;to&#39;, u&#39;the&#39;, u&#39;high&#39;, u&#39;accuracy&#39;, u&#39;that&#39;, u&#39;rulebased&#39;, u&#39;tokenizers&#39;, u&#39;achieve&#39;, u&#39;.&#39;)</span>
<span class="sd">    (u&#39;But&#39;, u&#39;rule-based&#39;, u&#39;tokenizers&#39;, u&#39;are&#39;, u&#39;hard&#39;, u&#39;to&#39;, u&#39;maintain&#39;, u&#39;and&#39;, u&#39;their&#39;, u&#39;rules&#39;, u&#39;language&#39;, u&#39;specific&#39;, u&#39;.&#39;)</span>
<span class="sd">    (u&#39;We&#39;, u&#39;evaluated&#39;, u&#39;our&#39;, u&#39;method&#39;, u&#39;on&#39;, u&#39;three&#39;, u&#39;languages&#39;, u&#39;and&#39;, u&#39;obtained&#39;, u&#39;error&#39;, u&#39;rates&#39;, u&#39;of&#39;, u&#39;0.27&#39;, u&#39;%&#39;, u&#39;(&#39;, u&#39;English&#39;, u&#39;)&#39;, u&#39;,&#39;, u&#39;0.35&#39;, u&#39;%&#39;, u&#39;(&#39;, u&#39;Dutch&#39;, u&#39;)&#39;, u&#39;and&#39;, u&#39;0.76&#39;, u&#39;%&#39;, u&#39;(&#39;, u&#39;Italian&#39;, u&#39;)&#39;, u&#39;for&#39;, u&#39;our&#39;, u&#39;best&#39;, u&#39;models&#39;, u&#39;.&#39;)</span>
<span class="sd">    &gt;&gt;&gt; for sent in tokenizer.tokenize_sents(sents, keep_token_positions=True): # doctest: +SKIP</span>
<span class="sd">    ...     print(sent)                                                         # doctest: +SKIP</span>
<span class="sd">    ...</span>
<span class="sd">    [(u&#39;Tokenization&#39;, 0, 12), (u&#39;is&#39;, 13, 15), (u&#39;widely&#39;, 16, 22), (u&#39;regarded&#39;, 23, 31), (u&#39;as&#39;, 32, 34), (u&#39;a&#39;, 35, 36), (u&#39;solved&#39;, 37, 43), (u&#39;problem&#39;, 44, 51), (u&#39;due&#39;, 52, 55), (u&#39;to&#39;, 56, 58), (u&#39;the&#39;, 59, 62), (u&#39;high&#39;, 63, 67), (u&#39;accuracy&#39;, 68, 76), (u&#39;that&#39;, 77, 81), (u&#39;rulebased&#39;, 82, 91), (u&#39;tokenizers&#39;, 92, 102), (u&#39;achieve&#39;, 103, 110), (u&#39;.&#39;, 110, 111)]</span>
<span class="sd">    [(u&#39;But&#39;, 0, 3), (u&#39;rule-based&#39;, 4, 14), (u&#39;tokenizers&#39;, 15, 25), (u&#39;are&#39;, 26, 29), (u&#39;hard&#39;, 30, 34), (u&#39;to&#39;, 35, 37), (u&#39;maintain&#39;, 38, 46), (u&#39;and&#39;, 47, 50), (u&#39;their&#39;, 51, 56), (u&#39;rules&#39;, 57, 62), (u&#39;language&#39;, 63, 71), (u&#39;specific&#39;, 72, 80), (u&#39;.&#39;, 80, 81)]</span>
<span class="sd">    [(u&#39;We&#39;, 0, 2), (u&#39;evaluated&#39;, 3, 12), (u&#39;our&#39;, 13, 16), (u&#39;method&#39;, 17, 23), (u&#39;on&#39;, 24, 26), (u&#39;three&#39;, 27, 32), (u&#39;languages&#39;, 33, 42), (u&#39;and&#39;, 43, 46), (u&#39;obtained&#39;, 47, 55), (u&#39;error&#39;, 56, 61), (u&#39;rates&#39;, 62, 67), (u&#39;of&#39;, 68, 70), (u&#39;0.27&#39;, 71, 75), (u&#39;%&#39;, 75, 76), (u&#39;(&#39;, 77, 78), (u&#39;English&#39;, 78, 85), (u&#39;)&#39;, 85, 86), (u&#39;,&#39;, 86, 87), (u&#39;0.35&#39;, 88, 92), (u&#39;%&#39;, 92, 93), (u&#39;(&#39;, 94, 95), (u&#39;Dutch&#39;, 95, 100), (u&#39;)&#39;, 100, 101), (u&#39;and&#39;, 102, 105), (u&#39;0.76&#39;, 106, 110), (u&#39;%&#39;, 110, 111), (u&#39;(&#39;, 112, 113), (u&#39;Italian&#39;, 113, 120), (u&#39;)&#39;, 120, 121), (u&#39;for&#39;, 122, 125), (u&#39;our&#39;, 126, 129), (u&#39;best&#39;, 130, 134), (u&#39;models&#39;, 135, 141), (u&#39;.&#39;, 141, 142)]</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="ReppTokenizer.__init__"><a class="viewcode-back" href="../../../api/nltk.tokenize.repp.html#nltk.tokenize.ReppTokenizer.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">repp_dir</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf8&quot;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">repp_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">find_repptokenizer</span><span class="p">(</span><span class="n">repp_dir</span><span class="p">)</span>
        <span class="c1"># Set a directory to store the temporary files.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">working_dir</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">gettempdir</span><span class="p">()</span>
        <span class="c1"># Set an encoding for the input strings.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoding</span> <span class="o">=</span> <span class="n">encoding</span></div>

<div class="viewcode-block" id="ReppTokenizer.tokenize"><a class="viewcode-back" href="../../../api/nltk.tokenize.repp.html#nltk.tokenize.ReppTokenizer.tokenize">[docs]</a>    <span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentence</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Use Repp to tokenize a single sentence.</span>

<span class="sd">        :param sentence: A single sentence string.</span>
<span class="sd">        :type sentence: str</span>
<span class="sd">        :return: A tuple of tokens.</span>
<span class="sd">        :rtype: tuple(str)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenize_sents</span><span class="p">([</span><span class="n">sentence</span><span class="p">]))</span></div>

<div class="viewcode-block" id="ReppTokenizer.tokenize_sents"><a class="viewcode-back" href="../../../api/nltk.tokenize.repp.html#nltk.tokenize.ReppTokenizer.tokenize_sents">[docs]</a>    <span class="k">def</span> <span class="nf">tokenize_sents</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentences</span><span class="p">,</span> <span class="n">keep_token_positions</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Tokenize multiple sentences using Repp.</span>

<span class="sd">        :param sentences: A list of sentence strings.</span>
<span class="sd">        :type sentences: list(str)</span>
<span class="sd">        :return: A list of tuples of tokens</span>
<span class="sd">        :rtype: iter(tuple(str))</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">NamedTemporaryFile</span><span class="p">(</span>
            <span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;repp_input.&quot;</span><span class="p">,</span> <span class="nb">dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">working_dir</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">delete</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span> <span class="k">as</span> <span class="n">input_file</span><span class="p">:</span>
            <span class="c1"># Write sentences to temporary input file.</span>
            <span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>
                <span class="n">input_file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">input_file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="c1"># Generate command to run REPP.</span>
            <span class="n">cmd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_repp_command</span><span class="p">(</span><span class="n">input_file</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
            <span class="c1"># Decode the stdout and strips the ending newline.</span>
            <span class="n">repp_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_execute</span><span class="p">(</span><span class="n">cmd</span><span class="p">)</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoding</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">tokenized_sent</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse_repp_outputs</span><span class="p">(</span><span class="n">repp_output</span><span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">keep_token_positions</span><span class="p">:</span>
                    <span class="c1"># Removes token position information.</span>
                    <span class="n">tokenized_sent</span><span class="p">,</span> <span class="n">starts</span><span class="p">,</span> <span class="n">ends</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">tokenized_sent</span><span class="p">)</span>
                <span class="k">yield</span> <span class="n">tokenized_sent</span></div>

<div class="viewcode-block" id="ReppTokenizer.generate_repp_command"><a class="viewcode-back" href="../../../api/nltk.tokenize.repp.html#nltk.tokenize.ReppTokenizer.generate_repp_command">[docs]</a>    <span class="k">def</span> <span class="nf">generate_repp_command</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputfilename</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This module generates the REPP command to be used at the terminal.</span>

<span class="sd">        :param inputfilename: path to the input file</span>
<span class="sd">        :type inputfilename: str</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">cmd</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">repp_dir</span> <span class="o">+</span> <span class="s2">&quot;/src/repp&quot;</span><span class="p">]</span>
        <span class="n">cmd</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;-c&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">repp_dir</span> <span class="o">+</span> <span class="s2">&quot;/erg/repp.set&quot;</span><span class="p">]</span>
        <span class="n">cmd</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;--format&quot;</span><span class="p">,</span> <span class="s2">&quot;triple&quot;</span><span class="p">]</span>
        <span class="n">cmd</span> <span class="o">+=</span> <span class="p">[</span><span class="n">inputfilename</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">cmd</span></div>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_execute</span><span class="p">(</span><span class="n">cmd</span><span class="p">):</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">Popen</span><span class="p">(</span><span class="n">cmd</span><span class="p">,</span> <span class="n">stdout</span><span class="o">=</span><span class="n">subprocess</span><span class="o">.</span><span class="n">PIPE</span><span class="p">,</span> <span class="n">stderr</span><span class="o">=</span><span class="n">subprocess</span><span class="o">.</span><span class="n">PIPE</span><span class="p">)</span>
        <span class="n">stdout</span><span class="p">,</span> <span class="n">stderr</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">communicate</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">stdout</span>

<div class="viewcode-block" id="ReppTokenizer.parse_repp_outputs"><a class="viewcode-back" href="../../../api/nltk.tokenize.repp.html#nltk.tokenize.ReppTokenizer.parse_repp_outputs">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">parse_repp_outputs</span><span class="p">(</span><span class="n">repp_output</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This module parses the tri-tuple format that REPP outputs using the</span>
<span class="sd">        &quot;--format triple&quot; option and returns an generator with tuple of string</span>
<span class="sd">        tokens.</span>

<span class="sd">        :param repp_output:</span>
<span class="sd">        :type repp_output: type</span>
<span class="sd">        :return: an iterable of the tokenized sentences as tuples of strings</span>
<span class="sd">        :rtype: iter(tuple)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">line_regex</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;^\((\d+), (\d+), (.+)\)$&quot;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">MULTILINE</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">section</span> <span class="ow">in</span> <span class="n">repp_output</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">):</span>
            <span class="n">words_with_positions</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">(</span><span class="n">token</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">start</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">end</span><span class="p">))</span>
                <span class="k">for</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">line_regex</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">section</span><span class="p">)</span>
            <span class="p">]</span>
            <span class="n">words</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">words_with_positions</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">words_with_positions</span></div>

<div class="viewcode-block" id="ReppTokenizer.find_repptokenizer"><a class="viewcode-back" href="../../../api/nltk.tokenize.repp.html#nltk.tokenize.ReppTokenizer.find_repptokenizer">[docs]</a>    <span class="k">def</span> <span class="nf">find_repptokenizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">repp_dirname</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A module to find REPP tokenizer binary and its *repp.set* config file.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">repp_dirname</span><span class="p">):</span>  <span class="c1"># If a full path is given.</span>
            <span class="n">_repp_dir</span> <span class="o">=</span> <span class="n">repp_dirname</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># Try to find path to REPP directory in environment variables.</span>
            <span class="n">_repp_dir</span> <span class="o">=</span> <span class="n">find_dir</span><span class="p">(</span><span class="n">repp_dirname</span><span class="p">,</span> <span class="n">env_vars</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;REPP_TOKENIZER&quot;</span><span class="p">,))</span>
        <span class="c1"># Checks for the REPP binary and erg/repp.set config file.</span>
        <span class="k">assert</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">_repp_dir</span> <span class="o">+</span> <span class="s2">&quot;/src/repp&quot;</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">_repp_dir</span> <span class="o">+</span> <span class="s2">&quot;/erg/repp.set&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_repp_dir</span></div></div>
</pre></div>

        </div>
      </div>

    </div>

<footer>
    <div id="footer-info">
        <ul id="build-details">
            

            
                <li class="footer-element">
                    <a href="https://github.com/nltk/nltk/tree/3.8.1">3.8.1</a>
                </li>
            

            
                <li class="footer-element">
                    Jan 02, 2023
                </li>
            
        </ul>

        
            <div id="copyright">
                &copy; 2023, NLTK Project
            </div>
        

        <div id="credit">
            created with <a href="http://sphinx-doc.org/">Sphinx</a> and <a href="https://github.com/tomaarsen/nltk_theme">NLTK Theme</a>
        </div>
    </div>
</footer> 

</div>

</body>
</html>