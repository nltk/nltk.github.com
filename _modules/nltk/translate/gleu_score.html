<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="theme-color" content="#2D2D2D" />
  
  <title>NLTK :: nltk.translate.gleu_score</title>
  

  <link rel="stylesheet" href="../../../_static/css/nltk_theme.css"/>
  <link rel="stylesheet" href="../../../_static/css/custom.css"/>

  <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../../../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
      <script type="text/javascript" src="../../../_static/doctools.js"></script>
  

  <script src="https://email.tl.fortawesome.com/c/eJxNjUEOgyAQAF8jR7Kw6wIHDh7sP1Cw2mgxgmn6-3JsMqc5zEQfE8dkxOY1KKMUOI3ACFKRJpSW2AAp7ontYIaxI6i7XPJVwyeVfCQ550Os3jLrGSNOLgbdAy6s0PBk2TFNjEbsfq31LB0OnX407pJa5v2faRadwSW63mn5KuLyR9j2tgx3zecanl-55R_-jjPs"></script> 
</head>

<body>
  <div id="nltk-theme-container">
    <header>
      <div id="logo-container">
          
          <h1>
            <a href="../../../index.html">NLTK</a>
          </h1>
          
      </div>
      <div id="project-container">
        
        <h1>Documentation</h1>
        
      </div>

      <a id="menu-toggle" class="fa fa-bars" aria-hidden="true"></a>

      <script type="text/javascript">
        $("#menu-toggle").click(function() {
          $("#menu-toggle").toggleClass("toggled");
          $("#side-menu-container").slideToggle(300);
        });
      </script>
    </header>

    <div id="content-container">

      <div id="side-menu-container">

        <div id="search" role="search">
        <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
            <input type="text" name="q" placeholder="Search" />
            <input type="hidden" name="check_keywords" value="yes" />
            <input type="hidden" name="area" value="default" />
        </form>
</div>

        <div id="side-menu" role="navigation">
          
  
    
  
  
    <p class="caption" role="heading"><span class="caption-text">NLTK Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api/nltk.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../howto.html">Example Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../py-modindex.html">Module Index</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk/wiki">Wiki</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk/wiki/FAQ">FAQ</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk/issues">Open Issues</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk">NLTK on GitHub</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../install.html">Installing NLTK</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../data.html">Installing NLTK Data</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../news.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../contribute.html">Contributing to NLTK</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../team.html">NLTK Team</a></li>
</ul>

  

        </div>

        
      </div>

      <div id="main-content-container">
        <div id="main-content" role="main">
          
  <h1>Source code for nltk.translate.gleu_score</h1><div class="highlight"><pre>
<span></span><span class="c1"># Natural Language Toolkit: GLEU Score</span>
<span class="c1">#</span>
<span class="c1"># Copyright (C) 2001-2023 NLTK Project</span>
<span class="c1"># Authors:</span>
<span class="c1"># Contributors: Mike Schuster, Michael Wayne Goodman, Liling Tan</span>
<span class="c1"># URL: &lt;https://www.nltk.org/&gt;</span>
<span class="c1"># For license information, see LICENSE.TXT</span>

<span class="sd">&quot;&quot;&quot; GLEU score implementation. &quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="kn">from</span> <span class="nn">nltk.util</span> <span class="kn">import</span> <span class="n">everygrams</span><span class="p">,</span> <span class="n">ngrams</span>


<div class="viewcode-block" id="sentence_gleu"><a class="viewcode-back" href="../../../api/nltk.translate.gleu_score.html#nltk.translate.gleu_score.sentence_gleu">[docs]</a><span class="k">def</span> <span class="nf">sentence_gleu</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="n">min_len</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the sentence level GLEU (Google-BLEU) score described in</span>

<span class="sd">        Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V. Le, Mohammad Norouzi,</span>
<span class="sd">        Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey,</span>
<span class="sd">        Jeff Klingner, Apurva Shah, Melvin Johnson, Xiaobing Liu, Lukasz Kaiser,</span>
<span class="sd">        Stephan Gouws, Yoshikiyo Kato, Taku Kudo, Hideto Kazawa, Keith Stevens,</span>
<span class="sd">        George Kurian, Nishant Patil, Wei Wang, Cliff Young, Jason Smith,</span>
<span class="sd">        Jason Riesa, Alex Rudnick, Oriol Vinyals, Greg Corrado, Macduff Hughes,</span>
<span class="sd">        Jeffrey Dean. (2016) Googleâ€™s Neural Machine Translation System:</span>
<span class="sd">        Bridging the Gap between Human and Machine Translation.</span>
<span class="sd">        eprint arXiv:1609.08144. https://arxiv.org/pdf/1609.08144v2.pdf</span>
<span class="sd">        Retrieved on 27 Oct 2016.</span>

<span class="sd">    From Wu et al. (2016):</span>
<span class="sd">        &quot;The BLEU score has some undesirable properties when used for single</span>
<span class="sd">         sentences, as it was designed to be a corpus measure. We therefore</span>
<span class="sd">         use a slightly different score for our RL experiments which we call</span>
<span class="sd">         the &#39;GLEU score&#39;. For the GLEU score, we record all sub-sequences of</span>
<span class="sd">         1, 2, 3 or 4 tokens in output and target sequence (n-grams). We then</span>
<span class="sd">         compute a recall, which is the ratio of the number of matching n-grams</span>
<span class="sd">         to the number of total n-grams in the target (ground truth) sequence,</span>
<span class="sd">         and a precision, which is the ratio of the number of matching n-grams</span>
<span class="sd">         to the number of total n-grams in the generated output sequence. Then</span>
<span class="sd">         GLEU score is simply the minimum of recall and precision. This GLEU</span>
<span class="sd">         score&#39;s range is always between 0 (no matches) and 1 (all match) and</span>
<span class="sd">         it is symmetrical when switching output and target. According to</span>
<span class="sd">         our experiments, GLEU score correlates quite well with the BLEU</span>
<span class="sd">         metric on a corpus level but does not have its drawbacks for our per</span>
<span class="sd">         sentence reward objective.&quot;</span>

<span class="sd">    Note: The initial implementation only allowed a single reference, but now</span>
<span class="sd">          a list of references is required (which is consistent with</span>
<span class="sd">          bleu_score.sentence_bleu()).</span>

<span class="sd">    The infamous &quot;the the the ... &quot; example</span>

<span class="sd">        &gt;&gt;&gt; ref = &#39;the cat is on the mat&#39;.split()</span>
<span class="sd">        &gt;&gt;&gt; hyp = &#39;the the the the the the the&#39;.split()</span>
<span class="sd">        &gt;&gt;&gt; sentence_gleu([ref], hyp)  # doctest: +ELLIPSIS</span>
<span class="sd">        0.0909...</span>

<span class="sd">    An example to evaluate normal machine translation outputs</span>

<span class="sd">        &gt;&gt;&gt; ref1 = str(&#39;It is a guide to action that ensures that the military &#39;</span>
<span class="sd">        ...            &#39;will forever heed Party commands&#39;).split()</span>
<span class="sd">        &gt;&gt;&gt; hyp1 = str(&#39;It is a guide to action which ensures that the military &#39;</span>
<span class="sd">        ...            &#39;always obeys the commands of the party&#39;).split()</span>
<span class="sd">        &gt;&gt;&gt; hyp2 = str(&#39;It is to insure the troops forever hearing the activity &#39;</span>
<span class="sd">        ...            &#39;guidebook that party direct&#39;).split()</span>
<span class="sd">        &gt;&gt;&gt; sentence_gleu([ref1], hyp1) # doctest: +ELLIPSIS</span>
<span class="sd">        0.4393...</span>
<span class="sd">        &gt;&gt;&gt; sentence_gleu([ref1], hyp2) # doctest: +ELLIPSIS</span>
<span class="sd">        0.1206...</span>

<span class="sd">    :param references: a list of reference sentences</span>
<span class="sd">    :type references: list(list(str))</span>
<span class="sd">    :param hypothesis: a hypothesis sentence</span>
<span class="sd">    :type hypothesis: list(str)</span>
<span class="sd">    :param min_len: The minimum order of n-gram this function should extract.</span>
<span class="sd">    :type min_len: int</span>
<span class="sd">    :param max_len: The maximum order of n-gram this function should extract.</span>
<span class="sd">    :type max_len: int</span>
<span class="sd">    :return: the sentence level GLEU score.</span>
<span class="sd">    :rtype: float</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">corpus_gleu</span><span class="p">([</span><span class="n">references</span><span class="p">],</span> <span class="p">[</span><span class="n">hypothesis</span><span class="p">],</span> <span class="n">min_len</span><span class="o">=</span><span class="n">min_len</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="n">max_len</span><span class="p">)</span></div>


<div class="viewcode-block" id="corpus_gleu"><a class="viewcode-back" href="../../../api/nltk.translate.gleu_score.html#nltk.translate.gleu_score.corpus_gleu">[docs]</a><span class="k">def</span> <span class="nf">corpus_gleu</span><span class="p">(</span><span class="n">list_of_references</span><span class="p">,</span> <span class="n">hypotheses</span><span class="p">,</span> <span class="n">min_len</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate a single corpus-level GLEU score (aka. system-level GLEU) for all</span>
<span class="sd">    the hypotheses and their respective references.</span>

<span class="sd">    Instead of averaging the sentence level GLEU scores (i.e. macro-average</span>
<span class="sd">    precision), Wu et al. (2016) sum up the matching tokens and the max of</span>
<span class="sd">    hypothesis and reference tokens for each sentence, then compute using the</span>
<span class="sd">    aggregate values.</span>

<span class="sd">    From Mike Schuster (via email):</span>
<span class="sd">        &quot;For the corpus, we just add up the two statistics n_match and</span>
<span class="sd">         n_all = max(n_all_output, n_all_target) for all sentences, then</span>
<span class="sd">         calculate gleu_score = n_match / n_all, so it is not just a mean of</span>
<span class="sd">         the sentence gleu scores (in our case, longer sentences count more,</span>
<span class="sd">         which I think makes sense as they are more difficult to translate).&quot;</span>

<span class="sd">    &gt;&gt;&gt; hyp1 = [&#39;It&#39;, &#39;is&#39;, &#39;a&#39;, &#39;guide&#39;, &#39;to&#39;, &#39;action&#39;, &#39;which&#39;,</span>
<span class="sd">    ...         &#39;ensures&#39;, &#39;that&#39;, &#39;the&#39;, &#39;military&#39;, &#39;always&#39;,</span>
<span class="sd">    ...         &#39;obeys&#39;, &#39;the&#39;, &#39;commands&#39;, &#39;of&#39;, &#39;the&#39;, &#39;party&#39;]</span>
<span class="sd">    &gt;&gt;&gt; ref1a = [&#39;It&#39;, &#39;is&#39;, &#39;a&#39;, &#39;guide&#39;, &#39;to&#39;, &#39;action&#39;, &#39;that&#39;,</span>
<span class="sd">    ...          &#39;ensures&#39;, &#39;that&#39;, &#39;the&#39;, &#39;military&#39;, &#39;will&#39;, &#39;forever&#39;,</span>
<span class="sd">    ...          &#39;heed&#39;, &#39;Party&#39;, &#39;commands&#39;]</span>
<span class="sd">    &gt;&gt;&gt; ref1b = [&#39;It&#39;, &#39;is&#39;, &#39;the&#39;, &#39;guiding&#39;, &#39;principle&#39;, &#39;which&#39;,</span>
<span class="sd">    ...          &#39;guarantees&#39;, &#39;the&#39;, &#39;military&#39;, &#39;forces&#39;, &#39;always&#39;,</span>
<span class="sd">    ...          &#39;being&#39;, &#39;under&#39;, &#39;the&#39;, &#39;command&#39;, &#39;of&#39;, &#39;the&#39;, &#39;Party&#39;]</span>
<span class="sd">    &gt;&gt;&gt; ref1c = [&#39;It&#39;, &#39;is&#39;, &#39;the&#39;, &#39;practical&#39;, &#39;guide&#39;, &#39;for&#39;, &#39;the&#39;,</span>
<span class="sd">    ...          &#39;army&#39;, &#39;always&#39;, &#39;to&#39;, &#39;heed&#39;, &#39;the&#39;, &#39;directions&#39;,</span>
<span class="sd">    ...          &#39;of&#39;, &#39;the&#39;, &#39;party&#39;]</span>

<span class="sd">    &gt;&gt;&gt; hyp2 = [&#39;he&#39;, &#39;read&#39;, &#39;the&#39;, &#39;book&#39;, &#39;because&#39;, &#39;he&#39;, &#39;was&#39;,</span>
<span class="sd">    ...         &#39;interested&#39;, &#39;in&#39;, &#39;world&#39;, &#39;history&#39;]</span>
<span class="sd">    &gt;&gt;&gt; ref2a = [&#39;he&#39;, &#39;was&#39;, &#39;interested&#39;, &#39;in&#39;, &#39;world&#39;, &#39;history&#39;,</span>
<span class="sd">    ...          &#39;because&#39;, &#39;he&#39;, &#39;read&#39;, &#39;the&#39;, &#39;book&#39;]</span>

<span class="sd">    &gt;&gt;&gt; list_of_references = [[ref1a, ref1b, ref1c], [ref2a]]</span>
<span class="sd">    &gt;&gt;&gt; hypotheses = [hyp1, hyp2]</span>
<span class="sd">    &gt;&gt;&gt; corpus_gleu(list_of_references, hypotheses) # doctest: +ELLIPSIS</span>
<span class="sd">    0.5673...</span>

<span class="sd">    The example below show that corpus_gleu() is different from averaging</span>
<span class="sd">    sentence_gleu() for hypotheses</span>

<span class="sd">    &gt;&gt;&gt; score1 = sentence_gleu([ref1a], hyp1)</span>
<span class="sd">    &gt;&gt;&gt; score2 = sentence_gleu([ref2a], hyp2)</span>
<span class="sd">    &gt;&gt;&gt; (score1 + score2) / 2 # doctest: +ELLIPSIS</span>
<span class="sd">    0.6144...</span>

<span class="sd">    :param list_of_references: a list of reference sentences, w.r.t. hypotheses</span>
<span class="sd">    :type list_of_references: list(list(list(str)))</span>
<span class="sd">    :param hypotheses: a list of hypothesis sentences</span>
<span class="sd">    :type hypotheses: list(list(str))</span>
<span class="sd">    :param min_len: The minimum order of n-gram this function should extract.</span>
<span class="sd">    :type min_len: int</span>
<span class="sd">    :param max_len: The maximum order of n-gram this function should extract.</span>
<span class="sd">    :type max_len: int</span>
<span class="sd">    :return: The corpus-level GLEU score.</span>
<span class="sd">    :rtype: float</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># sanity check</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">list_of_references</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span>
        <span class="n">hypotheses</span>
    <span class="p">),</span> <span class="s2">&quot;The number of hypotheses and their reference(s) should be the same&quot;</span>

    <span class="c1"># sum matches and max-token-lengths over all sentences</span>
    <span class="n">corpus_n_match</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">corpus_n_all</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">list_of_references</span><span class="p">,</span> <span class="n">hypotheses</span><span class="p">):</span>
        <span class="n">hyp_ngrams</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">everygrams</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">,</span> <span class="n">min_len</span><span class="p">,</span> <span class="n">max_len</span><span class="p">))</span>
        <span class="n">tpfp</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">hyp_ngrams</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>  <span class="c1"># True positives + False positives.</span>

        <span class="n">hyp_counts</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">reference</span> <span class="ow">in</span> <span class="n">references</span><span class="p">:</span>
            <span class="n">ref_ngrams</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">everygrams</span><span class="p">(</span><span class="n">reference</span><span class="p">,</span> <span class="n">min_len</span><span class="p">,</span> <span class="n">max_len</span><span class="p">))</span>
            <span class="n">tpfn</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">ref_ngrams</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>  <span class="c1"># True positives + False negatives.</span>

            <span class="n">overlap_ngrams</span> <span class="o">=</span> <span class="n">ref_ngrams</span> <span class="o">&amp;</span> <span class="n">hyp_ngrams</span>
            <span class="n">tp</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">overlap_ngrams</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>  <span class="c1"># True positives.</span>

            <span class="c1"># While GLEU is defined as the minimum of precision and</span>
            <span class="c1"># recall, we can reduce the number of division operations by one by</span>
            <span class="c1"># instead finding the maximum of the denominators for the precision</span>
            <span class="c1"># and recall formulae, since the numerators are the same:</span>
            <span class="c1">#     precision = tp / tpfp</span>
            <span class="c1">#     recall = tp / tpfn</span>
            <span class="c1">#     gleu_score = min(precision, recall) == tp / max(tpfp, tpfn)</span>
            <span class="n">n_all</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">tpfp</span><span class="p">,</span> <span class="n">tpfn</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">n_all</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">hyp_counts</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">tp</span><span class="p">,</span> <span class="n">n_all</span><span class="p">))</span>

        <span class="c1"># use the reference yielding the highest score</span>
        <span class="k">if</span> <span class="n">hyp_counts</span><span class="p">:</span>
            <span class="n">n_match</span><span class="p">,</span> <span class="n">n_all</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">hyp_counts</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">hc</span><span class="p">:</span> <span class="n">hc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">hc</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">corpus_n_match</span> <span class="o">+=</span> <span class="n">n_match</span>
            <span class="n">corpus_n_all</span> <span class="o">+=</span> <span class="n">n_all</span>

    <span class="c1"># corner case: empty corpus or empty references---don&#39;t divide by zero!</span>
    <span class="k">if</span> <span class="n">corpus_n_all</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">gleu_score</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">gleu_score</span> <span class="o">=</span> <span class="n">corpus_n_match</span> <span class="o">/</span> <span class="n">corpus_n_all</span>

    <span class="k">return</span> <span class="n">gleu_score</span></div>
</pre></div>

        </div>
      </div>

    </div>

<footer>
    <div id="footer-info">
        <ul id="build-details">
            

            
                <li class="footer-element">
                    <a href="https://github.com/nltk/nltk/tree/3.8.1">3.8.1</a>
                </li>
            

            
                <li class="footer-element">
                    Jan 02, 2023
                </li>
            
        </ul>

        
            <div id="copyright">
                &copy; 2023, NLTK Project
            </div>
        

        <div id="credit">
            created with <a href="http://sphinx-doc.org/">Sphinx</a> and <a href="https://github.com/tomaarsen/nltk_theme">NLTK Theme</a>
        </div>
    </div>
</footer> 

</div>

</body>
</html>