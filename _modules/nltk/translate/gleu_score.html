
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>nltk.translate.gleu_score &#8212; NLTK 3.4.4 documentation</title>
    <link rel="stylesheet" href="../../../_static/agogo.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../_static/language_data.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
  </head><body>
    <div class="header-wrapper" role="banner">
      <div class="header">
        <div class="headertitle"><a
          href="../../../index.html">NLTK 3.4.4 documentation</a></div>
        <div class="rel" role="navigation" aria-label="related navigation">
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> |
          <a href="../../../genindex.html" title="General Index"
             accesskey="I">index</a>
        </div>
       </div>
    </div>

    <div class="content-wrapper">
      <div class="content">
        <div class="document">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for nltk.translate.gleu_score</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="c1"># Natural Language Toolkit: GLEU Score</span>
<span class="c1">#</span>
<span class="c1"># Copyright (C) 2001-2019 NLTK Project</span>
<span class="c1"># Authors:</span>
<span class="c1"># Contributors: Mike Schuster, Michael Wayne Goodman, Liling Tan</span>
<span class="c1"># URL: &lt;http://nltk.org/&gt;</span>
<span class="c1"># For license information, see LICENSE.TXT</span>

<span class="sd">&quot;&quot;&quot; GLEU score implementation. &quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">Counter</span>

<span class="kn">from</span> <span class="nn">nltk.util</span> <span class="k">import</span> <span class="n">ngrams</span><span class="p">,</span> <span class="n">everygrams</span>


<div class="viewcode-block" id="sentence_gleu"><a class="viewcode-back" href="../../../api/nltk.translate.html#nltk.translate.gleu_score.sentence_gleu">[docs]</a><span class="k">def</span> <span class="nf">sentence_gleu</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="n">min_len</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the sentence level GLEU (Google-BLEU) score described in</span>

<span class="sd">        Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V. Le, Mohammad Norouzi,</span>
<span class="sd">        Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey,</span>
<span class="sd">        Jeff Klingner, Apurva Shah, Melvin Johnson, Xiaobing Liu, Lukasz Kaiser,</span>
<span class="sd">        Stephan Gouws, Yoshikiyo Kato, Taku Kudo, Hideto Kazawa, Keith Stevens,</span>
<span class="sd">        George Kurian, Nishant Patil, Wei Wang, Cliff Young, Jason Smith,</span>
<span class="sd">        Jason Riesa, Alex Rudnick, Oriol Vinyals, Greg Corrado, Macduff Hughes,</span>
<span class="sd">        Jeffrey Dean. (2016) Googleâ€™s Neural Machine Translation System:</span>
<span class="sd">        Bridging the Gap between Human and Machine Translation.</span>
<span class="sd">        eprint arXiv:1609.08144. https://arxiv.org/pdf/1609.08144v2.pdf</span>
<span class="sd">        Retrieved on 27 Oct 2016.</span>

<span class="sd">    From Wu et al. (2016):</span>
<span class="sd">        &quot;The BLEU score has some undesirable properties when used for single</span>
<span class="sd">         sentences, as it was designed to be a corpus measure. We therefore</span>
<span class="sd">         use a slightly different score for our RL experiments which we call</span>
<span class="sd">         the &#39;GLEU score&#39;. For the GLEU score, we record all sub-sequences of</span>
<span class="sd">         1, 2, 3 or 4 tokens in output and target sequence (n-grams). We then</span>
<span class="sd">         compute a recall, which is the ratio of the number of matching n-grams</span>
<span class="sd">         to the number of total n-grams in the target (ground truth) sequence,</span>
<span class="sd">         and a precision, which is the ratio of the number of matching n-grams</span>
<span class="sd">         to the number of total n-grams in the generated output sequence. Then</span>
<span class="sd">         GLEU score is simply the minimum of recall and precision. This GLEU</span>
<span class="sd">         score&#39;s range is always between 0 (no matches) and 1 (all match) and</span>
<span class="sd">         it is symmetrical when switching output and target. According to</span>
<span class="sd">         our experiments, GLEU score correlates quite well with the BLEU</span>
<span class="sd">         metric on a corpus level but does not have its drawbacks for our per</span>
<span class="sd">         sentence reward objective.&quot;</span>

<span class="sd">    Note: The initial implementation only allowed a single reference, but now</span>
<span class="sd">          a list of references is required (which is consistent with</span>
<span class="sd">          bleu_score.sentence_bleu()).</span>

<span class="sd">    The infamous &quot;the the the ... &quot; example</span>

<span class="sd">        &gt;&gt;&gt; ref = &#39;the cat is on the mat&#39;.split()</span>
<span class="sd">        &gt;&gt;&gt; hyp = &#39;the the the the the the the&#39;.split()</span>
<span class="sd">        &gt;&gt;&gt; sentence_gleu([ref], hyp)  # doctest: +ELLIPSIS</span>
<span class="sd">        0.0909...</span>

<span class="sd">    An example to evaluate normal machine translation outputs</span>

<span class="sd">        &gt;&gt;&gt; ref1 = str(&#39;It is a guide to action that ensures that the military &#39;</span>
<span class="sd">        ...            &#39;will forever heed Party commands&#39;).split()</span>
<span class="sd">        &gt;&gt;&gt; hyp1 = str(&#39;It is a guide to action which ensures that the military &#39;</span>
<span class="sd">        ...            &#39;always obeys the commands of the party&#39;).split()</span>
<span class="sd">        &gt;&gt;&gt; hyp2 = str(&#39;It is to insure the troops forever hearing the activity &#39;</span>
<span class="sd">        ...            &#39;guidebook that party direct&#39;).split()</span>
<span class="sd">        &gt;&gt;&gt; sentence_gleu([ref1], hyp1) # doctest: +ELLIPSIS</span>
<span class="sd">        0.4393...</span>
<span class="sd">        &gt;&gt;&gt; sentence_gleu([ref1], hyp2) # doctest: +ELLIPSIS</span>
<span class="sd">        0.1206...</span>

<span class="sd">    :param references: a list of reference sentences</span>
<span class="sd">    :type references: list(list(str))</span>
<span class="sd">    :param hypothesis: a hypothesis sentence</span>
<span class="sd">    :type hypothesis: list(str)</span>
<span class="sd">    :param min_len: The minimum order of n-gram this function should extract.</span>
<span class="sd">    :type min_len: int</span>
<span class="sd">    :param max_len: The maximum order of n-gram this function should extract.</span>
<span class="sd">    :type max_len: int</span>
<span class="sd">    :return: the sentence level GLEU score.</span>
<span class="sd">    :rtype: float</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">corpus_gleu</span><span class="p">([</span><span class="n">references</span><span class="p">],</span> <span class="p">[</span><span class="n">hypothesis</span><span class="p">],</span> <span class="n">min_len</span><span class="o">=</span><span class="n">min_len</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="n">max_len</span><span class="p">)</span></div>


<div class="viewcode-block" id="corpus_gleu"><a class="viewcode-back" href="../../../api/nltk.translate.html#nltk.translate.gleu_score.corpus_gleu">[docs]</a><span class="k">def</span> <span class="nf">corpus_gleu</span><span class="p">(</span><span class="n">list_of_references</span><span class="p">,</span> <span class="n">hypotheses</span><span class="p">,</span> <span class="n">min_len</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate a single corpus-level GLEU score (aka. system-level GLEU) for all</span>
<span class="sd">    the hypotheses and their respective references.</span>

<span class="sd">    Instead of averaging the sentence level GLEU scores (i.e. macro-average</span>
<span class="sd">    precision), Wu et al. (2016) sum up the matching tokens and the max of</span>
<span class="sd">    hypothesis and reference tokens for each sentence, then compute using the</span>
<span class="sd">    aggregate values.</span>

<span class="sd">    From Mike Schuster (via email):</span>
<span class="sd">        &quot;For the corpus, we just add up the two statistics n_match and</span>
<span class="sd">         n_all = max(n_all_output, n_all_target) for all sentences, then</span>
<span class="sd">         calculate gleu_score = n_match / n_all, so it is not just a mean of</span>
<span class="sd">         the sentence gleu scores (in our case, longer sentences count more,</span>
<span class="sd">         which I think makes sense as they are more difficult to translate).&quot;</span>

<span class="sd">    &gt;&gt;&gt; hyp1 = [&#39;It&#39;, &#39;is&#39;, &#39;a&#39;, &#39;guide&#39;, &#39;to&#39;, &#39;action&#39;, &#39;which&#39;,</span>
<span class="sd">    ...         &#39;ensures&#39;, &#39;that&#39;, &#39;the&#39;, &#39;military&#39;, &#39;always&#39;,</span>
<span class="sd">    ...         &#39;obeys&#39;, &#39;the&#39;, &#39;commands&#39;, &#39;of&#39;, &#39;the&#39;, &#39;party&#39;]</span>
<span class="sd">    &gt;&gt;&gt; ref1a = [&#39;It&#39;, &#39;is&#39;, &#39;a&#39;, &#39;guide&#39;, &#39;to&#39;, &#39;action&#39;, &#39;that&#39;,</span>
<span class="sd">    ...          &#39;ensures&#39;, &#39;that&#39;, &#39;the&#39;, &#39;military&#39;, &#39;will&#39;, &#39;forever&#39;,</span>
<span class="sd">    ...          &#39;heed&#39;, &#39;Party&#39;, &#39;commands&#39;]</span>
<span class="sd">    &gt;&gt;&gt; ref1b = [&#39;It&#39;, &#39;is&#39;, &#39;the&#39;, &#39;guiding&#39;, &#39;principle&#39;, &#39;which&#39;,</span>
<span class="sd">    ...          &#39;guarantees&#39;, &#39;the&#39;, &#39;military&#39;, &#39;forces&#39;, &#39;always&#39;,</span>
<span class="sd">    ...          &#39;being&#39;, &#39;under&#39;, &#39;the&#39;, &#39;command&#39;, &#39;of&#39;, &#39;the&#39;, &#39;Party&#39;]</span>
<span class="sd">    &gt;&gt;&gt; ref1c = [&#39;It&#39;, &#39;is&#39;, &#39;the&#39;, &#39;practical&#39;, &#39;guide&#39;, &#39;for&#39;, &#39;the&#39;,</span>
<span class="sd">    ...          &#39;army&#39;, &#39;always&#39;, &#39;to&#39;, &#39;heed&#39;, &#39;the&#39;, &#39;directions&#39;,</span>
<span class="sd">    ...          &#39;of&#39;, &#39;the&#39;, &#39;party&#39;]</span>

<span class="sd">    &gt;&gt;&gt; hyp2 = [&#39;he&#39;, &#39;read&#39;, &#39;the&#39;, &#39;book&#39;, &#39;because&#39;, &#39;he&#39;, &#39;was&#39;,</span>
<span class="sd">    ...         &#39;interested&#39;, &#39;in&#39;, &#39;world&#39;, &#39;history&#39;]</span>
<span class="sd">    &gt;&gt;&gt; ref2a = [&#39;he&#39;, &#39;was&#39;, &#39;interested&#39;, &#39;in&#39;, &#39;world&#39;, &#39;history&#39;,</span>
<span class="sd">    ...          &#39;because&#39;, &#39;he&#39;, &#39;read&#39;, &#39;the&#39;, &#39;book&#39;]</span>

<span class="sd">    &gt;&gt;&gt; list_of_references = [[ref1a, ref1b, ref1c], [ref2a]]</span>
<span class="sd">    &gt;&gt;&gt; hypotheses = [hyp1, hyp2]</span>
<span class="sd">    &gt;&gt;&gt; corpus_gleu(list_of_references, hypotheses) # doctest: +ELLIPSIS</span>
<span class="sd">    0.5673...</span>

<span class="sd">    The example below show that corpus_gleu() is different from averaging</span>
<span class="sd">    sentence_gleu() for hypotheses</span>

<span class="sd">    &gt;&gt;&gt; score1 = sentence_gleu([ref1a], hyp1)</span>
<span class="sd">    &gt;&gt;&gt; score2 = sentence_gleu([ref2a], hyp2)</span>
<span class="sd">    &gt;&gt;&gt; (score1 + score2) / 2 # doctest: +ELLIPSIS</span>
<span class="sd">    0.6144...</span>

<span class="sd">    :param list_of_references: a list of reference sentences, w.r.t. hypotheses</span>
<span class="sd">    :type list_of_references: list(list(list(str)))</span>
<span class="sd">    :param hypotheses: a list of hypothesis sentences</span>
<span class="sd">    :type hypotheses: list(list(str))</span>
<span class="sd">    :param min_len: The minimum order of n-gram this function should extract.</span>
<span class="sd">    :type min_len: int</span>
<span class="sd">    :param max_len: The maximum order of n-gram this function should extract.</span>
<span class="sd">    :type max_len: int</span>
<span class="sd">    :return: The corpus-level GLEU score.</span>
<span class="sd">    :rtype: float</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># sanity check</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">list_of_references</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span>
        <span class="n">hypotheses</span>
    <span class="p">),</span> <span class="s2">&quot;The number of hypotheses and their reference(s) should be the same&quot;</span>

    <span class="c1"># sum matches and max-token-lengths over all sentences</span>
    <span class="n">corpus_n_match</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">corpus_n_all</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">list_of_references</span><span class="p">,</span> <span class="n">hypotheses</span><span class="p">):</span>
        <span class="n">hyp_ngrams</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">everygrams</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">,</span> <span class="n">min_len</span><span class="p">,</span> <span class="n">max_len</span><span class="p">))</span>
        <span class="n">tpfp</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">hyp_ngrams</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>  <span class="c1"># True positives + False positives.</span>

        <span class="n">hyp_counts</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">reference</span> <span class="ow">in</span> <span class="n">references</span><span class="p">:</span>
            <span class="n">ref_ngrams</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">everygrams</span><span class="p">(</span><span class="n">reference</span><span class="p">,</span> <span class="n">min_len</span><span class="p">,</span> <span class="n">max_len</span><span class="p">))</span>
            <span class="n">tpfn</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">ref_ngrams</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>  <span class="c1"># True positives + False negatives.</span>

            <span class="n">overlap_ngrams</span> <span class="o">=</span> <span class="n">ref_ngrams</span> <span class="o">&amp;</span> <span class="n">hyp_ngrams</span>
            <span class="n">tp</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">overlap_ngrams</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>  <span class="c1"># True positives.</span>

            <span class="c1"># While GLEU is defined as the minimum of precision and</span>
            <span class="c1"># recall, we can reduce the number of division operations by one by</span>
            <span class="c1"># instead finding the maximum of the denominators for the precision</span>
            <span class="c1"># and recall formulae, since the numerators are the same:</span>
            <span class="c1">#     precision = tp / tpfp</span>
            <span class="c1">#     recall = tp / tpfn</span>
            <span class="c1">#     gleu_score = min(precision, recall) == tp / max(tpfp, tpfn)</span>
            <span class="n">n_all</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">tpfp</span><span class="p">,</span> <span class="n">tpfn</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">n_all</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">hyp_counts</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">tp</span><span class="p">,</span> <span class="n">n_all</span><span class="p">))</span>

        <span class="c1"># use the reference yielding the highest score</span>
        <span class="k">if</span> <span class="n">hyp_counts</span><span class="p">:</span>
            <span class="n">n_match</span><span class="p">,</span> <span class="n">n_all</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">hyp_counts</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">hc</span><span class="p">:</span> <span class="n">hc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">hc</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">corpus_n_match</span> <span class="o">+=</span> <span class="n">n_match</span>
            <span class="n">corpus_n_all</span> <span class="o">+=</span> <span class="n">n_all</span>

    <span class="c1"># corner case: empty corpus or empty references---don&#39;t divide by zero!</span>
    <span class="k">if</span> <span class="n">corpus_n_all</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">gleu_score</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">gleu_score</span> <span class="o">=</span> <span class="n">corpus_n_match</span> <span class="o">/</span> <span class="n">corpus_n_all</span>

    <span class="k">return</span> <span class="n">gleu_score</span></div>
</pre></div>

          </div>
        </div>
      </div>
        </div>
        <div class="sidebar">
          <h3>Table of Contents</h3>
          <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../news.html">NLTK News</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../install.html">Installing NLTK</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../data.html">Installing NLTK Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../contribute.html">Contribute to NLTK</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk/wiki/FAQ">FAQ</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk/wiki">Wiki</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/nltk.html">API</a></li>
<li class="toctree-l1"><a class="reference external" href="http://www.nltk.org/howto">HOWTO</a></li>
</ul>

          <div role="search">
            <h3 style="margin-top: 1.5em;">Search</h3>
            <form class="search" action="../../../search.html" method="get">
                <input type="text" name="q" />
                <input type="submit" value="Go" />
            </form>
          </div>
        </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer-wrapper">
      <div class="footer">
        <div class="left">
          <div role="navigation" aria-label="related navigaton">
            <a href="../../../py-modindex.html" title="Python Module Index"
              >modules</a> |
            <a href="../../../genindex.html" title="General Index"
              >index</a>
          </div>
          <div role="note" aria-label="source link">
          </div>
        </div>

        <div class="right">
          
    <div class="footer" role="contentinfo">
        &#169; Copyright 2019, NLTK Project.
      Last updated on Jul 04, 2019.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.1.2.
    </div>
        </div>
        <div class="clearer"></div>
      </div>
    </div>

  </body>
</html>