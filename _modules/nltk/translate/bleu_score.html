<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="theme-color" content="#2D2D2D" />
  
  <title>NLTK :: nltk.translate.bleu_score</title>
  

  <link rel="stylesheet" href="../../../_static/css/nltk_theme.css"/>
  <link rel="stylesheet" href="../../../_static/css/custom.css"/>

  <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../../../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
      <script type="text/javascript" src="../../../_static/doctools.js"></script>
  

  <script src="https://email.tl.fortawesome.com/c/eJxNjUEOgyAQAF8jR7Kw6wIHDh7sP1Cw2mgxgmn6-3JsMqc5zEQfE8dkxOY1KKMUOI3ACFKRJpSW2AAp7ontYIaxI6i7XPJVwyeVfCQ550Os3jLrGSNOLgbdAy6s0PBk2TFNjEbsfq31LB0OnX407pJa5v2faRadwSW63mn5KuLyR9j2tgx3zecanl-55R_-jjPs"></script> 
</head>

<body>
  <div id="nltk-theme-container">
    <header>
      <div id="logo-container">
          
          <h1>
            <a href="../../../index.html">NLTK</a>
          </h1>
          
      </div>
      <div id="project-container">
        
        <h1>Documentation</h1>
        
      </div>

      <a id="menu-toggle" class="fa fa-bars" aria-hidden="true"></a>

      <script type="text/javascript">
        $("#menu-toggle").click(function() {
          $("#menu-toggle").toggleClass("toggled");
          $("#side-menu-container").slideToggle(300);
        });
      </script>
    </header>

    <div id="content-container">

      <div id="side-menu-container">

        <div id="search" role="search">
        <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
            <input type="text" name="q" placeholder="Search" />
            <input type="hidden" name="check_keywords" value="yes" />
            <input type="hidden" name="area" value="default" />
        </form>
</div>

        <div id="side-menu" role="navigation">
          
  
    
  
  
    <p class="caption" role="heading"><span class="caption-text">NLTK Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api/nltk.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../howto.html">Example Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../py-modindex.html">Module Index</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk/wiki">Wiki</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk/wiki/FAQ">FAQ</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk/issues">Open Issues</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk">NLTK on GitHub</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../install.html">Installing NLTK</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../data.html">Installing NLTK Data</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">More</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../news.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../contribute.html">Contributing to NLTK</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../team.html">NLTK Team</a></li>
</ul>

  

        </div>

        
      </div>

      <div id="main-content-container">
        <div id="main-content" role="main">
          
  <h1>Source code for nltk.translate.bleu_score</h1><div class="highlight"><pre>
<span></span><span class="c1"># Natural Language Toolkit: BLEU Score</span>
<span class="c1">#</span>
<span class="c1"># Copyright (C) 2001-2023 NLTK Project</span>
<span class="c1"># Authors: Chin Yee Lee, Hengfeng Li, Ruxin Hou, Calvin Tanujaya Lim</span>
<span class="c1"># Contributors: Bj√∂rn Mattsson, Dmitrijs Milajevs, Liling Tan</span>
<span class="c1"># URL: &lt;https://www.nltk.org/&gt;</span>
<span class="c1"># For license information, see LICENSE.TXT</span>

<span class="sd">&quot;&quot;&quot;BLEU score implementation.&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="nn">fractions</span> <span class="kn">import</span> <span class="n">Fraction</span>

<span class="kn">from</span> <span class="nn">nltk.util</span> <span class="kn">import</span> <span class="n">ngrams</span>


<div class="viewcode-block" id="sentence_bleu"><a class="viewcode-back" href="../../../api/nltk.translate.bleu_score.html#nltk.translate.bleu_score.sentence_bleu">[docs]</a><span class="k">def</span> <span class="nf">sentence_bleu</span><span class="p">(</span>
    <span class="n">references</span><span class="p">,</span>
    <span class="n">hypothesis</span><span class="p">,</span>
    <span class="n">weights</span><span class="o">=</span><span class="p">(</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">),</span>
    <span class="n">smoothing_function</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">auto_reweigh</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate BLEU score (Bilingual Evaluation Understudy) from</span>
<span class="sd">    Papineni, Kishore, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.</span>
<span class="sd">    &quot;BLEU: a method for automatic evaluation of machine translation.&quot;</span>
<span class="sd">    In Proceedings of ACL. https://www.aclweb.org/anthology/P02-1040.pdf</span>

<span class="sd">    &gt;&gt;&gt; hypothesis1 = [&#39;It&#39;, &#39;is&#39;, &#39;a&#39;, &#39;guide&#39;, &#39;to&#39;, &#39;action&#39;, &#39;which&#39;,</span>
<span class="sd">    ...               &#39;ensures&#39;, &#39;that&#39;, &#39;the&#39;, &#39;military&#39;, &#39;always&#39;,</span>
<span class="sd">    ...               &#39;obeys&#39;, &#39;the&#39;, &#39;commands&#39;, &#39;of&#39;, &#39;the&#39;, &#39;party&#39;]</span>

<span class="sd">    &gt;&gt;&gt; hypothesis2 = [&#39;It&#39;, &#39;is&#39;, &#39;to&#39;, &#39;insure&#39;, &#39;the&#39;, &#39;troops&#39;,</span>
<span class="sd">    ...               &#39;forever&#39;, &#39;hearing&#39;, &#39;the&#39;, &#39;activity&#39;, &#39;guidebook&#39;,</span>
<span class="sd">    ...               &#39;that&#39;, &#39;party&#39;, &#39;direct&#39;]</span>

<span class="sd">    &gt;&gt;&gt; reference1 = [&#39;It&#39;, &#39;is&#39;, &#39;a&#39;, &#39;guide&#39;, &#39;to&#39;, &#39;action&#39;, &#39;that&#39;,</span>
<span class="sd">    ...               &#39;ensures&#39;, &#39;that&#39;, &#39;the&#39;, &#39;military&#39;, &#39;will&#39;, &#39;forever&#39;,</span>
<span class="sd">    ...               &#39;heed&#39;, &#39;Party&#39;, &#39;commands&#39;]</span>

<span class="sd">    &gt;&gt;&gt; reference2 = [&#39;It&#39;, &#39;is&#39;, &#39;the&#39;, &#39;guiding&#39;, &#39;principle&#39;, &#39;which&#39;,</span>
<span class="sd">    ...               &#39;guarantees&#39;, &#39;the&#39;, &#39;military&#39;, &#39;forces&#39;, &#39;always&#39;,</span>
<span class="sd">    ...               &#39;being&#39;, &#39;under&#39;, &#39;the&#39;, &#39;command&#39;, &#39;of&#39;, &#39;the&#39;,</span>
<span class="sd">    ...               &#39;Party&#39;]</span>

<span class="sd">    &gt;&gt;&gt; reference3 = [&#39;It&#39;, &#39;is&#39;, &#39;the&#39;, &#39;practical&#39;, &#39;guide&#39;, &#39;for&#39;, &#39;the&#39;,</span>
<span class="sd">    ...               &#39;army&#39;, &#39;always&#39;, &#39;to&#39;, &#39;heed&#39;, &#39;the&#39;, &#39;directions&#39;,</span>
<span class="sd">    ...               &#39;of&#39;, &#39;the&#39;, &#39;party&#39;]</span>

<span class="sd">    &gt;&gt;&gt; sentence_bleu([reference1, reference2, reference3], hypothesis1) # doctest: +ELLIPSIS</span>
<span class="sd">    0.5045...</span>

<span class="sd">    If there is no ngrams overlap for any order of n-grams, BLEU returns the</span>
<span class="sd">    value 0. This is because the precision for the order of n-grams without</span>
<span class="sd">    overlap is 0, and the geometric mean in the final BLEU score computation</span>
<span class="sd">    multiplies the 0 with the precision of other n-grams. This results in 0</span>
<span class="sd">    (independently of the precision of the other n-gram orders). The following</span>
<span class="sd">    example has zero 3-gram and 4-gram overlaps:</span>

<span class="sd">    &gt;&gt;&gt; round(sentence_bleu([reference1, reference2, reference3], hypothesis2),4) # doctest: +ELLIPSIS</span>
<span class="sd">    0.0</span>

<span class="sd">    To avoid this harsh behaviour when no ngram overlaps are found a smoothing</span>
<span class="sd">    function can be used.</span>

<span class="sd">    &gt;&gt;&gt; chencherry = SmoothingFunction()</span>
<span class="sd">    &gt;&gt;&gt; sentence_bleu([reference1, reference2, reference3], hypothesis2,</span>
<span class="sd">    ...     smoothing_function=chencherry.method1) # doctest: +ELLIPSIS</span>
<span class="sd">    0.0370...</span>

<span class="sd">    The default BLEU calculates a score for up to 4-grams using uniform</span>
<span class="sd">    weights (this is called BLEU-4). To evaluate your translations with</span>
<span class="sd">    higher/lower order ngrams, use customized weights. E.g. when accounting</span>
<span class="sd">    for up to 5-grams with uniform weights (this is called BLEU-5) use:</span>

<span class="sd">    &gt;&gt;&gt; weights = (1./5., 1./5., 1./5., 1./5., 1./5.)</span>
<span class="sd">    &gt;&gt;&gt; sentence_bleu([reference1, reference2, reference3], hypothesis1, weights) # doctest: +ELLIPSIS</span>
<span class="sd">    0.3920...</span>

<span class="sd">    Multiple BLEU scores can be computed at once, by supplying a list of weights.</span>
<span class="sd">    E.g. for computing BLEU-2, BLEU-3 *and* BLEU-4 in one computation, use:</span>
<span class="sd">    &gt;&gt;&gt; weights = [</span>
<span class="sd">    ...     (1./2., 1./2.),</span>
<span class="sd">    ...     (1./3., 1./3., 1./3.),</span>
<span class="sd">    ...     (1./4., 1./4., 1./4., 1./4.)</span>
<span class="sd">    ... ]</span>
<span class="sd">    &gt;&gt;&gt; sentence_bleu([reference1, reference2, reference3], hypothesis1, weights) # doctest: +ELLIPSIS</span>
<span class="sd">    [0.7453..., 0.6240..., 0.5045...]</span>

<span class="sd">    :param references: reference sentences</span>
<span class="sd">    :type references: list(list(str))</span>
<span class="sd">    :param hypothesis: a hypothesis sentence</span>
<span class="sd">    :type hypothesis: list(str)</span>
<span class="sd">    :param weights: weights for unigrams, bigrams, trigrams and so on (one or a list of weights)</span>
<span class="sd">    :type weights: tuple(float) / list(tuple(float))</span>
<span class="sd">    :param smoothing_function:</span>
<span class="sd">    :type smoothing_function: SmoothingFunction</span>
<span class="sd">    :param auto_reweigh: Option to re-normalize the weights uniformly.</span>
<span class="sd">    :type auto_reweigh: bool</span>
<span class="sd">    :return: The sentence-level BLEU score. Returns a list if multiple weights were supplied.</span>
<span class="sd">    :rtype: float / list(float)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">corpus_bleu</span><span class="p">(</span>
        <span class="p">[</span><span class="n">references</span><span class="p">],</span> <span class="p">[</span><span class="n">hypothesis</span><span class="p">],</span> <span class="n">weights</span><span class="p">,</span> <span class="n">smoothing_function</span><span class="p">,</span> <span class="n">auto_reweigh</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="corpus_bleu"><a class="viewcode-back" href="../../../api/nltk.translate.bleu_score.html#nltk.translate.bleu_score.corpus_bleu">[docs]</a><span class="k">def</span> <span class="nf">corpus_bleu</span><span class="p">(</span>
    <span class="n">list_of_references</span><span class="p">,</span>
    <span class="n">hypotheses</span><span class="p">,</span>
    <span class="n">weights</span><span class="o">=</span><span class="p">(</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">),</span>
    <span class="n">smoothing_function</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">auto_reweigh</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate a single corpus-level BLEU score (aka. system-level BLEU) for all</span>
<span class="sd">    the hypotheses and their respective references.</span>

<span class="sd">    Instead of averaging the sentence level BLEU scores (i.e. macro-average</span>
<span class="sd">    precision), the original BLEU metric (Papineni et al. 2002) accounts for</span>
<span class="sd">    the micro-average precision (i.e. summing the numerators and denominators</span>
<span class="sd">    for each hypothesis-reference(s) pairs before the division).</span>

<span class="sd">    &gt;&gt;&gt; hyp1 = [&#39;It&#39;, &#39;is&#39;, &#39;a&#39;, &#39;guide&#39;, &#39;to&#39;, &#39;action&#39;, &#39;which&#39;,</span>
<span class="sd">    ...         &#39;ensures&#39;, &#39;that&#39;, &#39;the&#39;, &#39;military&#39;, &#39;always&#39;,</span>
<span class="sd">    ...         &#39;obeys&#39;, &#39;the&#39;, &#39;commands&#39;, &#39;of&#39;, &#39;the&#39;, &#39;party&#39;]</span>
<span class="sd">    &gt;&gt;&gt; ref1a = [&#39;It&#39;, &#39;is&#39;, &#39;a&#39;, &#39;guide&#39;, &#39;to&#39;, &#39;action&#39;, &#39;that&#39;,</span>
<span class="sd">    ...          &#39;ensures&#39;, &#39;that&#39;, &#39;the&#39;, &#39;military&#39;, &#39;will&#39;, &#39;forever&#39;,</span>
<span class="sd">    ...          &#39;heed&#39;, &#39;Party&#39;, &#39;commands&#39;]</span>
<span class="sd">    &gt;&gt;&gt; ref1b = [&#39;It&#39;, &#39;is&#39;, &#39;the&#39;, &#39;guiding&#39;, &#39;principle&#39;, &#39;which&#39;,</span>
<span class="sd">    ...          &#39;guarantees&#39;, &#39;the&#39;, &#39;military&#39;, &#39;forces&#39;, &#39;always&#39;,</span>
<span class="sd">    ...          &#39;being&#39;, &#39;under&#39;, &#39;the&#39;, &#39;command&#39;, &#39;of&#39;, &#39;the&#39;, &#39;Party&#39;]</span>
<span class="sd">    &gt;&gt;&gt; ref1c = [&#39;It&#39;, &#39;is&#39;, &#39;the&#39;, &#39;practical&#39;, &#39;guide&#39;, &#39;for&#39;, &#39;the&#39;,</span>
<span class="sd">    ...          &#39;army&#39;, &#39;always&#39;, &#39;to&#39;, &#39;heed&#39;, &#39;the&#39;, &#39;directions&#39;,</span>
<span class="sd">    ...          &#39;of&#39;, &#39;the&#39;, &#39;party&#39;]</span>

<span class="sd">    &gt;&gt;&gt; hyp2 = [&#39;he&#39;, &#39;read&#39;, &#39;the&#39;, &#39;book&#39;, &#39;because&#39;, &#39;he&#39;, &#39;was&#39;,</span>
<span class="sd">    ...         &#39;interested&#39;, &#39;in&#39;, &#39;world&#39;, &#39;history&#39;]</span>
<span class="sd">    &gt;&gt;&gt; ref2a = [&#39;he&#39;, &#39;was&#39;, &#39;interested&#39;, &#39;in&#39;, &#39;world&#39;, &#39;history&#39;,</span>
<span class="sd">    ...          &#39;because&#39;, &#39;he&#39;, &#39;read&#39;, &#39;the&#39;, &#39;book&#39;]</span>

<span class="sd">    &gt;&gt;&gt; list_of_references = [[ref1a, ref1b, ref1c], [ref2a]]</span>
<span class="sd">    &gt;&gt;&gt; hypotheses = [hyp1, hyp2]</span>
<span class="sd">    &gt;&gt;&gt; corpus_bleu(list_of_references, hypotheses) # doctest: +ELLIPSIS</span>
<span class="sd">    0.5920...</span>

<span class="sd">    The example below show that corpus_bleu() is different from averaging</span>
<span class="sd">    sentence_bleu() for hypotheses</span>

<span class="sd">    &gt;&gt;&gt; score1 = sentence_bleu([ref1a, ref1b, ref1c], hyp1)</span>
<span class="sd">    &gt;&gt;&gt; score2 = sentence_bleu([ref2a], hyp2)</span>
<span class="sd">    &gt;&gt;&gt; (score1 + score2) / 2 # doctest: +ELLIPSIS</span>
<span class="sd">    0.6223...</span>

<span class="sd">    Custom weights may be supplied to fine-tune the BLEU score further.</span>
<span class="sd">    A tuple of float weights for unigrams, bigrams, trigrams and so on can be given.</span>
<span class="sd">    &gt;&gt;&gt; weights = (0.1, 0.3, 0.5, 0.1)</span>
<span class="sd">    &gt;&gt;&gt; corpus_bleu(list_of_references, hypotheses, weights=weights) # doctest: +ELLIPSIS</span>
<span class="sd">    0.5818...</span>

<span class="sd">    This particular weight gave extra value to trigrams.</span>
<span class="sd">    Furthermore, multiple weights can be given, resulting in multiple BLEU scores.</span>
<span class="sd">    &gt;&gt;&gt; weights = [</span>
<span class="sd">    ...     (0.5, 0.5),</span>
<span class="sd">    ...     (0.333, 0.333, 0.334),</span>
<span class="sd">    ...     (0.25, 0.25, 0.25, 0.25),</span>
<span class="sd">    ...     (0.2, 0.2, 0.2, 0.2, 0.2)</span>
<span class="sd">    ... ]</span>
<span class="sd">    &gt;&gt;&gt; corpus_bleu(list_of_references, hypotheses, weights=weights) # doctest: +ELLIPSIS</span>
<span class="sd">    [0.8242..., 0.7067..., 0.5920..., 0.4719...]</span>

<span class="sd">    :param list_of_references: a corpus of lists of reference sentences, w.r.t. hypotheses</span>
<span class="sd">    :type list_of_references: list(list(list(str)))</span>
<span class="sd">    :param hypotheses: a list of hypothesis sentences</span>
<span class="sd">    :type hypotheses: list(list(str))</span>
<span class="sd">    :param weights: weights for unigrams, bigrams, trigrams and so on (one or a list of weights)</span>
<span class="sd">    :type weights: tuple(float) / list(tuple(float))</span>
<span class="sd">    :param smoothing_function:</span>
<span class="sd">    :type smoothing_function: SmoothingFunction</span>
<span class="sd">    :param auto_reweigh: Option to re-normalize the weights uniformly.</span>
<span class="sd">    :type auto_reweigh: bool</span>
<span class="sd">    :return: The corpus-level BLEU score.</span>
<span class="sd">    :rtype: float</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Before proceeding to compute BLEU, perform sanity checks.</span>

    <span class="n">p_numerators</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>  <span class="c1"># Key = ngram order, and value = no. of ngram matches.</span>
    <span class="n">p_denominators</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>  <span class="c1"># Key = ngram order, and value = no. of ngram in ref.</span>
    <span class="n">hyp_lengths</span><span class="p">,</span> <span class="n">ref_lengths</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>

    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">list_of_references</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">hypotheses</span><span class="p">),</span> <span class="p">(</span>
        <span class="s2">&quot;The number of hypotheses and their reference(s) should be the &quot;</span> <span class="s2">&quot;same &quot;</span>
    <span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">weights</span><span class="p">]</span>
    <span class="n">max_weight_length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span> <span class="k">for</span> <span class="n">weight</span> <span class="ow">in</span> <span class="n">weights</span><span class="p">)</span>

    <span class="c1"># Iterate through each hypothesis and their corresponding references.</span>
    <span class="k">for</span> <span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">list_of_references</span><span class="p">,</span> <span class="n">hypotheses</span><span class="p">):</span>
        <span class="c1"># For each order of ngram, calculate the numerator and</span>
        <span class="c1"># denominator for the corpus-level modified precision.</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_weight_length</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">p_i</span> <span class="o">=</span> <span class="n">modified_precision</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
            <span class="n">p_numerators</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">p_i</span><span class="o">.</span><span class="n">numerator</span>
            <span class="n">p_denominators</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">p_i</span><span class="o">.</span><span class="n">denominator</span>

        <span class="c1"># Calculate the hypothesis length and the closest reference length.</span>
        <span class="c1"># Adds them to the corpus-level hypothesis and reference counts.</span>
        <span class="n">hyp_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">)</span>
        <span class="n">hyp_lengths</span> <span class="o">+=</span> <span class="n">hyp_len</span>
        <span class="n">ref_lengths</span> <span class="o">+=</span> <span class="n">closest_ref_length</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">)</span>

    <span class="c1"># Calculate corpus-level brevity penalty.</span>
    <span class="n">bp</span> <span class="o">=</span> <span class="n">brevity_penalty</span><span class="p">(</span><span class="n">ref_lengths</span><span class="p">,</span> <span class="n">hyp_lengths</span><span class="p">)</span>

    <span class="c1"># Collects the various precision values for the different ngram orders.</span>
    <span class="n">p_n</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">Fraction</span><span class="p">(</span><span class="n">p_numerators</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">p_denominators</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">_normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_weight_length</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="c1"># Returns 0 if there&#39;s no matching n-grams</span>
    <span class="c1"># We only need to check for p_numerators[1] == 0, since if there&#39;s</span>
    <span class="c1"># no unigrams, there won&#39;t be any higher order ngrams.</span>
    <span class="k">if</span> <span class="n">p_numerators</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>

    <span class="c1"># If there&#39;s no smoothing, set use method0 from SmoothinFunction class.</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">smoothing_function</span><span class="p">:</span>
        <span class="n">smoothing_function</span> <span class="o">=</span> <span class="n">SmoothingFunction</span><span class="p">()</span><span class="o">.</span><span class="n">method0</span>
    <span class="c1"># Smoothen the modified precision.</span>
    <span class="c1"># Note: smoothing_function() may convert values into floats;</span>
    <span class="c1">#       it tries to retain the Fraction object as much as the</span>
    <span class="c1">#       smoothing method allows.</span>
    <span class="n">p_n</span> <span class="o">=</span> <span class="n">smoothing_function</span><span class="p">(</span>
        <span class="n">p_n</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span><span class="o">=</span><span class="n">hypothesis</span><span class="p">,</span> <span class="n">hyp_len</span><span class="o">=</span><span class="n">hyp_lengths</span>
    <span class="p">)</span>

    <span class="n">bleu_scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">weight</span> <span class="ow">in</span> <span class="n">weights</span><span class="p">:</span>
        <span class="c1"># Uniformly re-weighting based on maximum hypothesis lengths if largest</span>
        <span class="c1"># order of n-grams &lt; 4 and weights is set at default.</span>
        <span class="k">if</span> <span class="n">auto_reweigh</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">hyp_lengths</span> <span class="o">&lt;</span> <span class="mi">4</span> <span class="ow">and</span> <span class="n">weight</span> <span class="o">==</span> <span class="p">(</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">):</span>
                <span class="n">weight</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">hyp_lengths</span><span class="p">,)</span> <span class="o">*</span> <span class="n">hyp_lengths</span>

        <span class="n">s</span> <span class="o">=</span> <span class="p">(</span><span class="n">w_i</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p_i</span><span class="p">)</span> <span class="k">for</span> <span class="n">w_i</span><span class="p">,</span> <span class="n">p_i</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">p_n</span><span class="p">)</span> <span class="k">if</span> <span class="n">p_i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">s</span> <span class="o">=</span> <span class="n">bp</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">fsum</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
        <span class="n">bleu_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">bleu_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">bleu_scores</span></div>


<div class="viewcode-block" id="modified_precision"><a class="viewcode-back" href="../../../api/nltk.translate.bleu_score.html#nltk.translate.bleu_score.modified_precision">[docs]</a><span class="k">def</span> <span class="nf">modified_precision</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate modified ngram precision.</span>

<span class="sd">    The normal precision method may lead to some wrong translations with</span>
<span class="sd">    high-precision, e.g., the translation, in which a word of reference</span>
<span class="sd">    repeats several times, has very high precision.</span>

<span class="sd">    This function only returns the Fraction object that contains the numerator</span>
<span class="sd">    and denominator necessary to calculate the corpus-level precision.</span>
<span class="sd">    To calculate the modified precision for a single pair of hypothesis and</span>
<span class="sd">    references, cast the Fraction object into a float.</span>

<span class="sd">    The famous &quot;the the the ... &quot; example shows that you can get BLEU precision</span>
<span class="sd">    by duplicating high frequency words.</span>

<span class="sd">        &gt;&gt;&gt; reference1 = &#39;the cat is on the mat&#39;.split()</span>
<span class="sd">        &gt;&gt;&gt; reference2 = &#39;there is a cat on the mat&#39;.split()</span>
<span class="sd">        &gt;&gt;&gt; hypothesis1 = &#39;the the the the the the the&#39;.split()</span>
<span class="sd">        &gt;&gt;&gt; references = [reference1, reference2]</span>
<span class="sd">        &gt;&gt;&gt; float(modified_precision(references, hypothesis1, n=1)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.2857...</span>

<span class="sd">    In the modified n-gram precision, a reference word will be considered</span>
<span class="sd">    exhausted after a matching hypothesis word is identified, e.g.</span>

<span class="sd">        &gt;&gt;&gt; reference1 = [&#39;It&#39;, &#39;is&#39;, &#39;a&#39;, &#39;guide&#39;, &#39;to&#39;, &#39;action&#39;, &#39;that&#39;,</span>
<span class="sd">        ...               &#39;ensures&#39;, &#39;that&#39;, &#39;the&#39;, &#39;military&#39;, &#39;will&#39;,</span>
<span class="sd">        ...               &#39;forever&#39;, &#39;heed&#39;, &#39;Party&#39;, &#39;commands&#39;]</span>
<span class="sd">        &gt;&gt;&gt; reference2 = [&#39;It&#39;, &#39;is&#39;, &#39;the&#39;, &#39;guiding&#39;, &#39;principle&#39;, &#39;which&#39;,</span>
<span class="sd">        ...               &#39;guarantees&#39;, &#39;the&#39;, &#39;military&#39;, &#39;forces&#39;, &#39;always&#39;,</span>
<span class="sd">        ...               &#39;being&#39;, &#39;under&#39;, &#39;the&#39;, &#39;command&#39;, &#39;of&#39;, &#39;the&#39;,</span>
<span class="sd">        ...               &#39;Party&#39;]</span>
<span class="sd">        &gt;&gt;&gt; reference3 = [&#39;It&#39;, &#39;is&#39;, &#39;the&#39;, &#39;practical&#39;, &#39;guide&#39;, &#39;for&#39;, &#39;the&#39;,</span>
<span class="sd">        ...               &#39;army&#39;, &#39;always&#39;, &#39;to&#39;, &#39;heed&#39;, &#39;the&#39;, &#39;directions&#39;,</span>
<span class="sd">        ...               &#39;of&#39;, &#39;the&#39;, &#39;party&#39;]</span>
<span class="sd">        &gt;&gt;&gt; hypothesis = &#39;of the&#39;.split()</span>
<span class="sd">        &gt;&gt;&gt; references = [reference1, reference2, reference3]</span>
<span class="sd">        &gt;&gt;&gt; float(modified_precision(references, hypothesis, n=1))</span>
<span class="sd">        1.0</span>
<span class="sd">        &gt;&gt;&gt; float(modified_precision(references, hypothesis, n=2))</span>
<span class="sd">        1.0</span>

<span class="sd">    An example of a normal machine translation hypothesis:</span>

<span class="sd">        &gt;&gt;&gt; hypothesis1 = [&#39;It&#39;, &#39;is&#39;, &#39;a&#39;, &#39;guide&#39;, &#39;to&#39;, &#39;action&#39;, &#39;which&#39;,</span>
<span class="sd">        ...               &#39;ensures&#39;, &#39;that&#39;, &#39;the&#39;, &#39;military&#39;, &#39;always&#39;,</span>
<span class="sd">        ...               &#39;obeys&#39;, &#39;the&#39;, &#39;commands&#39;, &#39;of&#39;, &#39;the&#39;, &#39;party&#39;]</span>

<span class="sd">        &gt;&gt;&gt; hypothesis2 = [&#39;It&#39;, &#39;is&#39;, &#39;to&#39;, &#39;insure&#39;, &#39;the&#39;, &#39;troops&#39;,</span>
<span class="sd">        ...               &#39;forever&#39;, &#39;hearing&#39;, &#39;the&#39;, &#39;activity&#39;, &#39;guidebook&#39;,</span>
<span class="sd">        ...               &#39;that&#39;, &#39;party&#39;, &#39;direct&#39;]</span>

<span class="sd">        &gt;&gt;&gt; reference1 = [&#39;It&#39;, &#39;is&#39;, &#39;a&#39;, &#39;guide&#39;, &#39;to&#39;, &#39;action&#39;, &#39;that&#39;,</span>
<span class="sd">        ...               &#39;ensures&#39;, &#39;that&#39;, &#39;the&#39;, &#39;military&#39;, &#39;will&#39;,</span>
<span class="sd">        ...               &#39;forever&#39;, &#39;heed&#39;, &#39;Party&#39;, &#39;commands&#39;]</span>

<span class="sd">        &gt;&gt;&gt; reference2 = [&#39;It&#39;, &#39;is&#39;, &#39;the&#39;, &#39;guiding&#39;, &#39;principle&#39;, &#39;which&#39;,</span>
<span class="sd">        ...               &#39;guarantees&#39;, &#39;the&#39;, &#39;military&#39;, &#39;forces&#39;, &#39;always&#39;,</span>
<span class="sd">        ...               &#39;being&#39;, &#39;under&#39;, &#39;the&#39;, &#39;command&#39;, &#39;of&#39;, &#39;the&#39;,</span>
<span class="sd">        ...               &#39;Party&#39;]</span>

<span class="sd">        &gt;&gt;&gt; reference3 = [&#39;It&#39;, &#39;is&#39;, &#39;the&#39;, &#39;practical&#39;, &#39;guide&#39;, &#39;for&#39;, &#39;the&#39;,</span>
<span class="sd">        ...               &#39;army&#39;, &#39;always&#39;, &#39;to&#39;, &#39;heed&#39;, &#39;the&#39;, &#39;directions&#39;,</span>
<span class="sd">        ...               &#39;of&#39;, &#39;the&#39;, &#39;party&#39;]</span>
<span class="sd">        &gt;&gt;&gt; references = [reference1, reference2, reference3]</span>
<span class="sd">        &gt;&gt;&gt; float(modified_precision(references, hypothesis1, n=1)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.9444...</span>
<span class="sd">        &gt;&gt;&gt; float(modified_precision(references, hypothesis2, n=1)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.5714...</span>
<span class="sd">        &gt;&gt;&gt; float(modified_precision(references, hypothesis1, n=2)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.5882352941176471</span>
<span class="sd">        &gt;&gt;&gt; float(modified_precision(references, hypothesis2, n=2)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.07692...</span>


<span class="sd">    :param references: A list of reference translations.</span>
<span class="sd">    :type references: list(list(str))</span>
<span class="sd">    :param hypothesis: A hypothesis translation.</span>
<span class="sd">    :type hypothesis: list(str)</span>
<span class="sd">    :param n: The ngram order.</span>
<span class="sd">    :type n: int</span>
<span class="sd">    :return: BLEU&#39;s modified precision for the nth order ngram.</span>
<span class="sd">    :rtype: Fraction</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Extracts all ngrams in hypothesis</span>
    <span class="c1"># Set an empty Counter if hypothesis is empty.</span>
    <span class="n">counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">ngrams</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">n</span> <span class="k">else</span> <span class="n">Counter</span><span class="p">()</span>
    <span class="c1"># Extract a union of references&#39; counts.</span>
    <span class="c1"># max_counts = reduce(or_, [Counter(ngrams(ref, n)) for ref in references])</span>
    <span class="n">max_counts</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">reference</span> <span class="ow">in</span> <span class="n">references</span><span class="p">:</span>
        <span class="n">reference_counts</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">Counter</span><span class="p">(</span><span class="n">ngrams</span><span class="p">(</span><span class="n">reference</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">reference</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">n</span> <span class="k">else</span> <span class="n">Counter</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">ngram</span> <span class="ow">in</span> <span class="n">counts</span><span class="p">:</span>
            <span class="n">max_counts</span><span class="p">[</span><span class="n">ngram</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">max_counts</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">ngram</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">reference_counts</span><span class="p">[</span><span class="n">ngram</span><span class="p">])</span>

    <span class="c1"># Assigns the intersection between hypothesis and references&#39; counts.</span>
    <span class="n">clipped_counts</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">ngram</span><span class="p">:</span> <span class="nb">min</span><span class="p">(</span><span class="n">count</span><span class="p">,</span> <span class="n">max_counts</span><span class="p">[</span><span class="n">ngram</span><span class="p">])</span> <span class="k">for</span> <span class="n">ngram</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">counts</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
    <span class="p">}</span>

    <span class="n">numerator</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">clipped_counts</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
    <span class="c1"># Ensures that denominator is minimum 1 to avoid ZeroDivisionError.</span>
    <span class="c1"># Usually this happens when the ngram order is &gt; len(reference).</span>
    <span class="n">denominator</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span><span class="n">counts</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>

    <span class="k">return</span> <span class="n">Fraction</span><span class="p">(</span><span class="n">numerator</span><span class="p">,</span> <span class="n">denominator</span><span class="p">,</span> <span class="n">_normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></div>


<div class="viewcode-block" id="closest_ref_length"><a class="viewcode-back" href="../../../api/nltk.translate.bleu_score.html#nltk.translate.bleu_score.closest_ref_length">[docs]</a><span class="k">def</span> <span class="nf">closest_ref_length</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function finds the reference that is the closest length to the</span>
<span class="sd">    hypothesis. The closest reference length is referred to as *r* variable</span>
<span class="sd">    from the brevity penalty formula in Papineni et. al. (2002)</span>

<span class="sd">    :param references: A list of reference translations.</span>
<span class="sd">    :type references: list(list(str))</span>
<span class="sd">    :param hyp_len: The length of the hypothesis.</span>
<span class="sd">    :type hyp_len: int</span>
<span class="sd">    :return: The length of the reference that&#39;s closest to the hypothesis.</span>
<span class="sd">    :rtype: int</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ref_lens</span> <span class="o">=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">reference</span><span class="p">)</span> <span class="k">for</span> <span class="n">reference</span> <span class="ow">in</span> <span class="n">references</span><span class="p">)</span>
    <span class="n">closest_ref_len</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span>
        <span class="n">ref_lens</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">ref_len</span><span class="p">:</span> <span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">ref_len</span> <span class="o">-</span> <span class="n">hyp_len</span><span class="p">),</span> <span class="n">ref_len</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">closest_ref_len</span></div>


<div class="viewcode-block" id="brevity_penalty"><a class="viewcode-back" href="../../../api/nltk.translate.bleu_score.html#nltk.translate.bleu_score.brevity_penalty">[docs]</a><span class="k">def</span> <span class="nf">brevity_penalty</span><span class="p">(</span><span class="n">closest_ref_len</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate brevity penalty.</span>

<span class="sd">    As the modified n-gram precision still has the problem from the short</span>
<span class="sd">    length sentence, brevity penalty is used to modify the overall BLEU</span>
<span class="sd">    score according to length.</span>

<span class="sd">    An example from the paper. There are three references with length 12, 15</span>
<span class="sd">    and 17. And a concise hypothesis of the length 12. The brevity penalty is 1.</span>

<span class="sd">    &gt;&gt;&gt; reference1 = list(&#39;aaaaaaaaaaaa&#39;)      # i.e. [&#39;a&#39;] * 12</span>
<span class="sd">    &gt;&gt;&gt; reference2 = list(&#39;aaaaaaaaaaaaaaa&#39;)   # i.e. [&#39;a&#39;] * 15</span>
<span class="sd">    &gt;&gt;&gt; reference3 = list(&#39;aaaaaaaaaaaaaaaaa&#39;) # i.e. [&#39;a&#39;] * 17</span>
<span class="sd">    &gt;&gt;&gt; hypothesis = list(&#39;aaaaaaaaaaaa&#39;)      # i.e. [&#39;a&#39;] * 12</span>
<span class="sd">    &gt;&gt;&gt; references = [reference1, reference2, reference3]</span>
<span class="sd">    &gt;&gt;&gt; hyp_len = len(hypothesis)</span>
<span class="sd">    &gt;&gt;&gt; closest_ref_len =  closest_ref_length(references, hyp_len)</span>
<span class="sd">    &gt;&gt;&gt; brevity_penalty(closest_ref_len, hyp_len)</span>
<span class="sd">    1.0</span>

<span class="sd">    In case a hypothesis translation is shorter than the references, penalty is</span>
<span class="sd">    applied.</span>

<span class="sd">    &gt;&gt;&gt; references = [[&#39;a&#39;] * 28, [&#39;a&#39;] * 28]</span>
<span class="sd">    &gt;&gt;&gt; hypothesis = [&#39;a&#39;] * 12</span>
<span class="sd">    &gt;&gt;&gt; hyp_len = len(hypothesis)</span>
<span class="sd">    &gt;&gt;&gt; closest_ref_len =  closest_ref_length(references, hyp_len)</span>
<span class="sd">    &gt;&gt;&gt; brevity_penalty(closest_ref_len, hyp_len)</span>
<span class="sd">    0.2635971381157267</span>

<span class="sd">    The length of the closest reference is used to compute the penalty. If the</span>
<span class="sd">    length of a hypothesis is 12, and the reference lengths are 13 and 2, the</span>
<span class="sd">    penalty is applied because the hypothesis length (12) is less then the</span>
<span class="sd">    closest reference length (13).</span>

<span class="sd">    &gt;&gt;&gt; references = [[&#39;a&#39;] * 13, [&#39;a&#39;] * 2]</span>
<span class="sd">    &gt;&gt;&gt; hypothesis = [&#39;a&#39;] * 12</span>
<span class="sd">    &gt;&gt;&gt; hyp_len = len(hypothesis)</span>
<span class="sd">    &gt;&gt;&gt; closest_ref_len =  closest_ref_length(references, hyp_len)</span>
<span class="sd">    &gt;&gt;&gt; brevity_penalty(closest_ref_len, hyp_len) # doctest: +ELLIPSIS</span>
<span class="sd">    0.9200...</span>

<span class="sd">    The brevity penalty doesn&#39;t depend on reference order. More importantly,</span>
<span class="sd">    when two reference sentences are at the same distance, the shortest</span>
<span class="sd">    reference sentence length is used.</span>

<span class="sd">    &gt;&gt;&gt; references = [[&#39;a&#39;] * 13, [&#39;a&#39;] * 11]</span>
<span class="sd">    &gt;&gt;&gt; hypothesis = [&#39;a&#39;] * 12</span>
<span class="sd">    &gt;&gt;&gt; hyp_len = len(hypothesis)</span>
<span class="sd">    &gt;&gt;&gt; closest_ref_len =  closest_ref_length(references, hyp_len)</span>
<span class="sd">    &gt;&gt;&gt; bp1 = brevity_penalty(closest_ref_len, hyp_len)</span>
<span class="sd">    &gt;&gt;&gt; hyp_len = len(hypothesis)</span>
<span class="sd">    &gt;&gt;&gt; closest_ref_len =  closest_ref_length(reversed(references), hyp_len)</span>
<span class="sd">    &gt;&gt;&gt; bp2 = brevity_penalty(closest_ref_len, hyp_len)</span>
<span class="sd">    &gt;&gt;&gt; bp1 == bp2 == 1</span>
<span class="sd">    True</span>

<span class="sd">    A test example from mteval-v13a.pl (starting from the line 705):</span>

<span class="sd">    &gt;&gt;&gt; references = [[&#39;a&#39;] * 11, [&#39;a&#39;] * 8]</span>
<span class="sd">    &gt;&gt;&gt; hypothesis = [&#39;a&#39;] * 7</span>
<span class="sd">    &gt;&gt;&gt; hyp_len = len(hypothesis)</span>
<span class="sd">    &gt;&gt;&gt; closest_ref_len =  closest_ref_length(references, hyp_len)</span>
<span class="sd">    &gt;&gt;&gt; brevity_penalty(closest_ref_len, hyp_len) # doctest: +ELLIPSIS</span>
<span class="sd">    0.8668...</span>

<span class="sd">    &gt;&gt;&gt; references = [[&#39;a&#39;] * 11, [&#39;a&#39;] * 8, [&#39;a&#39;] * 6, [&#39;a&#39;] * 7]</span>
<span class="sd">    &gt;&gt;&gt; hypothesis = [&#39;a&#39;] * 7</span>
<span class="sd">    &gt;&gt;&gt; hyp_len = len(hypothesis)</span>
<span class="sd">    &gt;&gt;&gt; closest_ref_len =  closest_ref_length(references, hyp_len)</span>
<span class="sd">    &gt;&gt;&gt; brevity_penalty(closest_ref_len, hyp_len)</span>
<span class="sd">    1.0</span>

<span class="sd">    :param hyp_len: The length of the hypothesis for a single sentence OR the</span>
<span class="sd">        sum of all the hypotheses&#39; lengths for a corpus</span>
<span class="sd">    :type hyp_len: int</span>
<span class="sd">    :param closest_ref_len: The length of the closest reference for a single</span>
<span class="sd">        hypothesis OR the sum of all the closest references for every hypotheses.</span>
<span class="sd">    :type closest_ref_len: int</span>
<span class="sd">    :return: BLEU&#39;s brevity penalty.</span>
<span class="sd">    :rtype: float</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">hyp_len</span> <span class="o">&gt;</span> <span class="n">closest_ref_len</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>
    <span class="c1"># If hypothesis is empty, brevity penalty = 0 should result in BLEU = 0.0</span>
    <span class="k">elif</span> <span class="n">hyp_len</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">closest_ref_len</span> <span class="o">/</span> <span class="n">hyp_len</span><span class="p">)</span></div>


<div class="viewcode-block" id="SmoothingFunction"><a class="viewcode-back" href="../../../api/nltk.translate.bleu_score.html#nltk.translate.bleu_score.SmoothingFunction">[docs]</a><span class="k">class</span> <span class="nc">SmoothingFunction</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This is an implementation of the smoothing techniques</span>
<span class="sd">    for segment-level BLEU scores that was presented in</span>
<span class="sd">    Boxing Chen and Collin Cherry (2014) A Systematic Comparison of</span>
<span class="sd">    Smoothing Techniques for Sentence-Level BLEU. In WMT14.</span>
<span class="sd">    http://acl2014.org/acl2014/W14-33/pdf/W14-3346.pdf</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="SmoothingFunction.__init__"><a class="viewcode-back" href="../../../api/nltk.translate.bleu_score.html#nltk.translate.bleu_score.SmoothingFunction.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This will initialize the parameters required for the various smoothing</span>
<span class="sd">        techniques, the default values are set to the numbers used in the</span>
<span class="sd">        experiments from Chen and Cherry (2014).</span>

<span class="sd">        &gt;&gt;&gt; hypothesis1 = [&#39;It&#39;, &#39;is&#39;, &#39;a&#39;, &#39;guide&#39;, &#39;to&#39;, &#39;action&#39;, &#39;which&#39;, &#39;ensures&#39;,</span>
<span class="sd">        ...                 &#39;that&#39;, &#39;the&#39;, &#39;military&#39;, &#39;always&#39;, &#39;obeys&#39;, &#39;the&#39;,</span>
<span class="sd">        ...                 &#39;commands&#39;, &#39;of&#39;, &#39;the&#39;, &#39;party&#39;]</span>
<span class="sd">        &gt;&gt;&gt; reference1 = [&#39;It&#39;, &#39;is&#39;, &#39;a&#39;, &#39;guide&#39;, &#39;to&#39;, &#39;action&#39;, &#39;that&#39;, &#39;ensures&#39;,</span>
<span class="sd">        ...               &#39;that&#39;, &#39;the&#39;, &#39;military&#39;, &#39;will&#39;, &#39;forever&#39;, &#39;heed&#39;,</span>
<span class="sd">        ...               &#39;Party&#39;, &#39;commands&#39;]</span>

<span class="sd">        &gt;&gt;&gt; chencherry = SmoothingFunction()</span>
<span class="sd">        &gt;&gt;&gt; print(sentence_bleu([reference1], hypothesis1)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.4118...</span>
<span class="sd">        &gt;&gt;&gt; print(sentence_bleu([reference1], hypothesis1, smoothing_function=chencherry.method0)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.4118...</span>
<span class="sd">        &gt;&gt;&gt; print(sentence_bleu([reference1], hypothesis1, smoothing_function=chencherry.method1)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.4118...</span>
<span class="sd">        &gt;&gt;&gt; print(sentence_bleu([reference1], hypothesis1, smoothing_function=chencherry.method2)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.4452...</span>
<span class="sd">        &gt;&gt;&gt; print(sentence_bleu([reference1], hypothesis1, smoothing_function=chencherry.method3)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.4118...</span>
<span class="sd">        &gt;&gt;&gt; print(sentence_bleu([reference1], hypothesis1, smoothing_function=chencherry.method4)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.4118...</span>
<span class="sd">        &gt;&gt;&gt; print(sentence_bleu([reference1], hypothesis1, smoothing_function=chencherry.method5)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.4905...</span>
<span class="sd">        &gt;&gt;&gt; print(sentence_bleu([reference1], hypothesis1, smoothing_function=chencherry.method6)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.4135...</span>
<span class="sd">        &gt;&gt;&gt; print(sentence_bleu([reference1], hypothesis1, smoothing_function=chencherry.method7)) # doctest: +ELLIPSIS</span>
<span class="sd">        0.4905...</span>

<span class="sd">        :param epsilon: the epsilon value use in method 1</span>
<span class="sd">        :type epsilon: float</span>
<span class="sd">        :param alpha: the alpha value use in method 6</span>
<span class="sd">        :type alpha: int</span>
<span class="sd">        :param k: the k value use in method 4</span>
<span class="sd">        :type k: int</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span></div>

<div class="viewcode-block" id="SmoothingFunction.method0"><a class="viewcode-back" href="../../../api/nltk.translate.bleu_score.html#nltk.translate.bleu_score.SmoothingFunction.method0">[docs]</a>    <span class="k">def</span> <span class="nf">method0</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p_n</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        No smoothing.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">p_n_new</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p_i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">p_n</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">p_i</span><span class="o">.</span><span class="n">numerator</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">p_n_new</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p_i</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">_msg</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span>
                    <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">The hypothesis contains 0 counts of </span><span class="si">{}</span><span class="s2">-gram overlaps.</span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="s2">&quot;Therefore the BLEU score evaluates to 0, independently of</span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="s2">&quot;how many N-gram overlaps of lower order it contains.</span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="s2">&quot;Consider using lower n-gram order or use &quot;</span>
                    <span class="s2">&quot;SmoothingFunction()&quot;</span>
                <span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">_msg</span><span class="p">)</span>
                <span class="c1"># When numerator==0 where denonminator==0 or !=0, the result</span>
                <span class="c1"># for the precision score should be equal to 0 or undefined.</span>
                <span class="c1"># Due to BLEU geometric mean computation in logarithm space,</span>
                <span class="c1"># we we need to take the return sys.float_info.min such that</span>
                <span class="c1"># math.log(sys.float_info.min) returns a 0 precision score.</span>
                <span class="n">p_n_new</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">float_info</span><span class="o">.</span><span class="n">min</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">p_n_new</span></div>

<div class="viewcode-block" id="SmoothingFunction.method1"><a class="viewcode-back" href="../../../api/nltk.translate.bleu_score.html#nltk.translate.bleu_score.SmoothingFunction.method1">[docs]</a>    <span class="k">def</span> <span class="nf">method1</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p_n</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Smoothing method 1: Add *epsilon* counts to precision with 0 counts.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="p">(</span><span class="n">p_i</span><span class="o">.</span><span class="n">numerator</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span> <span class="o">/</span> <span class="n">p_i</span><span class="o">.</span><span class="n">denominator</span>
            <span class="k">if</span> <span class="n">p_i</span><span class="o">.</span><span class="n">numerator</span> <span class="o">==</span> <span class="mi">0</span>
            <span class="k">else</span> <span class="n">p_i</span>
            <span class="k">for</span> <span class="n">p_i</span> <span class="ow">in</span> <span class="n">p_n</span>
        <span class="p">]</span></div>

<div class="viewcode-block" id="SmoothingFunction.method2"><a class="viewcode-back" href="../../../api/nltk.translate.bleu_score.html#nltk.translate.bleu_score.SmoothingFunction.method2">[docs]</a>    <span class="k">def</span> <span class="nf">method2</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p_n</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Smoothing method 2: Add 1 to both numerator and denominator from</span>
<span class="sd">        Chin-Yew Lin and Franz Josef Och (2004) ORANGE: a Method for</span>
<span class="sd">        Evaluating Automatic Evaluation Metrics for Machine Translation.</span>
<span class="sd">        In COLING 2004.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="n">Fraction</span><span class="p">(</span><span class="n">p_n</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">numerator</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p_n</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">denominator</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">_normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="mi">0</span>
            <span class="k">else</span> <span class="n">p_n</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">p_n</span><span class="p">))</span>
        <span class="p">]</span></div>

<div class="viewcode-block" id="SmoothingFunction.method3"><a class="viewcode-back" href="../../../api/nltk.translate.bleu_score.html#nltk.translate.bleu_score.SmoothingFunction.method3">[docs]</a>    <span class="k">def</span> <span class="nf">method3</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p_n</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Smoothing method 3: NIST geometric sequence smoothing</span>
<span class="sd">        The smoothing is computed by taking 1 / ( 2^k ), instead of 0, for each</span>
<span class="sd">        precision score whose matching n-gram count is null.</span>
<span class="sd">        k is 1 for the first &#39;n&#39; value for which the n-gram match count is null/</span>

<span class="sd">        For example, if the text contains:</span>

<span class="sd">        - one 2-gram match</span>
<span class="sd">        - and (consequently) two 1-gram matches</span>

<span class="sd">        the n-gram count for each individual precision score would be:</span>

<span class="sd">        - n=1  =&gt;  prec_count = 2     (two unigrams)</span>
<span class="sd">        - n=2  =&gt;  prec_count = 1     (one bigram)</span>
<span class="sd">        - n=3  =&gt;  prec_count = 1/2   (no trigram,  taking &#39;smoothed&#39; value of 1 / ( 2^k ), with k=1)</span>
<span class="sd">        - n=4  =&gt;  prec_count = 1/4   (no fourgram, taking &#39;smoothed&#39; value of 1 / ( 2^k ), with k=2)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">incvnt</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># From the mteval-v13a.pl, it&#39;s referred to as k.</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p_i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">p_n</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">p_i</span><span class="o">.</span><span class="n">numerator</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">p_n</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="n">incvnt</span> <span class="o">*</span> <span class="n">p_i</span><span class="o">.</span><span class="n">denominator</span><span class="p">)</span>
                <span class="n">incvnt</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">p_n</span></div>

<div class="viewcode-block" id="SmoothingFunction.method4"><a class="viewcode-back" href="../../../api/nltk.translate.bleu_score.html#nltk.translate.bleu_score.SmoothingFunction.method4">[docs]</a>    <span class="k">def</span> <span class="nf">method4</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p_n</span><span class="p">,</span> <span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="n">hyp_len</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Smoothing method 4:</span>
<span class="sd">        Shorter translations may have inflated precision values due to having</span>
<span class="sd">        smaller denominators; therefore, we give them proportionally</span>
<span class="sd">        smaller smoothed counts. Instead of scaling to 1/(2^k), Chen and Cherry</span>
<span class="sd">        suggests dividing by 1/ln(len(T)), where T is the length of the translation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">incvnt</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">hyp_len</span> <span class="o">=</span> <span class="n">hyp_len</span> <span class="k">if</span> <span class="n">hyp_len</span> <span class="k">else</span> <span class="nb">len</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p_i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">p_n</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">p_i</span><span class="o">.</span><span class="n">numerator</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">hyp_len</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="c1"># incvnt = i + 1 * self.k / math.log(</span>
                <span class="c1">#     hyp_len</span>
                <span class="c1"># )  # Note that this K is different from the K from NIST.</span>
                <span class="c1"># p_n[i] = incvnt / p_i.denominator\</span>
                <span class="n">numerator</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="n">incvnt</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">hyp_len</span><span class="p">))</span>
                <span class="n">p_n</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">numerator</span> <span class="o">/</span> <span class="n">p_i</span><span class="o">.</span><span class="n">denominator</span>
                <span class="n">incvnt</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">p_n</span></div>

<div class="viewcode-block" id="SmoothingFunction.method5"><a class="viewcode-back" href="../../../api/nltk.translate.bleu_score.html#nltk.translate.bleu_score.SmoothingFunction.method5">[docs]</a>    <span class="k">def</span> <span class="nf">method5</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p_n</span><span class="p">,</span> <span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="n">hyp_len</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Smoothing method 5:</span>
<span class="sd">        The matched counts for similar values of n should be similar. To a</span>
<span class="sd">        calculate the n-gram matched count, it averages the n‚àí1, n and n+1 gram</span>
<span class="sd">        matched counts.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">hyp_len</span> <span class="o">=</span> <span class="n">hyp_len</span> <span class="k">if</span> <span class="n">hyp_len</span> <span class="k">else</span> <span class="nb">len</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">)</span>
        <span class="n">m</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="c1"># Requires an precision value for an addition ngram order.</span>
        <span class="n">p_n_plus1</span> <span class="o">=</span> <span class="n">p_n</span> <span class="o">+</span> <span class="p">[</span><span class="n">modified_precision</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="mi">5</span><span class="p">)]</span>
        <span class="n">m</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_n</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p_i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">p_n</span><span class="p">):</span>
            <span class="n">p_n</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">m</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">p_i</span> <span class="o">+</span> <span class="n">p_n_plus1</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="mi">3</span>
            <span class="n">m</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_n</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">p_n</span></div>

<div class="viewcode-block" id="SmoothingFunction.method6"><a class="viewcode-back" href="../../../api/nltk.translate.bleu_score.html#nltk.translate.bleu_score.SmoothingFunction.method6">[docs]</a>    <span class="k">def</span> <span class="nf">method6</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p_n</span><span class="p">,</span> <span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="n">hyp_len</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Smoothing method 6:</span>
<span class="sd">        Interpolates the maximum likelihood estimate of the precision *p_n* with</span>
<span class="sd">        a prior estimate *pi0*. The prior is estimated by assuming that the ratio</span>
<span class="sd">        between pn and pn‚àí1 will be the same as that between pn‚àí1 and pn‚àí2; from</span>
<span class="sd">        Gao and He (2013) Training MRF-Based Phrase Translation Models using</span>
<span class="sd">        Gradient Ascent. In NAACL.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">hyp_len</span> <span class="o">=</span> <span class="n">hyp_len</span> <span class="k">if</span> <span class="n">hyp_len</span> <span class="k">else</span> <span class="nb">len</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">)</span>
        <span class="c1"># This smoothing only works when p_1 and p_2 is non-zero.</span>
        <span class="c1"># Raise an error with an appropriate message when the input is too short</span>
        <span class="c1"># to use this smoothing technique.</span>
        <span class="k">assert</span> <span class="n">p_n</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="s2">&quot;This smoothing method requires non-zero precision for bigrams.&quot;</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p_i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">p_n</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]:</span>  <span class="c1"># Skips the first 2 orders of ngrams.</span>
                <span class="k">continue</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">pi0</span> <span class="o">=</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">p_n</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">p_n</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">p_n</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">2</span><span class="p">]</span>
                <span class="c1"># No. of ngrams in translation that matches the reference.</span>
                <span class="n">m</span> <span class="o">=</span> <span class="n">p_i</span><span class="o">.</span><span class="n">numerator</span>
                <span class="c1"># No. of ngrams in translation.</span>
                <span class="n">l</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">ngrams</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
                <span class="c1"># Calculates the interpolated precision.</span>
                <span class="n">p_n</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">m</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">pi0</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">l</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">p_n</span></div>

<div class="viewcode-block" id="SmoothingFunction.method7"><a class="viewcode-back" href="../../../api/nltk.translate.bleu_score.html#nltk.translate.bleu_score.SmoothingFunction.method7">[docs]</a>    <span class="k">def</span> <span class="nf">method7</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p_n</span><span class="p">,</span> <span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="n">hyp_len</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Smoothing method 7:</span>
<span class="sd">        Interpolates methods 4 and 5.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">hyp_len</span> <span class="o">=</span> <span class="n">hyp_len</span> <span class="k">if</span> <span class="n">hyp_len</span> <span class="k">else</span> <span class="nb">len</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">)</span>
        <span class="n">p_n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">method4</span><span class="p">(</span><span class="n">p_n</span><span class="p">,</span> <span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">)</span>
        <span class="n">p_n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">method5</span><span class="p">(</span><span class="n">p_n</span><span class="p">,</span> <span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">p_n</span></div></div>
</pre></div>

        </div>
      </div>

    </div>

<footer>
    <div id="footer-info">
        <ul id="build-details">
            

            
                <li class="footer-element">
                    <a href="https://github.com/nltk/nltk/tree/3.8.1">3.8.1</a>
                </li>
            

            
                <li class="footer-element">
                    Jan 02, 2023
                </li>
            
        </ul>

        
            <div id="copyright">
                &copy; 2023, NLTK Project
            </div>
        

        <div id="credit">
            created with <a href="http://sphinx-doc.org/">Sphinx</a> and <a href="https://github.com/tomaarsen/nltk_theme">NLTK Theme</a>
        </div>
    </div>
</footer> 

</div>

</body>
</html>